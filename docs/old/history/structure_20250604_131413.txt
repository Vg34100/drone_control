Scan Report
===========
Date: 2025-06-04 13:14:13
Source Directory: C:\Users\video\The Studio\Downloads\drone_control
Output File: C:\Users\video\The Studio\Downloads\drone_control\docs\history\structure_20250604_131413.txt

Ignored Patterns:
================
- **/*.log
- **/*.patch
- **/*/__pycache__/*
- **/.vscode
- **/dataset/*
- **/debug_frames/*
- **/docs/history/*
- **/recordings/*
- **/runs/*
- **/test/*
- **/venv
- *.log
- *.patch
- */__pycache__/*
- .vscode
- dataset/*
- debug_frames/*
- docs/history/*
- recordings/*
- runs/*
- test/*
- venv
- *debug*
- *models*
- path_walker.py

Directory Structure:
===================

drone_control/
  main.py
  detection/
    bullseye_detector.py
    camera.py
    gcp_yolo_detector.py
    video_recorder.py
  docs/
    old/
      delivery.py
      gcp.py
      gcp_detector.py
  drone/
    connection.py
    navigation.py
    servo.py
  missions/
    test_missions.py
    waypoint.py
    waypoint_bullseye.py
    waypoint_gcp.py


File Contents:
=============


--- main.py ---
#!/usr/bin/env python3
"""
main.py - IMPROVED VERSION WITH VIDEO RECORDING & BULLSEYE DETECTION
Drone Control System - Main Launcher
-----------------------------------
This script serves as the main entry point for all drone operations.
It parses command-line arguments to determine which mission to run.
"""

import argparse
import sys
import logging
import time
from typing import Dict, Callable, Any
from pymavlink import mavutil

# Import modules
from detection.gcp_yolo_detector import test_gcp_yolo_detection
from drone.connection import connect_vehicle, close_vehicle
from drone.navigation import set_mode, test_motors
from drone.servo import test_servo_simple
from missions.test_missions import (
    test_connection, test_arm, test_takeoff, test_camera, test_detection,
    test_motor, test_incremental_takeoff, monitor_altitude_realtime
)
from missions.waypoint import (
    mission_diamond_precision_fixed, mission_waypoint, mission_waypoint_detect
)
from detection.video_recorder import create_video_recorder
from detection.bullseye_detector import test_bullseye_detection
from missions.waypoint_bullseye import mission_waypoint_bullseye_detection
from missions.waypoint_gcp import mission_waypoint_gcp_detection

class MissionConfig:
    """Configuration class for mission parameters and shortcuts"""

    # Mission aliases mapping - maps shortcuts to primary mission names
    MISSION_ALIASES = {
        # Connection tests
        "test-connection": ["conn", "c", "1"],
        "preflight-all": ["pre", "p", "0"],
        "reset-controller": ["reset", "r", "2"],

        # Takeoff tests
        "incremental-takeoff": ["t-t", "inc-takeoff"],
        "diamond-waypoints": ["t-w", "diamond"],

        # Quick access shortcuts
        "test-arm": ["arm", "a"],
        "test-motor": ["motor", "m"],
        "test-camera": ["cam", "camera"],
        "test-servo": ["servo", "s"],
        "test-takeoff": ["takeoff", "to"],

        # NEW: Bullseye detection test
        "test-bullseye-video": ["bullseye", "bull", "b", "target"],
        "test-gcp-detection": ["gcp", "gcp-test", "g", "ground-control"],  # NEW: GCP detection

        # NEW: Video recording test
        "test-video-recording": ["record-test", "rec-test", "video-test"],

        # Diagnostics
        "diagnostics": ["diag", "d"],
        "check-altitude": ["alt", "altitude"],
        "safety-check": ["safety", "safe"],
        "orientation-check": ["orient", "orientation"],
        "position-hold-check": ["pos-hold", "position"],

        "test-waypoint-bullseye": ["waypoint-bullseye", "wb", "bullseye-waypoint"],

        # GCP Detection missions
        "test-gcp-yolo": ["gcp", "gcp-yolo", "test-gcp", "gcp-test"],
        "test-waypoint-gcp": ["waypoint-gcp", "wgcp", "gcp-waypoint"],
    }

    # Reverse mapping for quick lookup
    ALIAS_TO_MISSION = {}
    for mission, aliases in MISSION_ALIASES.items():
        ALIAS_TO_MISSION[mission] = mission  # Add the primary name
        for alias in aliases:
            ALIAS_TO_MISSION[alias] = mission

class DroneController:
    """Main drone controller class"""

    def __init__(self):
        self.vehicle = None
        self.config = MissionConfig()
        self.mission_handlers = self._setup_mission_handlers()
        self.video_recorder = None

    def _setup_mission_handlers(self) -> Dict[str, Callable]:
        """Setup mission handler mapping"""
        return {
            # Connection and diagnostics
            "test-connection": self._handle_test_connection,
            "preflight-all": self._handle_preflight_all,
            "reset-controller": self._handle_reset_controller,
            "diagnostics": self._handle_diagnostics,

            # Basic tests
            "test-arm": self._handle_test_arm,
            "test-motor": self._handle_test_motor,
            "test-camera": self._handle_test_camera,
            "test-servo": self._handle_test_servo,
            "test-detect": self._handle_test_detect,

            # NEW: Bullseye detection test
            "test-bullseye-video": self._handle_test_bullseye_video,
            "test-gcp-detection": self._handle_test_gcp_detection,

            # NEW: Video recording test
            "test-video-recording": self._handle_test_video_recording,

            # Takeoff tests
            "test-takeoff": self._handle_test_takeoff,
            "incremental-takeoff": self._handle_incremental_takeoff,
            "diamond-waypoints": self._handle_diamond_waypoints,

            # Navigation missions
            "waypoint": self._handle_waypoint,
            "waypoint-detect": self._handle_waypoint_detect,

            # System controls
            "fix-mode": self._handle_fix_mode,

            # Safety checks
            "safety-check": self._handle_safety_check,
            "orientation-check": self._handle_orientation_check,
            "position-hold-check": self._handle_position_hold_check,
            "check-altitude": self._handle_check_altitude,

            "test-waypoint-bullseye": self._handle_waypoint_bullseye,

            # GCP detection tests
            "test-gcp-yolo": self._handle_test_gcp_yolo,
            "test-waypoint-gcp": self._handle_waypoint_gcp,
        }

    def setup_logging(self):
        """Configure logging"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            filename='drone_mission.log'
        )
        console = logging.StreamHandler()
        console.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console.setFormatter(formatter)
        logging.getLogger('').addHandler(console)

    def create_parser(self) -> argparse.ArgumentParser:
        """Create and configure argument parser"""
        parser = argparse.ArgumentParser(
            description="Drone Mission Control System",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog=self._get_help_epilog()
        )

        # Get all possible mission choices (primary names + aliases)
        all_choices = list(self.config.ALIAS_TO_MISSION.keys())

        parser.add_argument(
            "mission",
            choices=all_choices,
            help="Mission to execute (use -h to see shortcuts)"
        )

        # Mission parameters
        parser.add_argument("--altitude", type=float, default=3.0,
                          help="Target altitude in meters")
        parser.add_argument("--connection", type=str, default="tcp:127.0.0.1:5761",
                          help="Connection string for the vehicle")
        parser.add_argument("--model", type=str, default="models/latest.pt",
                          help="Path to the detection model")
        parser.add_argument("--duration", type=float, default=1.0,
                          help="Duration for motor testing")
        parser.add_argument("--throttle", type=float, default=15.0,
                          help="Throttle percentage for motor testing (0-100)")
        parser.add_argument("--increment", type=float, default=1.0,
                          help="Height increment in meters for incremental takeoff")
        parser.add_argument("--loops", type=int, default=1,
                          help="Number of times to repeat the mission")

        # NEW: Video recording options
        parser.add_argument("--record", action="store_true",
                          help="Record video during mission execution")
        parser.add_argument("--record-fps", type=float, default=30.0,
                          help="Recording frame rate (default: 30 FPS)")
        parser.add_argument("--record-dir", type=str, default="recordings",
                          help="Directory to save recordings (default: recordings)")

        # NEW: Bullseye detection options
        parser.add_argument("--source", type=str, default="0",
                          help="Camera ID, video file, or image file for bullseye detection")
        parser.add_argument("--display", action="store_true", default=True,
                          help="Display detection results (default: True)")
        parser.add_argument("--no-display", dest="display", action="store_false",
                          help="Disable display of detection results")
        parser.add_argument("--save-results", action="store_true", default=True,
                          help="Save detection results (default: True)")
        parser.add_argument("--no-save", dest="save_results", action="store_false",
                          help="Disable saving of detection results")
        parser.add_argument("--video-delay", type=float, default=0.1,
                          help="Delay between video frames in seconds (default: 0.1)")

        parser.add_argument("--confidence", type=float, default=0.5,
                          help="Detection confidence threshold (default: 0.5)")


        # GCP-specific options
        parser.add_argument("--gcp-model", type=str, default="models/best-gcp.pt",
                          help="Path to GCP YOLO model (default: models/best-gcp.pt)")
        parser.add_argument("--gcp-confidence", type=float, default=0.5,
                          help="Confidence threshold for GCP detection (default: 0.5)")

        return parser

    def _get_help_epilog(self) -> str:
        """Generate help text showing mission shortcuts"""
        lines = ["\nMission Shortcuts:"]
        lines.append("=" * 50)

        for mission, aliases in self.config.MISSION_ALIASES.items():
            if aliases:  # Only show if there are aliases
                aliases_str = ", ".join(aliases)
                lines.append(f"  {mission:<20} ‚Üí {aliases_str}")

        lines.append("\nExamples:")
        lines.append("  python main.py c              # test-connection")
        lines.append("  python main.py pre --altitude 5  # preflight-all at 5m")
        lines.append("  python main.py t-t --increment 0.5  # incremental takeoff")
        lines.append("  python main.py diamond --loops 3    # 3 diamond loops")
        lines.append("  python main.py diamond --record     # record video during mission")
        lines.append("  python main.py bullseye --source video.mp4  # detect bullseyes in video")
        lines.append("  python main.py bull --source image.jpg --no-display  # process image without display")
        lines.append("  python main.py record-test --duration 15  # test video recording for 15 seconds")
        lines.append("  python main.py rec-test --source 1 --duration 30  # test camera 1 for 30 seconds")

        lines.append("  python main.py wb --altitude 5 --loops 2    # waypoint bullseye mission")
        lines.append("  python main.py test-waypoint-bullseye --model best.pt --confidence 0.6")

        lines.append("  python main.py gcp --source video.mp4  # detect GCP markers in video")
        lines.append("  python main.py test-gcp-yolo --source 0 --gcp-confidence 0.6  # test GCP detection")
        lines.append("  python main.py wgcp --altitude 8 --loops 1    # waypoint GCP mission")
        lines.append("  python main.py test-waypoint-gcp --gcp-model best-gcp.pt --confidence 0.7")

        return "\n".join(lines)

    def connect_if_needed(self, mission: str, connection_string: str) -> bool:
        """Connect to vehicle if the mission requires it"""
        # Resolve mission alias to primary name FIRST
        primary_mission = self.config.ALIAS_TO_MISSION.get(mission, mission)

        missions_without_vehicle = {
            "test-camera",
            "test-bullseye-video",
            "test-video-recording",
            "test-gcp-detection",
            "test-gcp-yolo",
        }

        if primary_mission in missions_without_vehicle:
            logging.info(f"Mission '{primary_mission}' does not require vehicle connection")
            return True

        logging.info(f"Connecting to vehicle at {connection_string}")
        self.vehicle = connect_vehicle(connection_string)

        if not self.vehicle:
            logging.error("Failed to connect to vehicle")
            return False

        return True

    def start_recording_if_requested(self, args, mission_name: str) -> bool:
        """Start video recording if requested"""
        if not args.record:
            return True

        logging.info("Starting video recording...")
        self.video_recorder = create_video_recorder(
            output_dir=args.record_dir,
            fps=args.record_fps
        )

        success = self.video_recorder.start_recording(
            camera_id=0,
            mission_name=mission_name
        )

        if success:
            logging.info(f"Recording started for mission: {mission_name}")
        else:
            logging.error("Failed to start video recording")
            self.video_recorder = None

        return success

    def stop_recording_if_active(self):
        """Stop video recording if active"""
        if self.video_recorder and self.video_recorder.is_recording():
            logging.info("Stopping video recording...")
            success = self.video_recorder.stop_recording()
            if success:
                logging.info("Video recording stopped successfully")
            else:
                logging.error("Error stopping video recording")
            self.video_recorder = None

    def execute_mission(self, mission: str, args: argparse.Namespace) -> bool:
        """Execute the specified mission"""
        # Resolve mission alias to primary name
        primary_mission = self.config.ALIAS_TO_MISSION.get(mission, mission)

        # Get handler for the mission
        handler = self.mission_handlers.get(primary_mission)

        if not handler:
            logging.error(f"Unknown mission: {mission}")
            return False

        logging.info(f"Executing mission: {primary_mission} (alias: {mission})")

        try:
            # Start recording if requested (except for standalone test missions)
            standalone_missions = {"test-camera", "test-bullseye-video", "test-gcp-detection", "test-video-recording"}
            if primary_mission not in standalone_missions:
                if not self.start_recording_if_requested(args, primary_mission):
                    logging.warning("Continuing mission without recording")

            # Execute the mission
            result = handler(args)

            return result

        except Exception as e:
            logging.exception(f"Mission '{primary_mission}' failed with error: {str(e)}")
            return False
        finally:
            # Always stop recording when mission ends
            self.stop_recording_if_active()

    # Mission handler methods
    def _handle_test_connection(self, args) -> bool:
        return test_connection(self.vehicle)

    def _handle_test_arm(self, args) -> bool:
        return test_arm(self.vehicle)

    def _handle_test_takeoff(self, args) -> bool:
        return test_takeoff(self.vehicle, args.altitude)

    def _handle_test_camera(self, args) -> bool:
        return test_camera()

    def _handle_test_detect(self, args) -> bool:
        return test_detection(args.model)

    def _handle_test_motor(self, args) -> bool:
        return test_motor(self.vehicle, args.throttle, args.duration)

    def _handle_test_servo(self, args) -> bool:
        return test_servo_simple(self.vehicle)

    def _handle_test_bullseye_video(self, args) -> bool:
        """Handle bullseye detection test"""
        # Convert source to appropriate type
        source = args.source
        try:
            # Try to convert to int (camera ID)
            source = int(source)
        except ValueError:
            # Keep as string (file path)
            pass

        return test_bullseye_detection(
            source=source,
            display=args.display,
            save_results=args.save_results,
            duration=args.duration if isinstance(source, int) else 0,
            video_delay=args.video_delay,
            model_path=args.model,
        )

    def _handle_test_gcp_detection(self, args) -> bool:
        """Handle GCP detection test"""
        # Convert source to appropriate type
        source = args.source
        try:
            # Try to convert to int (camera ID)
            source = int(source)
        except ValueError:
            # Keep as string (file path)
            pass

        return test_gcp_detection(
            source=source,
            display=args.display,
            save_results=args.save_results,
            duration=args.duration if isinstance(source, int) else 0,
            video_delay=args.video_delay,
            confidence=args.gcp_confidence
        )

    def _handle_test_video_recording(self, args) -> bool:
        """Handle video recording test (no vehicle required)"""
        from detection.video_recorder import test_video_recording

        # Convert source to camera ID if it's a digit
        camera_id = 0
        try:
            camera_id = int(args.source)
        except ValueError:
            logging.warning(f"Invalid camera ID '{args.source}', using camera 0")

        return test_video_recording(
            camera_id=camera_id,
            duration=args.duration if args.duration > 1 else 10,  # Default 10 seconds
            output_dir=args.record_dir
        )

    def _handle_incremental_takeoff(self, args) -> bool:
        return test_incremental_takeoff(self.vehicle, args.altitude, args.increment)

    def _handle_diamond_waypoints(self, args) -> bool:
        return mission_diamond_precision_fixed(self.vehicle, args.altitude, args.loops)

    def _handle_waypoint(self, args) -> bool:
        return mission_waypoint(self.vehicle, args.altitude)

    def _handle_waypoint_detect(self, args) -> bool:
        return mission_waypoint_detect(self.vehicle, args.altitude, args.model)

    def _handle_fix_mode(self, args) -> bool:
        if not self.vehicle:
            logging.error("Vehicle connection required for fix-mode")
            return False

        success = set_mode(self.vehicle, "LOITER")
        if success:
            logging.info("Successfully changed vehicle mode to LOITER")
        else:
            logging.error("Failed to change vehicle mode")
        return success

    def _handle_diagnostics(self, args) -> bool:
        from drone.connection import get_vehicle_diagnostics
        diagnostics = get_vehicle_diagnostics(self.vehicle, timeout=10)
        if diagnostics:
            logging.info("Diagnostics complete - see log for details")
            return True
        else:
            logging.error("Failed to get diagnostics")
            return False

    def _handle_reset_controller(self, args) -> bool:
        from drone.connection import reset_flight_controller
        success = reset_flight_controller(self.vehicle)
        if success:
            logging.info("Reset command sent to flight controller")
        else:
            logging.error("Failed to send reset command")
        return success

    def _handle_safety_check(self, args) -> bool:
        from drone.navigation import run_preflight_checks
        checks_passed, failure_reason = run_preflight_checks(self.vehicle)
        if not checks_passed:
            logging.error(f"Safety checks failed: {failure_reason}")
        else:
            logging.info("All safety checks passed!")
        return checks_passed

    def _handle_orientation_check(self, args) -> bool:
        from drone.navigation import verify_orientation
        success = verify_orientation(self.vehicle)
        if success:
            logging.info("Orientation is stable and suitable for takeoff")
        else:
            logging.warning("Orientation may be unstable - use caution")
        return success

    def _handle_position_hold_check(self, args) -> bool:
        from drone.navigation import verify_position_hold
        return verify_position_hold(self.vehicle)

    def _handle_check_altitude(self, args) -> bool:
        success = monitor_altitude_realtime(self.vehicle, duration=0)
        if success:
            logging.info("Altitude monitoring completed")
        else:
            logging.error("Altitude monitoring failed")
        return success

    def _handle_waypoint_bullseye(self, args) -> bool:
        """Handle waypoint bullseye detection and landing mission"""
        return mission_waypoint_bullseye_detection(
            vehicle=self.vehicle,
            altitude=args.altitude,
            model_path=args.model,
            confidence=getattr(args, 'confidence', 0.5),
            loops=args.loops,
            land_on_detection=True,
            video_recorder=self.video_recorder  # Pass the shared video recorder
        )

    def _handle_test_gcp_yolo(self, args) -> bool:
        """Handle GCP YOLO detection test"""
        # Convert source to appropriate type
        source = args.source
        try:
            # Try to convert to int (camera ID)
            source = int(source)
        except ValueError:
            # Keep as string (file path)
            pass

        return test_gcp_yolo_detection(
            source=source,
            display=args.display,
            save_results=args.save_results,
            duration=args.duration if isinstance(source, int) else 0,
            video_delay=args.video_delay,
            model_path=args.gcp_model,
            confidence=args.gcp_confidence,
            imgsz=getattr(args, 'imgsz', 160)
        )

    def _handle_waypoint_gcp(self, args) -> bool:
        """Handle waypoint GCP detection and collection mission"""
        return mission_waypoint_gcp_detection(
            vehicle=self.vehicle,
            altitude=args.altitude,
            model_path=args.gcp_model,
            confidence=args.gcp_confidence,
            loops=args.loops,
            video_recorder=self.video_recorder  # Pass the shared video recorder
        )


    def _handle_preflight_all(self, args) -> bool:
        """Run comprehensive preflight checks"""
        logging.info("Running comprehensive preflight checks...")

        checks = [
            ("Connection Test", lambda: test_connection(self.vehicle)),
            ("Arm Test", lambda: test_arm(self.vehicle)),
            ("Motor Test", lambda: test_motor(self.vehicle, args.throttle)),
            ("Safety Checks", self._handle_safety_check),
            ("Orientation Check", self._handle_orientation_check),
            ("Position Hold Check", self._handle_position_hold_check),
        ]

        results = []
        for check_name, check_func in checks:
            logging.info(f"Running {check_name}...")
            try:
                result = check_func(args) if check_name in ["Safety Checks", "Orientation Check", "Position Hold Check"] else check_func()
                results.append((check_name, result))
                logging.info(f"{check_name}: {'PASSED' if result else 'FAILED'}")
                time.sleep(2)  # Brief pause between checks
            except Exception as e:
                logging.error(f"{check_name} failed with exception: {str(e)}")
                results.append((check_name, False))

        # Summary
        passed = sum(1 for _, result in results if result)
        total = len(results)

        logging.info(f"\nPreflight Summary: {passed}/{total} checks passed")
        for check_name, result in results:
            status = "‚úì PASS" if result else "‚úó FAIL"
            logging.info(f"  {check_name}: {status}")

        return passed == total

    def cleanup(self):
        """Clean up resources"""
        # Stop recording if active
        self.stop_recording_if_active()

        # Close vehicle connection
        if self.vehicle:
            close_vehicle(self.vehicle)
            logging.info("Mission clean-up completed")

    def run(self) -> int:
        """Main execution method"""
        try:
            self.setup_logging()
            parser = self.create_parser()
            args = parser.parse_args()

            # Connect to vehicle if needed
            if not self.connect_if_needed(args.mission, args.connection):
                return 1

            # Execute mission
            success = self.execute_mission(args.mission, args)

            if success:
                logging.info(f"Mission '{args.mission}' completed successfully")
                return 0
            else:
                logging.error(f"Mission '{args.mission}' failed")
                return 1

        except KeyboardInterrupt:
            logging.warning("Mission aborted by user")
            return 130
        except Exception as e:
            logging.exception(f"Unexpected error: {str(e)}")
            return 1
        finally:
            self.cleanup()

def main():
    """Entry point"""
    controller = DroneController()
    return controller.run()

if __name__ == "__main__":
    sys.exit(main())


--- detection\bullseye_detector.py ---
# detection/bullseye_detector.py - UPDATED TO USE YOLO MODEL
"""
Bullseye Detection Module using YOLO Model
------------------------------------------
Updated to use trained YOLO model instead of OpenCV pattern matching.
Optimized for drone competition use with Jetson Orin Nano.
"""

import cv2
import numpy as np
import logging
import time
import os
from typing import List, Tuple, Optional, Union
from pathlib import Path

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    logging.warning("YOLO not available - install ultralytics: pip install ultralytics")

class BullseyeDetector:
    """YOLO-based bullseye detector for drone use"""

    def __init__(self, model_path="models/best.pt", confidence_threshold=0.5, imgsz=160):
        """
        Initialize the bullseye detector with YOLO model.

        Args:
            model_path: Path to the YOLO model file (best.pt or best.engine)
            confidence_threshold: Minimum confidence for detections
            imgsz: Input image size for the model
        """
        if not YOLO_AVAILABLE:
            raise ImportError("YOLO not available. Install with: pip install ultralytics")

        self.model_path = model_path
        self.conf_threshold = confidence_threshold
        self.imgsz = imgsz

        # Try to load the model
        if not os.path.exists(model_path):
            logging.error(f"Model file not found: {model_path}")
            # Try common locations
            alt_paths = [
                "best.pt",
                "models/best.pt",
                "best.engine",
                "models/best.engine"
            ]
            for alt_path in alt_paths:
                if os.path.exists(alt_path):
                    self.model_path = alt_path
                    logging.info(f"Found model at: {alt_path}")
                    break
            else:
                raise FileNotFoundError(f"Could not find model file. Tried: {model_path}, {alt_paths}")

        logging.info(f"Loading YOLO model: {self.model_path}")
        self.model = YOLO(self.model_path)

        # Performance tracking
        self.frame_count = 0
        self.total_inference_time = 0
        self.detections_count = 0

    def detect_bullseyes_in_frame(self, frame):
        """
        Detect bullseyes in a single frame using YOLO model.

        Args:
            frame: Input BGR image

        Returns:
            Tuple of (bullseyes, debug_image)
            bullseyes: List of (center_x, center_y, bbox_info, confidence)
            debug_image: Annotated image showing detections
        """
        if frame is None:
            return [], frame

        try:
            start_time = time.time()

            # Run YOLO inference
            results = self.model.predict(
                frame,
                imgsz=self.imgsz,
                conf=self.conf_threshold,
                verbose=False
            )

            inference_time = time.time() - start_time
            self.total_inference_time += inference_time
            self.frame_count += 1

            # Process results
            bullseyes = []
            debug_image = frame.copy()

            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        # Extract box coordinates and confidence
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        confidence = float(box.conf[0])

                        # Calculate center
                        center_x = (x1 + x2) // 2
                        center_y = (y1 + y2) // 2

                        # Create bbox info dictionary
                        bbox_info = {
                            'bbox': (x1, y1, x2, y2),
                            'width': x2 - x1,
                            'height': y2 - y1,
                            'area': (x2 - x1) * (y2 - y1)
                        }

                        # Add to bullseyes list (format compatible with old system)
                        bullseyes.append((center_x, center_y, bbox_info, confidence))
                        self.detections_count += 1

                        # Draw on debug image
                        self._draw_detection(debug_image, x1, y1, x2, y2, center_x, center_y, confidence)

            # Add frame info to debug image
            self._add_frame_info(debug_image, len(bullseyes), inference_time)

            return bullseyes, debug_image

        except Exception as e:
            logging.error(f"Error in YOLO bullseye detection: {str(e)}")
            return [], frame

    def _draw_detection(self, image, x1, y1, x2, y2, center_x, center_y, confidence):
        """Draw detection on image"""
        # Draw bounding box
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # Draw center point
        cv2.circle(image, (center_x, center_y), 5, (255, 0, 0), -1)

        # Draw crosshair at center
        cv2.line(image, (center_x - 10, center_y), (center_x + 10, center_y), (255, 0, 0), 2)
        cv2.line(image, (center_x, center_y - 10), (center_x, center_y + 10), (255, 0, 0), 2)

        # Add confidence label
        label = f"Bullseye: {confidence:.3f}"
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
        cv2.rectangle(image, (x1, y1 - label_size[1] - 10),
                     (x1 + label_size[0], y1), (0, 255, 0), -1)
        cv2.putText(image, label, (x1, y1 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

    def _add_frame_info(self, image, num_detections, inference_time):
        """Add frame information overlay"""
        # Calculate FPS
        fps = 1.0 / inference_time if inference_time > 0 else 0

        # Add frame info
        info_text = f"FPS: {fps:.1f} | Detections: {num_detections} | Frame: {self.frame_count}"
        cv2.putText(image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)

        # Add crosshair at frame center for drone alignment reference
        h, w = image.shape[:2]
        cv2.line(image, (w//2 - 20, h//2), (w//2 + 20, h//2), (0, 0, 255), 2)
        cv2.line(image, (w//2, h//2 - 20), (w//2, h//2 + 20), (0, 0, 255), 2)
        cv2.circle(image, (w//2, h//2), 3, (0, 0, 255), -1)

    def get_performance_stats(self):
        """Get performance statistics"""
        if self.frame_count == 0:
            return {}

        avg_fps = self.frame_count / self.total_inference_time if self.total_inference_time > 0 else 0
        avg_inference_ms = (self.total_inference_time / self.frame_count) * 1000

        return {
            'total_frames': self.frame_count,
            'total_detections': self.detections_count,
            'avg_detections_per_frame': self.detections_count / self.frame_count,
            'avg_fps': avg_fps,
            'avg_inference_ms': avg_inference_ms
        }

def create_enhanced_detection_display(original_frame, bullseyes, debug_image):
    """
    Create enhanced display with big indicators for detections.
    Updated to work with YOLO detection format.
    """
    enhanced = debug_image.copy()
    height, width = enhanced.shape[:2]

    # Add big detection indicators
    if len(bullseyes) > 0:
        # Green background overlay for success
        overlay = enhanced.copy()
        cv2.rectangle(overlay, (0, 0), (width, 80), (0, 150, 0), -1)
        enhanced = cv2.addWeighted(enhanced, 0.7, overlay, 0.3, 0)

        # Big success text
        cv2.putText(enhanced, f"üéØ BULLSEYE DETECTED! ({len(bullseyes)} found)",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        cv2.putText(enhanced, f"üéØ BULLSEYE DETECTED! ({len(bullseyes)} found)",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)

        # Draw big circles around detections
        for i, (center_x, center_y, bbox_info, confidence) in enumerate(bullseyes):
            # Big outer circle
            cv2.circle(enhanced, (center_x, center_y), 80, (0, 255, 0), 5)
            # Confidence text
            conf_text = f"Confidence: {confidence:.1%}"
            cv2.putText(enhanced, conf_text, (center_x - 60, center_y + 100),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    else:
        # Red background overlay for no detection
        overlay = enhanced.copy()
        cv2.rectangle(overlay, (0, 0), (width, 60), (0, 0, 150), -1)
        enhanced = cv2.addWeighted(enhanced, 0.8, overlay, 0.2, 0)

        # No detection text
        cv2.putText(enhanced, "üîç NO BULLSEYES DETECTED",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)
        cv2.putText(enhanced, "üîç NO BULLSEYES DETECTED",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

    return enhanced

def test_bullseye_detection(source: Union[str, int] = 0,
                          display: bool = True,
                          save_results: bool = True,
                          duration: float = 0,
                          video_delay: float = 0.1,
                          model_path: str = "models/best.pt",
                          confidence: float = 0.5,
                          imgsz: int = 160) -> bool:
    """
    Test YOLO-based bullseye detection on camera feed, video file, or image.

    Args:
        source: Camera ID (int), video file path, or image file path
        display: Whether to display the detection results
        save_results: Whether to save detection results
        duration: Duration for camera/video (0 = until 'q' pressed)
        video_delay: Delay between frames for video/camera (seconds)
        model_path: Path to YOLO model file
        confidence: Confidence threshold for detections
        imgsz: Model input image size

    Returns:
        True if test completed successfully
    """
    try:
        logging.info(f"Starting YOLO bullseye detection test with source: {source}")

        detector = BullseyeDetector(
            model_path=model_path,
            confidence_threshold=confidence,
            imgsz=imgsz
        )

        # Determine source type
        if isinstance(source, int):
            # Camera input
            cap = cv2.VideoCapture(source)
            if not cap.isOpened():
                logging.error(f"Failed to open camera {source}")
                return False

            # Set camera properties for drone use
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)
            source_type = "camera"

        elif isinstance(source, str):
            if source.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                # Image file
                image = cv2.imread(source)
                if image is None:
                    logging.error(f"Failed to load image: {source}")
                    return False
                source_type = "image"
            else:
                # Video file
                cap = cv2.VideoCapture(source)
                if not cap.isOpened():
                    logging.error(f"Failed to open video: {source}")
                    return False
                source_type = "video"
        else:
            logging.error("Invalid source type")
            return False

        # Process single image
        if source_type == "image":
            bullseyes, debug_image = detector.detect_bullseyes_in_frame(image)

            # Create enhanced display image
            enhanced_image = create_enhanced_detection_display(image, bullseyes, debug_image)

            logging.info(f"Detected {len(bullseyes)} bullseyes in image")
            for i, (x, y, bbox_info, confidence) in enumerate(bullseyes):
                logging.info(f"Bullseye {i+1}: Center ({x}, {y}), Confidence: {confidence:.3f}")

            if display:
                cv2.imshow("YOLO Bullseye Detection Results", enhanced_image)
                print("\n" + "="*60)
                print("üì∏ YOLO IMAGE DETECTION RESULTS")
                print("="*60)
                if len(bullseyes) > 0:
                    print(f"üéØ BULLSEYES FOUND: {len(bullseyes)}")
                    for i, (x, y, bbox_info, confidence) in enumerate(bullseyes):
                        print(f"   Bullseye {i+1}: Position ({x}, {y}), Confidence: {confidence:.1%}")
                else:
                    print("‚ùå NO BULLSEYES DETECTED")
                print("="*60)
                print("Press any key to close...")
                cv2.waitKey(0)
                cv2.destroyAllWindows()

            if save_results:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f"yolo_bullseye_detection_{timestamp}.jpg"
                cv2.imwrite(filename, enhanced_image)
                logging.info(f"Results saved to: {filename}")

            return True

        # Process video or camera feed
        else:
            total_frames = 0
            detection_frames = 0
            start_time = time.time()

            if source_type == "video":
                total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                video_fps = cap.get(cv2.CAP_PROP_FPS)
                logging.info(f"Video: {total_video_frames} frames @ {video_fps} FPS")

            logging.info(f"Processing {source_type}. Press 'q' to quit, 's' to save frame")
            print("\n" + "="*80)
            print(f"üé• {source_type.upper()} YOLO BULLSEYE DETECTION")
            print("="*80)
            print("Controls: 'q' = quit, 's' = save frame, 'p' = pause")
            print("="*80)

            while True:
                ret, frame = cap.read()

                if not ret:
                    if source_type == "camera":
                        logging.error("Failed to capture frame")
                        break
                    else:
                        logging.info("End of video reached")
                        break

                total_frames += 1

                # Detect bullseyes
                bullseyes, debug_image = detector.detect_bullseyes_in_frame(frame)

                # Create enhanced display
                enhanced_image = create_enhanced_detection_display(frame, bullseyes, debug_image)

                # Track detections
                if bullseyes:
                    detection_frames += 1
                    print(f"üéØ Frame {total_frames}: {len(bullseyes)} bullseye(s) detected!")
                    for i, (x, y, bbox_info, confidence) in enumerate(bullseyes):
                        print(f"   ‚Üí Bullseye {i+1} at ({x}, {y}), confidence: {confidence:.3f}")
                elif total_frames % 30 == 0:  # Log every 30 frames when no detection
                    print(f"üîç Frame {total_frames}: Searching for bullseyes...")

                # Display results
                if display:
                    cv2.imshow("YOLO Bullseye Detection", enhanced_image)

                    key = cv2.waitKey(int(video_delay * 1000)) & 0xFF
                    if key == ord('q'):
                        break
                    elif key == ord('s') and save_results:
                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                        filename = f"yolo_bullseye_frame_{total_frames}_{timestamp}.jpg"
                        cv2.imwrite(filename, enhanced_image)
                        logging.info(f"Frame saved: {filename}")
                    elif key == ord('p'):  # Pause
                        cv2.waitKey(0)
                else:
                    time.sleep(video_delay)

                # Check duration for camera
                if source_type == "camera" and duration > 0:
                    if time.time() - start_time >= duration:
                        break

                # Progress for video
                if source_type == "video" and total_frames % 30 == 0:
                    progress = (total_frames / total_video_frames) * 100
                    print(f"Progress: {progress:.1f}% ({total_frames}/{total_video_frames})")

            # Cleanup
            cap.release()
            if display:
                cv2.destroyAllWindows()

            # Final summary
            total_time = time.time() - start_time
            detection_rate = (detection_frames / total_frames * 100) if total_frames > 0 else 0
            stats = detector.get_performance_stats()

            print("\n" + "="*80)
            print("üìä YOLO DETECTION SUMMARY")
            print("="*80)
            print(f"Total frames processed: {total_frames}")
            print(f"Frames with bullseyes: {detection_frames}")
            print(f"Detection rate: {detection_rate:.1f}%")
            print(f"Processing time: {total_time:.1f}s")
            print(f"Average FPS: {stats.get('avg_fps', 0):.1f}")
            print(f"Average inference time: {stats.get('avg_inference_ms', 0):.1f}ms")

            if detection_frames > 0:
                print(f"üéØ SUCCESS: Bullseyes detected in {detection_frames} frames!")
            else:
                print("‚ùå NO BULLSEYES DETECTED in any frame")
            print("="*80)

            return True

    except Exception as e:
        logging.error(f"Error during YOLO bullseye detection test: {str(e)}")
        return False

def create_bullseye_detector(model_path="models/best.pt", confidence=0.5, imgsz=160):
    """
    Factory function to create a YOLO bullseye detector.

    Returns:
        BullseyeDetector instance
    """
    return BullseyeDetector(model_path, confidence, imgsz)


--- detection\camera.py ---
"""
Camera Module
------------
Functions for managing camera operations, including setup and testing.
"""

import cv2
import time
import logging
import os
import numpy as np

def initialize_camera(camera_id=0, resolution=(640, 480)):
    """
    Initialize the camera.

    Args:
        camera_id: Camera ID (default: 0 for primary camera)
        resolution: Tuple of (width, height) for desired resolution

    Returns:
        Initialized camera object or None if initialization failed
    """
    try:
        cap = cv2.VideoCapture(camera_id)

        # Set resolution
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, resolution[0])
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, resolution[1])

        # Check if camera opened successfully
        if not cap.isOpened():
            logging.error(f"Failed to open camera {camera_id}")
            return None

        # Read a test frame to confirm camera is working
        ret, _ = cap.read()
        if not ret:
            logging.error(f"Failed to read from camera {camera_id}")
            cap.release()
            return None

        logging.info(f"Camera {camera_id} initialized at resolution {resolution}")
        return cap
    except Exception as e:
        logging.error(f"Error initializing camera: {str(e)}")
        return None

def capture_frame(cap):
    """
    Capture a single frame from the camera.

    Args:
        cap: The initialized camera object

    Returns:
        Captured frame or None if capture failed
    """
    if not cap or not cap.isOpened():
        logging.error("Invalid camera object")
        return None

    try:
        ret, frame = cap.read()
        if not ret:
            logging.error("Failed to capture frame")
            return None

        return frame
    except Exception as e:
        logging.error(f"Error capturing frame: {str(e)}")
        return None

def save_frame(frame, output_dir="debug_frames", filename=None):
    """
    Save a frame to disk.

    Args:
        frame: The frame to save
        output_dir: Directory to save the frame
        filename: Filename (if None, use timestamp)

    Returns:
        Path to saved file or None if save failed
    """
    if frame is None:
        logging.error("Cannot save None frame")
        return None

    try:
        # Create output directory if it doesn't exist
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # Generate filename based on timestamp if not provided
        if filename is None:
            filename = f"frame_{time.strftime('%Y%m%d_%H%M%S')}.jpg"

        # Full path to save the frame
        file_path = os.path.join(output_dir, filename)

        # Save the frame
        cv2.imwrite(file_path, frame)
        logging.info(f"Frame saved to {file_path}")

        return file_path
    except Exception as e:
        logging.error(f"Error saving frame: {str(e)}")
        return None

def test_camera_feed(camera_id=0, duration=10, show_preview=True):
    """
    Test the camera by capturing frames for a specified duration.

    Args:
        camera_id: Camera ID
        duration: Test duration in seconds
        show_preview: Whether to show preview window

    Returns:
        True if test was successful, False otherwise
    """
    try:
        cap = initialize_camera(camera_id)
        if not cap:
            return False

        start_time = time.time()
        frame_count = 0

        logging.info(f"Starting camera test for {duration} seconds")

        # Create debug directory if showing preview
        debug_dir = "debug_frames"
        if not os.path.exists(debug_dir):
            os.makedirs(debug_dir)

        while time.time() - start_time < duration:
            frame = capture_frame(cap)
            if frame is None:
                break

            frame_count += 1

            # Add frame counter and timestamp
            timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
            cv2.putText(frame, f"Frame: {frame_count} Time: {timestamp}",
                      (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            # Display the frame if preview is enabled
            if show_preview:
                cv2.imshow('Camera Test', frame)

                # Break the loop if 'q' is pressed
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            # Save every 30th frame
            if frame_count % 30 == 0:
                save_frame(frame, debug_dir, f"test_{frame_count}.jpg")

        # Calculate FPS
        elapsed_time = time.time() - start_time
        fps = frame_count / elapsed_time if elapsed_time > 0 else 0

        # Clean up
        cap.release()
        if show_preview:
            cv2.destroyAllWindows()

        logging.info(f"Camera test completed. Captured {frame_count} frames in {elapsed_time:.1f} seconds ({fps:.1f} FPS)")
        return frame_count > 0
    except Exception as e:
        logging.error(f"Error during camera test: {str(e)}")
        return False

def close_camera(cap):
    """
    Safely release the camera resource.

    Args:
        cap: The camera object to close
    """
    if cap and cap.isOpened():
        try:
            cap.release()
            logging.info("Camera released")
        except Exception as e:
            logging.error(f"Error releasing camera: {str(e)}")

def adjust_camera_settings(cap, brightness=None, contrast=None, saturation=None,
                         exposure=None, auto_exposure=None):
    """
    Adjust camera settings like brightness, contrast, etc.

    Args:
        cap: The initialized camera object
        brightness: Brightness value (typically 0-100)
        contrast: Contrast value (typically 0-100)
        saturation: Saturation value (typically 0-100)
        exposure: Exposure value
        auto_exposure: Auto exposure mode (0: manual, 1: auto)

    Returns:
        True if settings were adjusted successfully, False otherwise
    """
    if not cap or not cap.isOpened():
        logging.error("Invalid camera object")
        return False

    try:
        # Set brightness if specified
        if brightness is not None:
            cap.set(cv2.CAP_PROP_BRIGHTNESS, brightness)
            logging.info(f"Camera brightness set to {brightness}")

        # Set contrast if specified
        if contrast is not None:
            cap.set(cv2.CAP_PROP_CONTRAST, contrast)
            logging.info(f"Camera contrast set to {contrast}")

        # Set saturation if specified
        if saturation is not None:
            cap.set(cv2.CAP_PROP_SATURATION, saturation)
            logging.info(f"Camera saturation set to {saturation}")

        # Set auto exposure mode if specified
        if auto_exposure is not None:
            cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, auto_exposure)
            logging.info(f"Camera auto exposure set to {auto_exposure}")

        # Set exposure if specified and auto exposure is off
        if exposure is not None and (auto_exposure is None or auto_exposure == 0):
            cap.set(cv2.CAP_PROP_EXPOSURE, exposure)
            logging.info(f"Camera exposure set to {exposure}")

        return True
    except Exception as e:
        logging.error(f"Error adjusting camera settings: {str(e)}")
        return False

def get_camera_properties(cap):
    """
    Get current camera properties.

    Args:
        cap: The initialized camera object

    Returns:
        Dictionary of camera properties or None if failed
    """
    if not cap or not cap.isOpened():
        logging.error("Invalid camera object")
        return None

    try:
        properties = {
            "width": cap.get(cv2.CAP_PROP_FRAME_WIDTH),
            "height": cap.get(cv2.CAP_PROP_FRAME_HEIGHT),
            "fps": cap.get(cv2.CAP_PROP_FPS),
            "brightness": cap.get(cv2.CAP_PROP_BRIGHTNESS),
            "contrast": cap.get(cv2.CAP_PROP_CONTRAST),
            "saturation": cap.get(cv2.CAP_PROP_SATURATION),
            "exposure": cap.get(cv2.CAP_PROP_EXPOSURE),
            "auto_exposure": cap.get(cv2.CAP_PROP_AUTO_EXPOSURE)
        }

        logging.info("Retrieved camera properties")
        return properties
    except Exception as e:
        logging.error(f"Error getting camera properties: {str(e)}")
        return None

def list_available_cameras(max_cameras=10):
    """
    List available cameras by trying to open each one.

    Args:
        max_cameras: Maximum number of cameras to check

    Returns:
        List of available camera IDs
    """
    available_cameras = []

    for i in range(max_cameras):
        try:
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                ret, _ = cap.read()
                if ret:
                    available_cameras.append(i)
                cap.release()
        except:
            pass

    if available_cameras:
        logging.info(f"Found {len(available_cameras)} available cameras: {available_cameras}")
    else:
        logging.warning("No available cameras found")

    return available_cameras


--- detection\gcp_yolo_detector.py ---
# detection/gcp_yolo_detector.py - UPDATED WITH LAYERED DETECTION
"""
GCP YOLO Detection Test Module - Enhanced with Layered Detection
---------------------------------------------------------------
Updated to perform layered detection: first check for numbered markers,
then fallback to general markers if confidence is low.
"""

import cv2
import numpy as np
import logging
import time
import os
from typing import List, Tuple, Optional, Union, Dict
from pathlib import Path

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    logging.warning("YOLO not available - install ultralytics: pip install ultralytics")

class GCPYOLODetector:
    """YOLO-based GCP detector with layered detection system"""

    def __init__(self, model_path="models/best-gcp.pt", confidence_threshold=0.5,
                 numbered_confidence_threshold=0.4, imgsz=160):
        """
        Initialize the GCP detector with YOLO model.

        Args:
            model_path: Path to GCP YOLO model file
            confidence_threshold: Minimum confidence for general marker detections
            numbered_confidence_threshold: Lower threshold for numbered marker detection layer
            imgsz: Model input image size
        """
        if not YOLO_AVAILABLE:
            raise ImportError("YOLO not available. Install with: pip install ultralytics")

        self.model_path = model_path
        self.conf_threshold = confidence_threshold
        self.numbered_conf_threshold = numbered_confidence_threshold
        self.imgsz = imgsz

        # Try to load the model
        if not os.path.exists(model_path):
            logging.error(f"GCP model file not found: {model_path}")
            # Try common locations
            alt_paths = [
                "best-gcp.pt",
                "models/best-gcp.pt",
                "best-gcp.engine",
                "models/best-gcp.engine"
            ]
            for alt_path in alt_paths:
                if os.path.exists(alt_path):
                    self.model_path = alt_path
                    logging.info(f"Found GCP model at: {alt_path}")
                    break
            else:
                raise FileNotFoundError(f"Could not find GCP model file. Tried: {model_path}, {alt_paths}")

        logging.info(f"Loading GCP YOLO model: {self.model_path}")
        logging.info(f"General marker confidence threshold: {self.conf_threshold}")
        logging.info(f"Numbered marker confidence threshold: {self.numbered_conf_threshold}")
        self.model = YOLO(self.model_path)

        # Performance tracking
        self.frame_count = 0
        self.total_inference_time = 0
        self.detections_count = 0
        self.layered_detection_count = 0

    def detect_gcp_markers_in_frame(self, frame):
        """
        Detect GCP markers in a single frame using improved detection with NMS.

        IMPROVED LOGIC:
        1. Run inference with standard confidence threshold
        2. Apply Non-Maximum Suppression to remove overlapping detections
        3. For 'markers' class detections, also check if they might be numbered markers
        4. Keep only the best detection per physical marker

        Args:
            frame: Input BGR image

        Returns:
            Tuple of (gcp_markers, debug_image)
            gcp_markers: List of (class_name, center_x, center_y, bbox_info, confidence)
            debug_image: Annotated image showing detections
        """
        if frame is None:
            return [], frame

        try:
            start_time = time.time()

            # Run inference with standard confidence threshold
            results = self.model.predict(
                frame,
                imgsz=self.imgsz,
                conf=self.conf_threshold,
                verbose=False
            )

            inference_time = time.time() - start_time
            self.total_inference_time += inference_time
            self.frame_count += 1

            # Process results and remove overlapping detections
            all_detections = []
            debug_image = frame.copy()

            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        # Extract box coordinates and confidence
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        confidence = float(box.conf[0])
                        class_id = int(box.cls[0])

                        # Get class name
                        class_name = result.names[class_id] if hasattr(result, 'names') else f"class_{class_id}"

                        # Only keep detections that meet confidence requirements
                        if class_name == 'marker-numbered' and confidence >= self.numbered_conf_threshold:
                            use_detection = True
                        elif class_name == 'markers' and confidence >= self.conf_threshold:
                            use_detection = True
                        else:
                            use_detection = False

                        if use_detection:
                            # Calculate center
                            center_x = (x1 + x2) // 2
                            center_y = (y1 + y2) // 2

                            # Store detection for overlap removal
                            all_detections.append({
                                'class': class_name,
                                'bbox': (x1, y1, x2, y2),
                                'center': (center_x, center_y),
                                'confidence': confidence,
                                'area': (x2 - x1) * (y2 - y1)
                            })

            # Remove overlapping detections using distance-based NMS
            final_detections = self._remove_overlapping_detections(all_detections)

            # LAYERED CHECK: For remaining 'markers', see if they should be 'marker-numbered'
            enhanced_detections = self._enhance_marker_classification(final_detections, frame)

            # Convert to final format and draw
            gcp_markers = []
            for detection in enhanced_detections:
                class_name = detection['class']
                center_x, center_y = detection['center']
                bbox = detection['bbox']
                confidence = detection['confidence']

                bbox_info = {
                    'bbox': bbox,
                    'width': bbox[2] - bbox[0],
                    'height': bbox[3] - bbox[1],
                    'area': detection['area']
                }

                gcp_markers.append((class_name, center_x, center_y, bbox_info, confidence))
                self.detections_count += 1

                # Draw on debug image
                x1, y1, x2, y2 = bbox
                self._draw_detection(debug_image, x1, y1, x2, y2, center_x, center_y,
                                   class_name, confidence)

            # Add frame info to debug image
            self._add_frame_info(debug_image, len(gcp_markers), inference_time)

            return gcp_markers, debug_image

        except Exception as e:
            logging.error(f"Error in GCP YOLO detection: {str(e)}")
            return [], frame

    def _remove_overlapping_detections(self, detections, overlap_threshold=0.3):
        """
        Remove overlapping detections using distance-based approach.

        Args:
            detections: List of detection dictionaries
            overlap_threshold: IoU threshold for considering detections as overlapping

        Returns:
            List of non-overlapping detections
        """
        if len(detections) <= 1:
            return detections

        # Sort by confidence (highest first)
        sorted_detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
        final_detections = []

        for current_det in sorted_detections:
            is_overlapping = False

            for kept_det in final_detections:
                # Calculate IoU (Intersection over Union)
                iou = self._calculate_iou(current_det['bbox'], kept_det['bbox'])

                if iou > overlap_threshold:
                    is_overlapping = True
                    break

            if not is_overlapping:
                final_detections.append(current_det)

        logging.debug(f"Removed {len(detections) - len(final_detections)} overlapping detections")
        return final_detections

    def _calculate_iou(self, bbox1, bbox2):
        """Calculate Intersection over Union (IoU) of two bounding boxes."""
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2

        # Calculate intersection area
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)

        if x2_i <= x1_i or y2_i <= y1_i:
            return 0.0

        intersection_area = (x2_i - x1_i) * (y2_i - y1_i)

        # Calculate union area
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = area1 + area2 - intersection_area

        return intersection_area / union_area if union_area > 0 else 0.0

    def _enhance_marker_classification(self, detections, frame):
        """
        For 'markers' class detections, check if they should be 'marker-numbered'.
        This runs a secondary check with lower confidence on the cropped region.
        """
        enhanced_detections = []

        for detection in detections:
            if detection['class'] == 'markers':
                # Crop the region and re-run detection with lower threshold
                x1, y1, x2, y2 = detection['bbox']

                # Add padding to crop
                padding = 10
                h, w = frame.shape[:2]
                x1_crop = max(0, x1 - padding)
                y1_crop = max(0, y1 - padding)
                x2_crop = min(w, x2 + padding)
                y2_crop = min(h, y2 + padding)

                cropped_region = frame[y1_crop:y2_crop, x1_crop:x2_crop]

                if cropped_region.size > 0:
                    # Re-run detection on cropped region with lower threshold
                    crop_results = self.model.predict(
                        cropped_region,
                        imgsz=self.imgsz,
                        conf=self.numbered_conf_threshold,
                        verbose=False
                    )

                    # Check if any numbered markers found in crop
                    found_numbered = False
                    best_numbered_conf = 0

                    for result in crop_results:
                        if result.boxes is not None:
                            for box in result.boxes:
                                class_id = int(box.cls[0])
                                class_name = result.names[class_id] if hasattr(result, 'names') else f"class_{class_id}"
                                confidence = float(box.conf[0])

                                if class_name == 'marker-numbered' and confidence >= self.numbered_conf_threshold:
                                    found_numbered = True
                                    best_numbered_conf = max(best_numbered_conf, confidence)

                    # If numbered marker found in crop, upgrade the classification
                    if found_numbered:
                        detection['class'] = 'marker-numbered'
                        detection['confidence'] = max(detection['confidence'], best_numbered_conf)
                        self.layered_detection_count += 1
                        logging.debug(f"Enhanced general marker to numbered marker (conf: {best_numbered_conf:.3f})")

            enhanced_detections.append(detection)

        return enhanced_detections

    def _draw_detection(self, image, x1, y1, x2, y2, center_x, center_y, class_name, confidence):
        """Draw detection on image"""
        # Color coding: green for 'markers', red for 'marker-numbered'
        if class_name == 'markers':
            color = (0, 255, 0)  # Green
            thickness = 2
        elif class_name == 'marker-numbered':
            color = (0, 0, 255)  # Red
            thickness = 3
        else:
            color = (255, 0, 255)  # Magenta for unknown classes
            thickness = 2

        # Draw bounding box
        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)

        # Draw center point
        cv2.circle(image, (center_x, center_y), 8, color, -1)
        cv2.circle(image, (center_x, center_y), 12, (255, 255, 255), 2)

        # Draw crosshair at center
        cv2.line(image, (center_x - 15, center_y), (center_x + 15, center_y), color, 2)
        cv2.line(image, (center_x, center_y - 15), (center_x, center_y + 15), color, 2)

        # Add confidence label
        label = f"{class_name}: {confidence:.3f}"
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
        cv2.rectangle(image, (x1, y1 - label_size[1] - 10),
                     (x1 + label_size[0], y1), color, -1)
        cv2.putText(image, label, (x1, y1 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    def _add_frame_info(self, image, num_detections, inference_time):
        """Add frame information overlay"""
        # Calculate FPS
        fps = 1.0 / inference_time if inference_time > 0 else 0

        # Add frame info
        info_text = f"GCP FPS: {fps:.1f} | Detections: {num_detections} | Frame: {self.frame_count}"
        cv2.putText(image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)

        # Add detection breakdown with correct counts
        # Note: gcp_markers should be passed to this function to get accurate counts
        breakdown = f"Total: {num_detections} | Layered Enhancements: {self.layered_detection_count}"
        cv2.putText(image, breakdown, (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(image, breakdown, (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

        # Add crosshair at frame center for drone alignment reference
        h, w = image.shape[:2]
        cv2.line(image, (w//2 - 20, h//2), (w//2 + 20, h//2), (0, 255, 255), 2)
        cv2.line(image, (w//2, h//2 - 20), (w//2, h//2 + 20), (0, 255, 255), 2)
        cv2.circle(image, (w//2, h//2), 3, (0, 255, 255), -1)

    def get_performance_stats(self):
        """Get performance statistics"""
        if self.frame_count == 0:
            return {}

        avg_fps = self.frame_count / self.total_inference_time if self.total_inference_time > 0 else 0
        avg_inference_ms = (self.total_inference_time / self.frame_count) * 1000

        return {
            'total_frames': self.frame_count,
            'total_detections': self.detections_count,
            'layered_detections': self.layered_detection_count,
            'avg_detections_per_frame': self.detections_count / self.frame_count,
            'avg_fps': avg_fps,
            'avg_inference_ms': avg_inference_ms
        }

def create_enhanced_gcp_display(original_frame, gcp_markers, debug_image):
    """
    Create enhanced display with big indicators for GCP detections.
    """
    enhanced = debug_image.copy()
    height, width = enhanced.shape[:2]

    # Count detection types
    markers_count = sum(1 for marker in gcp_markers if marker[0] == 'markers')
    numbered_count = sum(1 for marker in gcp_markers if marker[0] == 'marker-numbered')
    total_detections = len(gcp_markers)

    # Add detection indicators
    if total_detections > 0:
        # Determine primary detection type for color coding
        if numbered_count > 0:
            # Numbered markers found - highest priority (red theme)
            overlay = enhanced.copy()
            cv2.rectangle(overlay, (0, 0), (width, 100), (0, 0, 150), -1)
            enhanced = cv2.addWeighted(enhanced, 0.7, overlay, 0.3, 0)

            cv2.putText(enhanced, f"üî¢ NUMBERED MARKERS DETECTED! ({numbered_count} found)",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
            cv2.putText(enhanced, f"üî¢ NUMBERED MARKERS DETECTED! ({numbered_count} found)",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 2)

            if markers_count > 0:
                cv2.putText(enhanced, f"üìç Also found {markers_count} general marker(s) for investigation",
                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        elif markers_count > 0:
            # General markers found (green theme)
            overlay = enhanced.copy()
            cv2.rectangle(overlay, (0, 0), (width, 80), (0, 150, 0), -1)
            enhanced = cv2.addWeighted(enhanced, 0.7, overlay, 0.3, 0)

            cv2.putText(enhanced, f"üìç MARKERS DETECTED! ({markers_count} found)",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
            cv2.putText(enhanced, f"üìç MARKERS DETECTED! ({markers_count} found)",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)

        # Draw big circles around numbered markers (highest priority)
        for class_name, center_x, center_y, bbox_info, confidence in gcp_markers:
            if class_name == 'marker-numbered':
                # Big outer circle for numbered markers
                cv2.circle(enhanced, (center_x, center_y), 100, (0, 0, 255), 5)
                # Inner circle
                cv2.circle(enhanced, (center_x, center_y), 50, (255, 255, 255), 3)
            elif class_name == 'markers':
                # Medium circle for general markers
                cv2.circle(enhanced, (center_x, center_y), 80, (0, 255, 0), 4)

    else:
        # No detections found
        overlay = enhanced.copy()
        cv2.rectangle(overlay, (0, 0), (width, 60), (0, 0, 150), -1)
        enhanced = cv2.addWeighted(enhanced, 0.8, overlay, 0.2, 0)

        cv2.putText(enhanced, "üîç NO GCP MARKERS DETECTED",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)
        cv2.putText(enhanced, "üîç NO GCP MARKERS DETECTED",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

    return enhanced

def test_gcp_yolo_detection(source: Union[str, int] = 0,
                           display: bool = True,
                           save_results: bool = True,
                           duration: float = 0,
                           video_delay: float = 0.1,
                           model_path: str = "models/best-gcp.pt",
                           confidence: float = 0.5,
                           numbered_confidence: float = 0.4,
                           imgsz: int = 160) -> bool:
    """
    Test GCP YOLO detection with layered detection system.

    Args:
        source: Camera ID (int), video file path, or image file path
        display: Whether to display the detection results
        save_results: Whether to save detection results
        duration: Duration for camera/video (0 = until 'q' pressed)
        video_delay: Delay between frames for video/camera (seconds)
        model_path: Path to GCP YOLO model file
        confidence: Confidence threshold for general markers
        numbered_confidence: Lower confidence threshold for numbered markers
        imgsz: Model input image size

    Returns:
        True if test completed successfully
    """
    try:
        logging.info(f"Starting GCP YOLO detection test with layered detection")
        logging.info(f"Source: {source}")
        logging.info(f"General marker confidence: {confidence}")
        logging.info(f"Numbered marker confidence: {numbered_confidence}")

        detector = GCPYOLODetector(
            model_path=model_path,
            confidence_threshold=confidence,
            numbered_confidence_threshold=numbered_confidence,
            imgsz=imgsz
        )

        # Determine source type
        if isinstance(source, int):
            # Camera input
            cap = cv2.VideoCapture(source)
            if not cap.isOpened():
                logging.error(f"Failed to open camera {source}")
                return False

            # Set camera properties for drone use
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)
            source_type = "camera"

        elif isinstance(source, str):
            if source.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                # Image file
                image = cv2.imread(source)
                if image is None:
                    logging.error(f"Failed to load image: {source}")
                    return False
                source_type = "image"
            else:
                # Video file
                cap = cv2.VideoCapture(source)
                if not cap.isOpened():
                    logging.error(f"Failed to open video: {source}")
                    return False
                source_type = "video"
        else:
            logging.error("Invalid source type")
            return False

        # Process single image
        if source_type == "image":
            gcp_markers, debug_image = detector.detect_gcp_markers_in_frame(image)

            # Create enhanced display image
            enhanced_image = create_enhanced_gcp_display(image, gcp_markers, debug_image)

            logging.info(f"Detected {len(gcp_markers)} GCP markers in image")
            markers_count = sum(1 for marker in gcp_markers if marker[0] == 'markers')
            numbered_count = sum(1 for marker in gcp_markers if marker[0] == 'marker-numbered')

            for i, (class_name, x, y, bbox_info, confidence) in enumerate(gcp_markers):
                logging.info(f"GCP {i+1}: {class_name} at ({x}, {y}), Confidence: {confidence:.3f}")

            if display:
                cv2.imshow("GCP YOLO Detection Results", enhanced_image)
                print("\n" + "="*60)
                print("üì∏ GCP IMAGE DETECTION RESULTS (LAYERED)")
                print("="*60)
                if len(gcp_markers) > 0:
                    print(f"üéØ GCP MARKERS FOUND: {len(gcp_markers)}")
                    print(f"   üìç General markers: {markers_count}")
                    print(f"   üî¢ Numbered markers: {numbered_count}")
                    for i, (class_name, x, y, bbox_info, confidence) in enumerate(gcp_markers):
                        print(f"     {class_name} {i+1}: Position ({x}, {y}), Confidence: {confidence:.1%}")
                else:
                    print("‚ùå NO GCP MARKERS DETECTED")
                print("="*60)
                print("Press any key to close...")
                cv2.waitKey(0)
                cv2.destroyAllWindows()

            if save_results:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f"gcp_layered_detection_{timestamp}.jpg"
                cv2.imwrite(filename, enhanced_image)
                logging.info(f"Results saved to: {filename}")

            return True

        # Process video or camera feed
        else:
            total_frames = 0
            detection_frames = 0
            markers_detected = 0
            numbered_detected = 0
            start_time = time.time()

            if source_type == "video":
                total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                video_fps = cap.get(cv2.CAP_PROP_FPS)
                logging.info(f"Video: {total_video_frames} frames @ {video_fps} FPS")

            logging.info(f"Processing {source_type}. Press 'q' to quit, 's' to save frame")
            print("\n" + "="*80)
            print(f"üé• {source_type.upper()} GCP LAYERED DETECTION")
            print("="*80)
            print("Controls: 'q' = quit, 's' = save frame, 'p' = pause")
            print("="*80)

            while True:
                ret, frame = cap.read()

                if not ret:
                    if source_type == "camera":
                        logging.error("Failed to capture frame")
                        break
                    else:
                        logging.info("End of video reached")
                        break

                total_frames += 1

                # Detect GCP markers
                gcp_markers, debug_image = detector.detect_gcp_markers_in_frame(frame)

                # Create enhanced display
                enhanced_image = create_enhanced_gcp_display(frame, gcp_markers, debug_image)

                # Track detections
                if gcp_markers:
                    detection_frames += 1
                    frame_markers = sum(1 for marker in gcp_markers if marker[0] == 'markers')
                    frame_numbered = sum(1 for marker in gcp_markers if marker[0] == 'marker-numbered')

                    markers_detected += frame_markers
                    numbered_detected += frame_numbered

                    print(f"üéØ Frame {total_frames}: {len(gcp_markers)} GCP marker(s) detected!")
                    if frame_numbered > 0:
                        print(f"   üî¢ NUMBERED MARKERS: {frame_numbered}")
                    if frame_markers > 0:
                        print(f"   üìç GENERAL MARKERS: {frame_markers}")

                    for i, (class_name, x, y, bbox_info, confidence) in enumerate(gcp_markers):
                        print(f"     ‚Üí {class_name} at ({x}, {y}), confidence: {confidence:.3f}")

                elif total_frames % 30 == 0:  # Log every 30 frames when no detection
                    print(f"üîç Frame {total_frames}: Searching for GCP markers...")

                # Display results
                if display:
                    cv2.imshow("GCP YOLO Layered Detection", enhanced_image)

                    key = cv2.waitKey(int(video_delay * 1000)) & 0xFF
                    if key == ord('q'):
                        break
                    elif key == ord('s') and save_results:
                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                        filename = f"gcp_layered_frame_{total_frames}_{timestamp}.jpg"
                        cv2.imwrite(filename, enhanced_image)
                        logging.info(f"Frame saved: {filename}")
                    elif key == ord('p'):  # Pause
                        cv2.waitKey(0)
                else:
                    time.sleep(video_delay)

                # Check duration for camera
                if source_type == "camera" and duration > 0:
                    if time.time() - start_time >= duration:
                        break

                # Progress for video
                if source_type == "video" and total_frames % 30 == 0:
                    progress = (total_frames / total_video_frames) * 100
                    print(f"Progress: {progress:.1f}% ({total_frames}/{total_video_frames})")

            # Cleanup
            cap.release()
            if display:
                cv2.destroyAllWindows()

            # Final summary
            total_time = time.time() - start_time
            detection_rate = (detection_frames / total_frames * 100) if total_frames > 0 else 0
            stats = detector.get_performance_stats()

            print("\n" + "="*80)
            print("üìä GCP LAYERED DETECTION SUMMARY")
            print("="*80)
            print(f"Total frames processed: {total_frames}")
            print(f"Frames with GCP markers: {detection_frames}")
            print(f"Detection rate: {detection_rate:.1f}%")
            print(f"Processing time: {total_time:.1f}s")
            print(f"Average FPS: {stats.get('avg_fps', 0):.1f}")
            print(f"Average inference time: {stats.get('avg_inference_ms', 0):.1f}ms")
            print(f"Layered detections: {stats.get('layered_detections', 0)}")

            # Detection breakdown
            print(f"\nDetection Breakdown:")
            print(f"  üìç General markers detected: {markers_detected}")
            print(f"  üî¢ Numbered markers detected: {numbered_detected}")

            if detection_frames > 0:
                print(f"üéØ SUCCESS: GCP markers detected in {detection_frames} frames!")
                if numbered_detected > 0:
                    print(f"üî¢ NUMBERED MARKERS FOUND: {numbered_detected} total detections!")
                if markers_detected > 0:
                    print(f"üìç GENERAL MARKERS FOUND: {markers_detected} total detections!")
            else:
                print("‚ùå NO GCP MARKERS DETECTED in any frame")
            print("="*80)

            return True

    except Exception as e:
        logging.error(f"Error during GCP YOLO detection test: {str(e)}")
        return False

def create_gcp_yolo_detector(model_path="models/best-gcp.pt", confidence=0.5,
                            numbered_confidence=0.4, imgsz=160):
    """
    Factory function to create a GCP YOLO detector with layered detection.

    Returns:
        GCPYOLODetector instance
    """
    return GCPYOLODetector(model_path, confidence, numbered_confidence, imgsz)


--- detection\video_recorder.py ---
# detection/video_recorder.py - NEW MODULE
"""
Video Recording Module
---------------------
Functions for recording camera footage during missions.
"""

import cv2
import time
import logging
import os
import threading
from datetime import datetime
from typing import Optional

class VideoRecorder:
    """Video recorder class for mission recording"""

    def __init__(self, output_dir="recordings", fps=30.0, codec='XVID'):
        self.output_dir = output_dir
        self.fps = fps
        self.codec = codec
        self.recording = False
        self.writer = None
        self.cap = None
        self.record_thread = None
        self.current_filename = None

        # Create output directory
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

    def start_recording(self, camera_id=0, resolution=(640, 480), mission_name="mission"):
        """
        Start recording video from camera.

        Args:
            camera_id: Camera ID to record from
            resolution: Video resolution (width, height)
            mission_name: Name of mission for filename

        Returns:
            True if recording started successfully
        """
        if self.recording:
            logging.warning("Recording already in progress")
            return False

        try:
            # Initialize camera
            self.cap = cv2.VideoCapture(camera_id)
            if not self.cap.isOpened():
                logging.error(f"Failed to open camera {camera_id}")
                return False

            # Set camera resolution
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, resolution[0])
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, resolution[1])
            self.cap.set(cv2.CAP_PROP_FPS, self.fps)

            # Test frame capture
            ret, frame = self.cap.read()
            if not ret:
                logging.error("Failed to capture test frame")
                self.cap.release()
                return False

            # Generate filename with timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.current_filename = f"{mission_name}_{timestamp}.avi"
            full_path = os.path.join(self.output_dir, self.current_filename)

            # Initialize video writer
            fourcc = cv2.VideoWriter_fourcc(*self.codec)
            actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

            self.writer = cv2.VideoWriter(full_path, fourcc, self.fps, (actual_width, actual_height))

            if not self.writer.isOpened():
                logging.error("Failed to initialize video writer")
                self.cap.release()
                return False

            # Start recording thread
            self.recording = True
            self.record_thread = threading.Thread(target=self._record_loop)
            self.record_thread.daemon = True
            self.record_thread.start()

            logging.info(f"Recording started: {full_path}")
            logging.info(f"Resolution: {actual_width}x{actual_height} @ {self.fps} FPS")

            return True

        except Exception as e:
            logging.error(f"Error starting recording: {str(e)}")
            self.cleanup()
            return False

    def _record_loop(self):
        """Main recording loop (runs in separate thread)"""
        frame_count = 0
        start_time = time.time()

        try:
            while self.recording and self.cap and self.cap.isOpened():
                ret, frame = self.cap.read()

                if not ret:
                    logging.warning("Failed to capture frame, stopping recording")
                    break

                # Write frame to video file
                if self.writer:
                    self.writer.write(frame)
                    frame_count += 1

                # Brief sleep to prevent 100% CPU usage
                time.sleep(0.001)

        except Exception as e:
            logging.error(f"Error in recording loop: {str(e)}")

        # Calculate recording stats
        duration = time.time() - start_time
        actual_fps = frame_count / duration if duration > 0 else 0

        logging.info(f"Recording stopped: {frame_count} frames in {duration:.1f}s ({actual_fps:.1f} FPS)")

    def stop_recording(self):
        """Stop recording and save file"""
        if not self.recording:
            logging.warning("No recording in progress")
            return False

        try:
            self.recording = False

            # Wait for recording thread to finish
            if self.record_thread:
                self.record_thread.join(timeout=5)

            self.cleanup()

            if self.current_filename:
                full_path = os.path.join(self.output_dir, self.current_filename)
                if os.path.exists(full_path):
                    file_size = os.path.getsize(full_path) / (1024 * 1024)  # MB
                    logging.info(f"Recording saved: {full_path} ({file_size:.1f} MB)")
                    return True
                else:
                    logging.error("Recording file not found after stopping")
                    return False

            return True

        except Exception as e:
            logging.error(f"Error stopping recording: {str(e)}")
            return False

    def cleanup(self):
        """Clean up resources"""
        try:
            if self.writer:
                self.writer.release()
                self.writer = None

            if self.cap:
                self.cap.release()
                self.cap = None

        except Exception as e:
            logging.error(f"Error during cleanup: {str(e)}")

    def is_recording(self):
        """Check if currently recording"""
        return self.recording

    def get_current_filename(self):
        """Get current recording filename"""
        return self.current_filename

def create_video_recorder(output_dir="recordings", fps=30.0, codec='XVID'):
    """
    Factory function to create a video recorder.

    Args:
        output_dir: Directory to save recordings
        fps: Frames per second
        codec: Video codec ('XVID', 'MJPG', 'H264')

    Returns:
        VideoRecorder instance
    """
    return VideoRecorder(output_dir, fps, codec)

def test_video_recording(camera_id=0, duration=10, output_dir="test_recordings"):
    """
    Test video recording functionality.

    Args:
        camera_id: Camera ID to use
        duration: Recording duration in seconds
        output_dir: Output directory for test recording

    Returns:
        True if test successful
    """
    try:
        logging.info(f"Testing video recording for {duration} seconds")

        recorder = create_video_recorder(output_dir)

        # Start recording
        if not recorder.start_recording(camera_id, mission_name="test"):
            logging.error("Failed to start test recording")
            return False

        # Record for specified duration
        time.sleep(duration)

        # Stop recording
        if not recorder.stop_recording():
            logging.error("Failed to stop test recording")
            return False

        logging.info("Video recording test completed successfully")
        return True

    except Exception as e:
        logging.error(f"Error during video recording test: {str(e)}")
        return False


--- docs\old\delivery.py ---
"""
Package Delivery Missions Module
-----------------------------
Functions for executing package delivery missions using pymavlink.
"""

import logging
import time
import math
from threading import Thread
import cv2
from pymavlink import mavutil

from drone.connection import get_vehicle_state  # Corrected import location
from drone.navigation import (
    arm_and_takeoff, get_location, navigate_to_waypoint,
    return_to_launch, send_ned_velocity
)
from drone.servo import operate_package_release, operate_claw
from detection.models import load_detection_model, run_detection, process_detection_results
from detection.camera import initialize_camera, capture_frame, close_camera
from detection.gcp import detect_gcp_markers

def align_to_target(vehicle, target_x, target_y, camera_x, camera_y, timeout=30):
    """
    Align the drone to a detected target.

    Args:
        vehicle: The connected mavlink object
        target_x: Target X coordinate in the image
        target_y: Target Y coordinate in the image
        camera_x: Camera center X coordinate
        camera_y: Camera center Y coordinate
        timeout: Maximum alignment time in seconds

    Returns:
        True if alignment was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Aligning drone to target")

        # Calculate offset
        offset_x = target_x - camera_x
        offset_y = target_y - camera_y

        # Define alignment threshold (pixels)
        threshold = 20

        # Start alignment timer
        start_time = time.time()

        while (abs(offset_x) > threshold or abs(offset_y) > threshold) and time.time() - start_time < timeout:
            logging.info(f"Target offset: X={offset_x}, Y={offset_y}")

            # Calculate velocity based on offset
            # Note: X offset maps to Y velocity, Y offset maps to X velocity in camera frame
            # Scale velocity based on how far we are from the target (proportional control)
            velocity_scale = 0.2  # m/s maximum speed
            velocity_x = velocity_scale * (offset_y / max(abs(offset_y), 100)) if abs(offset_y) > threshold else 0
            velocity_y = velocity_scale * (offset_x / max(abs(offset_x), 100)) if abs(offset_x) > threshold else 0

            logging.info(f"Adjustment velocity: X={velocity_x}, Y={velocity_y}")

            # Send velocity command
            send_ned_velocity(vehicle, velocity_x, velocity_y, 0, 1)

            # Wait for drone to move
            time.sleep(1)

            # Recalculate offset (this would come from detection thread in practice)
            # This is a stub - in a real implementation, you'd get updated coordinates
            # from the detection system
            offset_x = offset_x * 0.7  # Simulate getting closer
            offset_y = offset_y * 0.7  # Simulate getting closer

        if time.time() - start_time >= timeout:
            logging.warning("Alignment timed out")
            return False

        logging.info("Drone aligned to target")
        return True
    except Exception as e:
        logging.error(f"Error during target alignment: {str(e)}")
        return False

def lower_to_delivery_height(vehicle, target_height, speed=0.5):
    """
    Lower the drone to a delivery height.

    Args:
        vehicle: The connected mavlink object
        target_height: Target height in meters
        speed: Descent speed in m/s

    Returns:
        True if lowering was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Get current height
        state = get_vehicle_state(vehicle)
        if not state or state['altitude'] is None:
            logging.error("Could not get current altitude")
            return False

        current_height = state['altitude']

        logging.info(f"Lowering drone from {current_height}m to {target_height}m")

        # Calculate descent distance
        descent_distance = current_height - target_height
        if descent_distance <= 0:
            logging.warning("Already at or below target height")
            return True

        # Calculate descent time
        descent_time = descent_distance / speed

        # Send descent velocity command (positive Z is down)
        send_ned_velocity(vehicle, 0, 0, speed, descent_time)

        # Wait for drone to reach target height
        timeout = descent_time + 5  # Add safety margin
        start_time = time.time()

        while time.time() - start_time < timeout:
            state = get_vehicle_state(vehicle)
            if state and state['altitude'] is not None:
                current_alt = state['altitude']
                logging.info(f"Current altitude: {current_alt}m")

                if current_alt <= target_height + 0.5:  # Allow 0.5m tolerance
                    logging.info(f"Reached delivery height: {current_alt}m")
                    return True

            time.sleep(1)

        logging.warning("Lowering timed out")
        return False
    except Exception as e:
        logging.error(f"Error during lowering: {str(e)}")
        return False

def raise_to_safe_height(vehicle, target_height, speed=0.5):
    """
    Raise the drone to a safe height after delivery.

    Args:
        vehicle: The connected mavlink object
        target_height: Target height in meters
        speed: Ascent speed in m/s

    Returns:
        True if raising was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Get current height
        state = get_vehicle_state(vehicle)
        if not state or state['altitude'] is None:
            logging.error("Could not get current altitude")
            return False

        current_height = state['altitude']

        logging.info(f"Raising drone from {current_height}m to {target_height}m")

        # Calculate ascent distance
        ascent_distance = target_height - current_height
        if ascent_distance <= 0:
            logging.warning("Already at or above target height")
            return True

        # Calculate ascent time
        ascent_time = ascent_distance / speed

        # Send ascent velocity command (negative Z is up)
        send_ned_velocity(vehicle, 0, 0, -speed, ascent_time)

        # Wait for drone to reach target height
        timeout = ascent_time + 5  # Add safety margin
        start_time = time.time()

        while time.time() - start_time < timeout:
            state = get_vehicle_state(vehicle)
            if state and state['altitude'] is not None:
                current_alt = state['altitude']
                logging.info(f"Current altitude: {current_alt}m")

                if current_alt >= target_height - 0.5:  # Allow 0.5m tolerance
                    logging.info(f"Reached safe height: {current_alt}m")
                    return True

            time.sleep(1)

        logging.warning("Raising timed out")
        return False
    except Exception as e:
        logging.error(f"Error during raising: {str(e)}")
        return False

def mission_package_delivery(vehicle, altitude=10, model_path=None, delivery_height=2):
    """
    Execute a package delivery mission with landing at target.

    Args:
        vehicle: The connected mavlink object
        altitude: Cruising altitude in meters
        model_path: Path to the detection model
        delivery_height: Height to lower to for delivery

    Returns:
        True if mission was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Starting package delivery mission")

        # Initialize variables for detection results
        target_detected = False
        detection_center_x = None
        detection_center_y = None
        detection_thread_running = True

        # Load detection model
        model = load_detection_model(model_path)
        if not model:
            logging.error("Failed to load detection model")
            return False

        # Define detection thread function
        def detection_thread():
            nonlocal target_detected, detection_center_x, detection_center_y

            try:
                # Initialize camera
                cap = initialize_camera(0)
                if not cap:
                    logging.error("Failed to initialize camera")
                    return

                # Get camera center coordinates
                cam_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
                cam_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
                camera_center_x = cam_width / 2
                camera_center_y = cam_height / 2

                logging.info(f"Camera initialized. Resolution: {cam_width}x{cam_height}")

                # Run detection until thread is stopped
                while detection_thread_running:
                    # Capture frame
                    frame = capture_frame(cap)
                    if frame is None:
                        time.sleep(0.1)
                        continue

                    # Run detection on frame
                    results = run_detection(
                        model,
                        source=frame,
                        threshold=0.5,
                        save_results=False
                    )

                    # Process detection results
                    if results:
                        detections = process_detection_results(
                            [next(results)],
                            frame,
                            display=True
                        )

                        # Check if any object was detected
                        if detections:
                            # Use the first detection (highest confidence)
                            detection = detections[0]
                            target_detected = True
                            detection_center_x = detection['center'][0]
                            detection_center_y = detection['center'][1]

                            logging.info(f"Target detected at ({detection_center_x}, {detection_center_y})")
                        else:
                            target_detected = False
                            detection_center_x = None
                            detection_center_y = None

                    # Sleep briefly to reduce CPU usage
                    time.sleep(0.1)

                # Clean up resources
                close_camera(cap)

            except Exception as e:
                logging.error(f"Error in detection thread: {str(e)}")

        # Start detection thread
        det_thread = Thread(target=detection_thread)
        det_thread.daemon = True
        det_thread.start()

        # Wait for detection thread to initialize
        time.sleep(2)

        # First, arm and take off
        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and take off")
            detection_thread_running = False
            return False

        # Start a search pattern (simple square for now)
        waypoints = [
            (10, 0),    # 10m North
            (10, 10),   # 10m North, 10m East
            (0, 10),    # 10m East
            (0, 0)      # Back to start
        ]

        # Search for target
        target_found = False

        for i, waypoint in enumerate(waypoints):
            logging.info(f"Navigating to search point {i+1}/{len(waypoints)}")

            success = navigate_to_waypoint(
                vehicle, waypoint, altitude, relative=True
            )

            if not success:
                logging.error(f"Failed to navigate to search point {i+1}")
                detection_thread_running = False
                return_to_launch(vehicle)
                return False

            # Hover for 5 seconds at each waypoint to run detection
            logging.info(f"Reached search point {i+1}. Scanning for target")

            # Check for detections at this waypoint
            detection_start = time.time()
            while time.time() - detection_start < 5:
                if target_detected:
                    logging.info("Target detected! Preparing for delivery")
                    target_found = True
                    break

                time.sleep(0.5)

            if target_found:
                break

        # If target was found, align and deliver package
        if target_found and detection_center_x is not None and detection_center_y is not None:
            logging.info("Target found. Proceeding with delivery")

            # Align to target
            camera_center_x = 640 / 2  # Assuming 640x480 resolution
            camera_center_y = 480 / 2

            if not align_to_target(
                vehicle, detection_center_x, detection_center_y,
                camera_center_x, camera_center_y
            ):
                logging.error("Failed to align to target")
                detection_thread_running = False
                return_to_launch(vehicle)
                return False

            # Lower to delivery height
            if not lower_to_delivery_height(vehicle, delivery_height):
                logging.error("Failed to lower to delivery height")
                detection_thread_running = False
                return_to_launch(vehicle)
                return False

            # Deploy package
            logging.info("Deploying package")
            operate_claw(vehicle)
            time.sleep(2)

            # Raise back to safe height
            if not raise_to_safe_height(vehicle, altitude):
                logging.error("Failed to raise to safe height")
                detection_thread_running = False
                return_to_launch(vehicle)
                return False
        else:
            logging.warning("Target not found during search pattern")

        # Return to launch
        logging.info("Mission complete. Returning to launch")
        return_to_launch(vehicle)

        # Wait for landing
        start_time = time.time()
        while time.time() - start_time < 60:  # 1 minute timeout
            # Get latest state
            state = get_vehicle_state(vehicle)
            if state:
                armed = state.get('armed', None)
                if armed is not None and not armed:
                    logging.info("Vehicle has disarmed")
                    break

                altitude = state.get('altitude', None)
                if altitude is not None:
                    logging.info(f"Altitude: {altitude} meters")
                    if altitude < 0.5:  # Close to ground
                        logging.info("Vehicle has landed")
                        break
            time.sleep(1)

        # Stop detection thread
        detection_thread_running = False
        det_thread.join(timeout=2)  # Wait for thread to finish

        logging.info("Package delivery mission completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during package delivery mission: {str(e)}")
        # Stop detection thread
        detection_thread_running = False
        # Try to return to launch if there was an error
        try:
            return_to_launch(vehicle)
        except:
            pass
        return False

def mission_package_drop(vehicle, altitude=10, model_path=None, drop_altitude=8):
    """
    Execute a package drop mission without lowering.

    Args:
        vehicle: The connected mavlink object
        altitude: Cruising altitude in meters
        model_path: Path to the detection model
        drop_altitude: Altitude at which to drop the package

    Returns:
        True if mission was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Starting package drop mission")

        # Initialize variables for detection results
        target_detected = False
        detection_center_x = None
        detection_center_y = None
        detection_thread_running = True

        # Load detection model
        model = load_detection_model(model_path)
        if not model:
            logging.error("Failed to load detection model")
            return False

        # Define detection thread function
        def detection_thread():
            nonlocal target_detected, detection_center_x, detection_center_y

            try:
                # Initialize camera
                cap = initialize_camera(0)
                if not cap:
                    logging.error("Failed to initialize camera")
                    return

                # Get camera center coordinates
                cam_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
                cam_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
                camera_center_x = cam_width / 2
                camera_center_y = cam_height / 2

                logging.info(f"Camera initialized. Resolution: {cam_width}x{cam_height}")

                # Run detection until thread is stopped
                while detection_thread_running:
                    # Capture frame
                    frame = capture_frame(cap)
                    if frame is None:
                        time.sleep(0.1)
                        continue

                    # Run detection on frame
                    results = run_detection(
                        model,
                        source=frame,
                        threshold=0.5,
                        save_results=False
                    )

                    # Process detection results
                    if results:
                        detections = process_detection_results(
                            [next(results)],
                            frame,
                            display=True
                        )

                        # Check if any object was detected
                        if detections:
                            # Use the first detection (highest confidence)
                            detection = detections[0]
                            target_detected = True
                            detection_center_x = detection['center'][0]
                            detection_center_y = detection['center'][1]

                            logging.info(f"Target detected at ({detection_center_x}, {detection_center_y})")
                        else:
                            target_detected = False
                            detection_center_x = None
                            detection_center_y = None

                    # Sleep briefly to reduce CPU usage
                    time.sleep(0.1)

                # Clean up resources
                close_camera(cap)

            except Exception as e:
                logging.error(f"Error in detection thread: {str(e)}")

        # Start detection thread
        det_thread = Thread(target=detection_thread)
        det_thread.daemon = True
        det_thread.start()

        # Wait for detection thread to initialize
        time.sleep(2)

        # First, arm and take off
        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and take off")
            detection_thread_running = False
            return False

        # Start a search pattern (simple square for now)
        waypoints = [
            (10, 0),    # 10m North
            (10, 10),   # 10m North, 10m East
            (0, 10),    # 10m East
            (0, 0)      # Back to start
        ]

        # Search for target
        target_found = False

        for i, waypoint in enumerate(waypoints):
            logging.info(f"Navigating to search point {i+1}/{len(waypoints)}")

            success = navigate_to_waypoint(
                vehicle, waypoint, altitude, relative=True
            )

            if not success:
                logging.error(f"Failed to navigate to search point {i+1}")
                detection_thread_running = False
                return_to_launch(vehicle)
                return False

            # Hover for 5 seconds at each waypoint to run detection
            logging.info(f"Reached search point {i+1}. Scanning for target")

            # Check for detections at this waypoint
            detection_start = time.time()
            while time.time() - detection_start < 5:
                if target_detected:
                    logging.info("Target detected! Preparing for drop")
                    target_found = True
                    break

                time.sleep(0.5)

            if target_found:
                break

        # If target was found, align and drop package
        if target_found and detection_center_x is not None and detection_center_y is not None:
            logging.info("Target found. Proceeding with package drop")

            # Align to target
            camera_center_x = 640 / 2  # Assuming 640x480 resolution
            camera_center_y = 480 / 2

            if not align_to_target(
                vehicle, detection_center_x, detection_center_y,
                camera_center_x, camera_center_y
            ):
                logging.error("Failed to align to target")
                detection_thread_running = False
                return_to_launch(vehicle)
                return False

            # Drop package
            logging.info("Dropping package")
            operate_package_release(vehicle)
            time.sleep(2)
        else:
            logging.warning("Target not found during search pattern")

        # Return to launch
        logging.info("Mission complete. Returning to launch")
        return_to_launch(vehicle)

        # Wait for landing
        start_time = time.time()
        while time.time() - start_time < 60:  # 1 minute timeout
            # Get latest state
            state = get_vehicle_state(vehicle)
            if state:
                armed = state.get('armed', None)
                if armed is not None and not armed:
                    logging.info("Vehicle has disarmed")
                    break

                altitude = state.get('altitude', None)
                if altitude is not None:
                    logging.info(f"Altitude: {altitude} meters")
                    if altitude < 0.5:  # Close to ground
                        logging.info("Vehicle has landed")
                        break
            time.sleep(1)

        # Stop detection thread
        detection_thread_running = False
        det_thread.join(timeout=2)  # Wait for thread to finish

        logging.info("Package drop mission completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during package drop mission: {str(e)}")
        # Stop detection thread
        detection_thread_running = False
        # Try to return to launch if there was an error
        try:
            return_to_launch(vehicle)
        except:
            pass
        return False

def mission_target_localize(vehicle, altitude=10):
    """
    Execute a mission to locate ground control points.

    Args:
        vehicle: The connected mavlink object
        altitude: Cruising altitude in meters

    Returns:
        True if mission was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Starting target localization mission")

        # Initialize variables for GCP detection
        target_found = False
        target_type = None
        target_position = None
        detection_thread_running = True

        # Define GCP detection thread function
        def gcp_detection_thread():
            nonlocal target_found, target_type, target_position

            try:
                # Initialize camera
                cap = initialize_camera(0)
                if not cap:
                    logging.error("Failed to initialize camera")
                    return

                logging.info("Camera initialized for GCP detection")

                # Run detection until thread is stopped
                while detection_thread_running:
                    # Capture frame
                    frame = capture_frame(cap)
                    if frame is None:
                        time.sleep(0.1)
                        continue

                    # Detect GCP markers
                    results = detect_gcp_markers(frame, save_debug=True)

                    # Check for X-patterns (highest priority)
                    if len(results['x_patterns']) > 0:
                        x, y, w, h, conf = results['x_patterns'][0]
                        target_found = True
                        target_type = 'x_pattern'
                        target_position = (x + w/2, y + h/2)
                        logging.info(f"X-Pattern detected at {target_position} with confidence {conf}")

                    # Check for triangles in squares
                    elif len(results['tri_in_squares']) > 0:
                        x, y, w, h, count = results['tri_in_squares'][0]
                        target_found = True
                        target_type = 'triangles_in_square'
                        target_position = (x + w/2, y + h/2)
                        logging.info(f"Triangles in square detected at {target_position} with {count} triangles")

                    # Check for squares
                    elif len(results['squares']) > 0:
                        x, y, w, h, _ = results['squares'][0]
                        target_found = True
                        target_type = 'square'
                        target_position = (x + w/2, y + h/2)
                        logging.info(f"Square detected at {target_position}")

                    # Check for triangles
                    elif len(results['triangles']) > 0:
                        x, y, w, h, _ = results['triangles'][0]
                        target_found = True
                        target_type = 'triangle'
                        target_position = (x + w/2, y + h/2)
                        logging.info(f"Triangle detected at {target_position}")

                    else:
                        target_found = False
                        target_type = None
                        target_position = None

                    # Display the frame with detections
                    cv2.imshow("GCP Detection", results['display_frame'])
                    cv2.waitKey(1)

                    # Sleep briefly to reduce CPU usage
                    time.sleep(0.1)

                # Clean up resources
                close_camera(cap)
                cv2.destroyAllWindows()

            except Exception as e:
                logging.error(f"Error in GCP detection thread: {str(e)}")

        # Start detection thread
        det_thread = Thread(target=gcp_detection_thread)
        det_thread.daemon = True
        det_thread.start()

        # Wait for detection thread to initialize
        time.sleep(2)

        # First, arm and take off
        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and take off")
            detection_thread_running = False
            return False

        # Start a search pattern
        waypoints = [
            (10, 0),    # 10m North
            (10, 10),   # 10m North, 10m East
            (0, 10),    # 10m East
            (0, 0)      # Back to start
        ]

        # Search for GCP targets
        for i, waypoint in enumerate(waypoints):
            logging.info(f"Navigating to search point {i+1}/{len(waypoints)}")

            success = navigate_to_waypoint(
                vehicle, waypoint, altitude, relative=True
            )

            if not success:
                logging.error(f"Failed to navigate to search point {i+1}")
                detection_thread_running = False
                return_to_launch(vehicle)
                return False

            # Hover for 10 seconds at each waypoint to run detection
            logging.info(f"Reached search point {i+1}. Scanning for GCP targets")

            # Check for detections at this waypoint
            start_time = time.time()
            while time.time() - start_time < 10:
                if target_found:
                    logging.info(f"GCP target found: {target_type}")

                    # Record location if target is found
                    location = get_location(vehicle)
                    if location:
                        logging.info(f"GCP target location: Lat {location[0]}, Lon {location[1]}, Alt {location[2]}")
                        logging.info(f"Target pixel position: {target_position}")

                    # Hover for an additional 5 seconds to gather more data
                    time.sleep(5)
                    break

                time.sleep(0.5)

        # Return to launch
        logging.info("Mission complete. Returning to launch")
        return_to_launch(vehicle)

        # Wait for landing
        start_time = time.time()
        while time.time() - start_time < 60:  # 1 minute timeout
            # Get latest state
            state = get_vehicle_state(vehicle)
            if state:
                armed = state.get('armed', None)
                if armed is not None and not armed:
                    logging.info("Vehicle has disarmed")
                    break

                altitude = state.get('altitude', None)
                if altitude is not None:
                    logging.info(f"Altitude: {altitude} meters")
                    if altitude < 0.5:  # Close to ground
                        logging.info("Vehicle has landed")
                        break
            time.sleep(1)

        # Stop detection thread
        detection_thread_running = False
        det_thread.join(timeout=2)  # Wait for thread to finish

        logging.info("Target localization mission completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during target localization mission: {str(e)}")
        # Stop detection thread
        detection_thread_running = False
        # Try to return to launch if there was an error
        try:
            return_to_launch(vehicle)
        except:
            pass
        return False


--- docs\old\gcp.py ---
"""
Ground Control Point (GCP) Detection Module
----------------------------------------
Functions for detecting ground control points like squares, triangles,
and X-patterns for drone navigation and landing.
"""

import cv2
import numpy as np
import math
import logging
import os
import time

def detect_squares(frame, min_area=100, max_area=10000, aspect_ratio_range=(0.8, 1.2)):
    """
    Detect squares in the frame.

    Args:
        frame: Input image frame
        min_area: Minimum contour area to consider
        max_area: Maximum contour area to consider
        aspect_ratio_range: Tuple of (min, max) aspect ratio for square detection

    Returns:
        List of detected squares, each as (x, y, w, h, contour)
    """
    try:
        # Convert to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Apply blur to reduce noise
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)

        # Find edges using Canny edge detector
        edges = cv2.Canny(blurred, 50, 150)

        # Find contours
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # List to store detected squares
        squares = []

        # Loop through all contours
        for contour in contours:
            # Filter by area
            area = cv2.contourArea(contour)
            if area < min_area or area > max_area:
                continue

            # Approximate the contour shape
            perimeter = cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)

            # Check if it has 4 vertices (potential square)
            if len(approx) == 4:
                # Get bounding rectangle
                x, y, w, h = cv2.boundingRect(approx)

                # Check aspect ratio for squareness
                aspect_ratio = float(w) / h
                if aspect_ratio_range[0] <= aspect_ratio <= aspect_ratio_range[1]:
                    squares.append((x, y, w, h, approx))

        return squares
    except Exception as e:
        logging.error(f"Error detecting squares: {str(e)}")
        return []

def detect_triangles(frame, min_area=100, max_area=10000, tolerance=0.15):
    """
    Detect triangles in the frame.

    Args:
        frame: Input image frame
        min_area: Minimum contour area to consider
        max_area: Maximum contour area to consider
        tolerance: Tolerance for side length similarity in equilateral triangles

    Returns:
        List of detected triangles, each as (x, y, w, h, contour)
    """
    try:
        # Convert to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Apply blur to reduce noise
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)

        # Find edges using Canny edge detector
        edges = cv2.Canny(blurred, 50, 150)

        # Find contours
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # List to store detected triangles
        triangles = []

        # Loop through all contours
        for contour in contours:
            # Filter by area
            area = cv2.contourArea(contour)
            if area < min_area or area > max_area:
                continue

            # Approximate the contour shape
            perimeter = cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)

            # Check if it has 3 vertices (triangle)
            if len(approx) == 3:
                # Calculate side lengths
                side1 = np.linalg.norm(approx[0][0] - approx[1][0])
                side2 = np.linalg.norm(approx[1][0] - approx[2][0])
                side3 = np.linalg.norm(approx[2][0] - approx[0][0])

                # Calculate average side length
                avg_side = (side1 + side2 + side3) / 3

                # Check if it's approximately equilateral
                if (abs(side1 - avg_side) / avg_side < tolerance and
                    abs(side2 - avg_side) / avg_side < tolerance and
                    abs(side3 - avg_side) / avg_side < tolerance):

                    # Get bounding rectangle
                    x, y, w, h = cv2.boundingRect(approx)
                    triangles.append((x, y, w, h, approx))

        return triangles
    except Exception as e:
        logging.error(f"Error detecting triangles: {str(e)}")
        return []

def detect_x_pattern(frame, min_area=500, max_area=100000, diagonal_angle_tolerance=15):
    """
    Detect X-patterns in the frame (squares with diagonal lines).

    Args:
        frame: Input image frame
        min_area: Minimum contour area to consider
        max_area: Maximum contour area to consider
        diagonal_angle_tolerance: Tolerance for diagonal angles (45¬±tolerance)

    Returns:
        List of detected X-patterns, each as (x, y, w, h, confidence)
    """
    try:
        # First, detect potential squares
        squares = detect_squares(frame, min_area, max_area)

        # Process each square to check for X-pattern
        x_patterns = []

        for x, y, w, h, approx in squares:
            # Create a mask for this square
            mask = np.zeros(frame.shape[:2], dtype=np.uint8)
            cv2.drawContours(mask, [approx], 0, 255, -1)

            # Get the ROI (Region of Interest)
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            roi = cv2.bitwise_and(gray, gray, mask=mask)

            # Skip if ROI is empty
            if roi[mask > 0].size == 0:
                continue

            # Apply edge detection to the ROI
            roi_edges = cv2.Canny(roi, 30, 120)

            # Look for diagonal lines using Hough transform
            lines = cv2.HoughLinesP(
                roi_edges, 1, np.pi/180,
                threshold=15,
                minLineLength=20,
                maxLineGap=20
            )

            # Count diagonal lines
            diagonal_lines = []

            if lines is not None:
                for line in lines:
                    x1, y1, x2, y2 = line[0]

                    # Calculate line angle
                    angle = math.degrees(math.atan2(y2 - y1, x2 - x1)) % 180

                    # Check if line is close to diagonal angles (45 or 135 degrees)
                    if ((45 - diagonal_angle_tolerance <= angle <= 45 + diagonal_angle_tolerance) or
                        (135 - diagonal_angle_tolerance <= angle <= 135 + diagonal_angle_tolerance)):
                        diagonal_lines.append((x1, y1, x2, y2, angle))

            # Check quadrant intensity differences as an alternative method
            h_half, w_half = h // 2, w // 2
            quadrant_pattern_detected = False

            if h_half > 0 and w_half > 0:
                # Define quadrant regions
                q1 = roi[y:y+h_half, x:x+w_half]
                q2 = roi[y:y+h_half, x+w_half:x+w]
                q3 = roi[y+h_half:y+h, x:x+w_half]
                q4 = roi[y+h_half:y+h, x+w_half:x+w]

                # Calculate mean intensity for non-zero pixels in each quadrant
                q1_intensity = np.mean(q1[q1 > 0]) if np.any(q1 > 0) else 0
                q2_intensity = np.mean(q2[q2 > 0]) if np.any(q2 > 0) else 0
                q3_intensity = np.mean(q3[q3 > 0]) if np.any(q3 > 0) else 0
                q4_intensity = np.mean(q4[q4 > 0]) if np.any(q4 > 0) else 0

                # Calculate intensity differences
                diagonal1_diff = abs(q1_intensity - q4_intensity)
                diagonal2_diff = abs(q2_intensity - q3_intensity)
                cross_diff = abs((q1_intensity + q4_intensity) / 2 - (q2_intensity + q3_intensity) / 2)

                # If diagonals have similar intensities within each diagonal but
                # different between diagonals, it's likely an X pattern
                quadrant_pattern_detected = (
                    diagonal1_diff < 10 and
                    diagonal2_diff < 10 and
                    cross_diff > 20
                )

            # Check if this is an X-pattern based on diagonal lines and quadrant analysis
            has_enough_diagonals = len(diagonal_lines) >= 2

            if has_enough_diagonals or quadrant_pattern_detected:
                # Calculate confidence score
                confidence = (len(diagonal_lines) * 0.3) + (1 if quadrant_pattern_detected else 0)
                x_patterns.append((x, y, w, h, confidence))

        return x_patterns
    except Exception as e:
        logging.error(f"Error detecting X-patterns: {str(e)}")
        return []

def detect_triangles_in_squares(frame, min_triangles=4):
    """
    Detect squares containing multiple triangles.

    Args:
        frame: Input image frame
        min_triangles: Minimum number of triangles required inside a square

    Returns:
        List of detected patterns, each as (x, y, w, h, num_triangles)
    """
    try:
        # Detect triangles and squares
        triangles = detect_triangles(frame)
        squares = detect_squares(frame)

        # Check which squares contain multiple triangles
        patterns = []

        for sx, sy, sw, sh, s_approx in squares:
            # Count triangles inside this square
            triangles_inside = 0

            for tx, ty, tw, th, t_approx in triangles:
                # Check if triangle center is inside square
                t_center_x = tx + tw/2
                t_center_y = ty + th/2

                if (sx <= t_center_x <= sx + sw and
                    sy <= t_center_y <= sy + sh):
                    triangles_inside += 1

            # If enough triangles are inside the square
            if triangles_inside >= min_triangles:
                patterns.append((sx, sy, sw, sh, triangles_inside))

        return patterns
    except Exception as e:
        logging.error(f"Error detecting triangles in squares: {str(e)}")
        return []

def detect_gcp_markers(frame, save_debug=False, debug_dir="debug_frames"):
    """
    Detect all types of GCP markers in a frame.

    Args:
        frame: Input image frame
        save_debug: Whether to save debug frames to disk
        debug_dir: Directory to save debug frames

    Returns:
        Dictionary of detected markers by type
    """
    try:
        # Create copy for visualization
        display_frame = frame.copy()

        # Detect different types of markers
        squares = detect_squares(frame)
        triangles = detect_triangles(frame)
        x_patterns = detect_x_pattern(frame)
        tri_in_squares = detect_triangles_in_squares(frame)

        # Draw detections on the display frame
        for x, y, w, h, _ in squares:
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(display_frame, "Square", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        for x, y, w, h, _ in triangles:
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            cv2.putText(display_frame, "Triangle", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        for x, y, w, h, conf in x_patterns:
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 0, 255), 2)
            cv2.putText(display_frame, f"X-Pattern ({conf:.1f})", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

        for x, y, w, h, count in tri_in_squares:
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 0, 255), 3)
            cv2.putText(display_frame, f"{count} triangles", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)

        # Save debug frame if requested
        if save_debug:
            if not os.path.exists(debug_dir):
                os.makedirs(debug_dir)

            timestamp = time.strftime("%Y%m%d_%H%M%S")
            cv2.imwrite(f"{debug_dir}/gcp_detection_{timestamp}.jpg", display_frame)

        # Return all detections
        return {
            'display_frame': display_frame,
            'squares': squares,
            'triangles': triangles,
            'x_patterns': x_patterns,
            'tri_in_squares': tri_in_squares
        }
    except Exception as e:
        logging.error(f"Error detecting GCP markers: {str(e)}")
        return {
            'display_frame': frame,
            'squares': [],
            'triangles': [],
            'x_patterns': [],
            'tri_in_squares': []
        }

def run_gcp_detection(camera_id=0, duration=30, save_detected=True):
    """
    Run continuous GCP detection on a camera feed.

    Args:
        camera_id: Camera ID to use
        duration: Duration in seconds (0 for indefinite)
        save_detected: Whether to save frames with detections

    Returns:
        True if completed successfully, False otherwise
    """
    try:
        # Initialize camera
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            logging.error(f"Failed to open camera {camera_id}")
            return False

        # Create debug directory
        debug_dir = "debug_frames"
        if not os.path.exists(debug_dir):
            os.makedirs(debug_dir)

        # Start detection loop
        start_time = time.time()
        frame_count = 0
        detection_count = 0

        logging.info(f"Starting GCP detection for {duration} seconds (0 = indefinite)")

        while True:
            # Check if duration is reached
            if duration > 0 and (time.time() - start_time > duration):
                break

            # Capture frame
            ret, frame = cap.read()
            if not ret:
                logging.error("Failed to capture frame")
                break

            frame_count += 1

            # Run detection every 5 frames to reduce processing load
            if frame_count % 5 == 0:
                # Detect GCP markers
                results = detect_gcp_markers(frame, save_debug=False)

                # Check if any markers were detected
                has_detections = (
                    len(results['squares']) > 0 or
                    len(results['triangles']) > 0 or
                    len(results['x_patterns']) > 0 or
                    len(results['tri_in_squares']) > 0
                )

                if has_detections:
                    detection_count += 1

                    # Save frame with detections if requested
                    if save_detected:
                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                        cv2.imwrite(f"{debug_dir}/gcp_detection_{timestamp}.jpg", results['display_frame'])

                # Display the frame with detections
                cv2.imshow("GCP Detection", results['display_frame'])

            # Break the loop if 'q' is pressed
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        # Clean up
        cap.release()
        cv2.destroyAllWindows()

        logging.info(f"GCP detection completed. Processed {frame_count} frames, found detections in {detection_count} frames")
        return True
    except Exception as e:
        logging.error(f"Error during GCP detection: {str(e)}")
        return False


--- docs\old\gcp_detector.py ---
# detection/gcp_detector.py - NEW MODULE
"""
GCP (Ground Control Point) Detection Test Module
-----------------------------------------------
Comprehensive testing module for GCP marker detection including X-patterns,
squares, triangles, and other geometric markers. Designed for drone competition use.
"""

import cv2
import numpy as np
import logging
import time
import os
import math
from typing import List, Tuple, Optional, Union, Dict
from pathlib import Path

class GCPDetector:
    """GCP detector for testing various ground control point markers"""

    def __init__(self, confidence_threshold=0.5):
        """
        Initialize the GCP detector.

        Args:
            confidence_threshold: Minimum confidence for X-pattern detections
        """
        self.conf_threshold = confidence_threshold

        # Performance tracking
        self.frame_count = 0
        self.total_inference_time = 0
        self.detections_count = 0
        self.detection_stats = {
            'x_patterns': 0,
            'squares': 0,
            'triangles': 0,
            'tri_in_squares': 0
        }

        # X-pattern saving
        self.x_pattern_save_count = 0

    def detect_squares(self, frame, min_area=100, max_area=10000, aspect_ratio_range=(0.8, 1.2)):
        """Detect squares in the frame."""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            squares = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area < min_area or area > max_area:
                    continue

                perimeter = cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)

                if len(approx) == 4:
                    x, y, w, h = cv2.boundingRect(approx)
                    aspect_ratio = float(w) / h
                    if aspect_ratio_range[0] <= aspect_ratio <= aspect_ratio_range[1]:
                        squares.append((x, y, w, h, approx))

            return squares
        except Exception as e:
            logging.error(f"Error detecting squares: {str(e)}")
            return []

    def detect_triangles(self, frame, min_area=100, max_area=10000, tolerance=0.15):
        """Detect triangles in the frame."""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            triangles = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area < min_area or area > max_area:
                    continue

                perimeter = cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)

                if len(approx) == 3:
                    side1 = np.linalg.norm(approx[0][0] - approx[1][0])
                    side2 = np.linalg.norm(approx[1][0] - approx[2][0])
                    side3 = np.linalg.norm(approx[2][0] - approx[0][0])

                    avg_side = (side1 + side2 + side3) / 3

                    if (abs(side1 - avg_side) / avg_side < tolerance and
                        abs(side2 - avg_side) / avg_side < tolerance and
                        abs(side3 - avg_side) / avg_side < tolerance):

                        x, y, w, h = cv2.boundingRect(approx)
                        triangles.append((x, y, w, h, approx))

            return triangles
        except Exception as e:
            logging.error(f"Error detecting triangles: {str(e)}")
            return []

    def detect_x_pattern(self, frame, min_area=500, max_area=100000, diagonal_angle_tolerance=15):
        """Detect X-patterns in the frame (squares with diagonal lines)."""
        try:
            squares = self.detect_squares(frame, min_area, max_area)
            x_patterns = []

            for x, y, w, h, approx in squares:
                # Create a mask for this square
                mask = np.zeros(frame.shape[:2], dtype=np.uint8)
                cv2.drawContours(mask, [approx], 0, 255, -1)

                # Get the ROI
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                roi = cv2.bitwise_and(gray, gray, mask=mask)

                if roi[mask > 0].size == 0:
                    continue

                # Apply edge detection to the ROI
                roi_edges = cv2.Canny(roi, 30, 120)

                # Look for diagonal lines using Hough transform
                lines = cv2.HoughLinesP(
                    roi_edges, 1, np.pi/180,
                    threshold=15,
                    minLineLength=20,
                    maxLineGap=20
                )

                diagonal_lines = []
                if lines is not None:
                    for line in lines:
                        x1, y1, x2, y2 = line[0]
                        angle = math.degrees(math.atan2(y2 - y1, x2 - x1)) % 180

                        if ((45 - diagonal_angle_tolerance <= angle <= 45 + diagonal_angle_tolerance) or
                            (135 - diagonal_angle_tolerance <= angle <= 135 + diagonal_angle_tolerance)):
                            diagonal_lines.append((x1, y1, x2, y2, angle))

                # Check quadrant intensity differences
                h_half, w_half = h // 2, w // 2
                quadrant_pattern_detected = False

                if h_half > 0 and w_half > 0:
                    q1 = roi[y:y+h_half, x:x+w_half]
                    q2 = roi[y:y+h_half, x+w_half:x+w]
                    q3 = roi[y+h_half:y+h, x:x+w_half]
                    q4 = roi[y+h_half:y+h, x+w_half:x+w]

                    q1_intensity = np.mean(q1[q1 > 0]) if np.any(q1 > 0) else 0
                    q2_intensity = np.mean(q2[q2 > 0]) if np.any(q2 > 0) else 0
                    q3_intensity = np.mean(q3[q3 > 0]) if np.any(q3 > 0) else 0
                    q4_intensity = np.mean(q4[q4 > 0]) if np.any(q4 > 0) else 0

                    diagonal1_diff = abs(q1_intensity - q4_intensity)
                    diagonal2_diff = abs(q2_intensity - q3_intensity)
                    cross_diff = abs((q1_intensity + q4_intensity) / 2 - (q2_intensity + q3_intensity) / 2)

                    quadrant_pattern_detected = (
                        diagonal1_diff < 10 and
                        diagonal2_diff < 10 and
                        cross_diff > 20
                    )

                has_enough_diagonals = len(diagonal_lines) >= 2

                if has_enough_diagonals or quadrant_pattern_detected:
                    confidence = (len(diagonal_lines) * 0.3) + (1 if quadrant_pattern_detected else 0)
                    confidence = min(confidence, 1.0)  # Cap at 1.0

                    if confidence >= self.conf_threshold:
                        x_patterns.append((x, y, w, h, confidence, diagonal_lines))

                        # Save preprocessing steps for X-pattern debugging
                        if self.x_pattern_save_count % 3 == 0:  # Save every 3rd X-pattern detection
                            self._save_x_pattern_debug(frame, x, y, w, h, confidence, gray, roi, roi_edges, diagonal_lines)
                        self.x_pattern_save_count += 1

            return x_patterns
        except Exception as e:
            logging.error(f"Error detecting X-patterns: {str(e)}")
            return []

    def detect_triangles_in_squares(self, frame, min_triangles=4):
        """Detect squares containing multiple triangles."""
        try:
            triangles = self.detect_triangles(frame)
            squares = self.detect_squares(frame)

            patterns = []
            for sx, sy, sw, sh, s_approx in squares:
                triangles_inside = 0

                for tx, ty, tw, th, t_approx in triangles:
                    t_center_x = tx + tw/2
                    t_center_y = ty + th/2

                    if (sx <= t_center_x <= sx + sw and
                        sy <= t_center_y <= sy + sh):
                        triangles_inside += 1

                if triangles_inside >= min_triangles:
                    patterns.append((sx, sy, sw, sh, triangles_inside))

            return patterns
        except Exception as e:
            logging.error(f"Error detecting triangles in squares: {str(e)}")
            return []

    def detect_gcp_markers_in_frame(self, frame):
        """
        Detect all types of GCP markers in a frame.

        Args:
            frame: Input BGR image

        Returns:
            Tuple of (gcp_markers, debug_image)
            gcp_markers: Dictionary with all detected marker types
            debug_image: Annotated image showing detections
        """
        if frame is None:
            return {}, frame

        try:
            start_time = time.time()

            # Detect different types of markers
            squares = self.detect_squares(frame)
            triangles = self.detect_triangles(frame)
            x_patterns = self.detect_x_pattern(frame)
            tri_in_squares = self.detect_triangles_in_squares(frame)

            inference_time = time.time() - start_time
            self.total_inference_time += inference_time
            self.frame_count += 1

            # Update detection counts
            self.detection_stats['squares'] += len(squares)
            self.detection_stats['triangles'] += len(triangles)
            self.detection_stats['x_patterns'] += len(x_patterns)
            self.detection_stats['tri_in_squares'] += len(tri_in_squares)
            self.detections_count += len(squares) + len(triangles) + len(x_patterns) + len(tri_in_squares)

            # Create debug image
            debug_image = frame.copy()

            # Draw detections on the display frame
            for x, y, w, h, _ in squares:
                cv2.rectangle(debug_image, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv2.putText(debug_image, "Square", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            for x, y, w, h, _ in triangles:
                cv2.rectangle(debug_image, (x, y), (x + w, y + h), (255, 0, 0), 2)
                cv2.putText(debug_image, "Triangle", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

            for x, y, w, h, conf, lines in x_patterns:
                # Draw main bounding box in red for X-patterns
                cv2.rectangle(debug_image, (x, y), (x + w, y + h), (0, 0, 255), 3)

                # Draw detected diagonal lines
                for line_data in lines:
                    x1, y1, x2, y2, angle = line_data
                    cv2.line(debug_image, (x1, y1), (x2, y2), (255, 255, 0), 2)

                # Draw center point
                center_x, center_y = x + w//2, y + h//2
                cv2.circle(debug_image, (center_x, center_y), 8, (0, 0, 255), -1)
                cv2.circle(debug_image, (center_x, center_y), 12, (255, 255, 255), 2)

                # Add confidence label
                label = f"X-Pattern: {conf:.3f}"
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                cv2.rectangle(debug_image, (x, y - label_size[1] - 15),
                             (x + label_size[0], y - 5), (0, 0, 255), -1)
                cv2.putText(debug_image, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            for x, y, w, h, count in tri_in_squares:
                cv2.rectangle(debug_image, (x, y), (x + w, y + h), (255, 0, 255), 3)
                cv2.putText(debug_image, f"{count} triangles", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)

            # Add frame info to debug image
            self._add_frame_info(debug_image, inference_time)

            # Prepare return data
            gcp_markers = {
                'squares': squares,
                'triangles': triangles,
                'x_patterns': x_patterns,
                'tri_in_squares': tri_in_squares,
                'total_detections': len(squares) + len(triangles) + len(x_patterns) + len(tri_in_squares)
            }

            return gcp_markers, debug_image

        except Exception as e:
            logging.error(f"Error in GCP marker detection: {str(e)}")
            return {}, frame

    def _add_frame_info(self, image, inference_time):
        """Add frame information overlay"""
        fps = 1.0 / inference_time if inference_time > 0 else 0

        # Add frame info
        info_text = f"FPS: {fps:.1f} | Total Detections: {self.detections_count} | Frame: {self.frame_count}"
        cv2.putText(image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)

        # Add detection breakdown
        breakdown = f"X:{self.detection_stats['x_patterns']} Sq:{self.detection_stats['squares']} Tri:{self.detection_stats['triangles']} TriSq:{self.detection_stats['tri_in_squares']}"
        cv2.putText(image, breakdown, (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(image, breakdown, (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

        # Add crosshair at frame center for drone alignment reference
        h, w = image.shape[:2]
        cv2.line(image, (w//2 - 20, h//2), (w//2 + 20, h//2), (0, 255, 255), 2)
        cv2.line(image, (w//2, h//2 - 20), (w//2, h//2 + 20), (0, 255, 255), 2)
        cv2.circle(image, (w//2, h//2), 3, (0, 255, 255), -1)

    def _save_x_pattern_debug(self, original_frame, x, y, w, h, confidence, gray, roi, roi_edges, diagonal_lines):
        """Save debugging images for X-pattern detection"""
        try:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            debug_dir = "debug_frames"
            if not os.path.exists(debug_dir):
                os.makedirs(debug_dir)

            # 1. Save original detection
            detection_frame = original_frame.copy()
            cv2.rectangle(detection_frame, (x, y), (x + w, y + h), (0, 0, 255), 3)
            cv2.putText(detection_frame, f"X-Pattern: {confidence:.3f}",
                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            cv2.imwrite(f"{debug_dir}/x_pattern_{self.x_pattern_save_count}_{timestamp}_detection.jpg", detection_frame)

            # 2. Save ROI preprocessing steps
            cv2.imwrite(f"{debug_dir}/x_pattern_{self.x_pattern_save_count}_{timestamp}_roi.jpg", roi)
            cv2.imwrite(f"{debug_dir}/x_pattern_{self.x_pattern_save_count}_{timestamp}_edges.jpg", roi_edges)

            # 3. Save detected lines overlay
            lines_frame = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)
            for line_data in diagonal_lines:
                x1, y1, x2, y2, angle = line_data
                cv2.line(lines_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(lines_frame, f"{angle:.0f}¬∞", (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
            cv2.imwrite(f"{debug_dir}/x_pattern_{self.x_pattern_save_count}_{timestamp}_lines.jpg", lines_frame)

            logging.info(f"Saved X-pattern debug images: x_pattern_{self.x_pattern_save_count}_{timestamp}_*.jpg")

        except Exception as e:
            logging.warning(f"Failed to save X-pattern debug images: {str(e)}")

    def get_performance_stats(self):
        """Get performance statistics"""
        if self.frame_count == 0:
            return {}

        avg_fps = self.frame_count / self.total_inference_time if self.total_inference_time > 0 else 0
        avg_inference_ms = (self.total_inference_time / self.frame_count) * 1000

        return {
            'total_frames': self.frame_count,
            'total_detections': self.detections_count,
            'avg_detections_per_frame': self.detections_count / self.frame_count,
            'avg_fps': avg_fps,
            'avg_inference_ms': avg_inference_ms,
            'detection_breakdown': self.detection_stats.copy()
        }

def create_enhanced_gcp_display(original_frame, gcp_markers, debug_image):
    """
    Create enhanced display with big indicators for GCP detections.
    """
    enhanced = debug_image.copy()
    height, width = enhanced.shape[:2]

    total_detections = gcp_markers.get('total_detections', 0)
    x_patterns = gcp_markers.get('x_patterns', [])

    # Add detection indicators
    if total_detections > 0:
        # Determine primary detection type for color coding
        if len(x_patterns) > 0:
            # X-patterns found - highest priority (red theme)
            overlay = enhanced.copy()
            cv2.rectangle(overlay, (0, 0), (width, 80), (0, 0, 150), -1)
            enhanced = cv2.addWeighted(enhanced, 0.7, overlay, 0.3, 0)

            cv2.putText(enhanced, f"üéØ X-PATTERN DETECTED! ({len(x_patterns)} found)",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
            cv2.putText(enhanced, f"üéØ X-PATTERN DETECTED! ({len(x_patterns)} found)",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 2)

            # Add confidence info for X-patterns
            best_x_pattern = max(x_patterns, key=lambda x: x[4])  # Get highest confidence
            conf_text = f"Best Confidence: {best_x_pattern[4]:.1%}"
            cv2.putText(enhanced, conf_text, (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        else:
            # Other GCP markers found (green theme)
            overlay = enhanced.copy()
            cv2.rectangle(overlay, (0, 0), (width, 80), (0, 150, 0), -1)
            enhanced = cv2.addWeighted(enhanced, 0.7, overlay, 0.3, 0)

            cv2.putText(enhanced, f"üìç GCP MARKERS DETECTED! ({total_detections} found)",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
            cv2.putText(enhanced, f"üìç GCP MARKERS DETECTED! ({total_detections} found)",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)

        # Draw big circles around X-patterns (highest priority)
        for x, y, w, h, conf, lines in x_patterns:
            center_x, center_y = x + w//2, y + h//2
            # Big outer circle for X-patterns
            cv2.circle(enhanced, (center_x, center_y), 100, (0, 0, 255), 5)
            # Inner circle
            cv2.circle(enhanced, (center_x, center_y), 50, (255, 255, 255), 3)

    else:
        # No detections found
        overlay = enhanced.copy()
        cv2.rectangle(overlay, (0, 0), (width, 60), (0, 0, 150), -1)
        enhanced = cv2.addWeighted(enhanced, 0.8, overlay, 0.2, 0)

        cv2.putText(enhanced, "üîç NO GCP MARKERS DETECTED",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)
        cv2.putText(enhanced, "üîç NO GCP MARKERS DETECTED",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

    return enhanced

def test_gcp_detection(source: Union[str, int] = 0,
                      display: bool = True,
                      save_results: bool = True,
                      duration: float = 0,
                      video_delay: float = 0.1,
                      confidence: float = 0.5) -> bool:
    """
    Test GCP detection on camera feed, video file, or image.

    Args:
        source: Camera ID (int), video file path, or image file path
        display: Whether to display the detection results
        save_results: Whether to save detection results
        duration: Duration for camera/video (0 = until 'q' pressed)
        video_delay: Delay between frames for video/camera (seconds)
        confidence: Confidence threshold for X-pattern detections

    Returns:
        True if test completed successfully
    """
    try:
        logging.info(f"Starting GCP detection test with source: {source}")

        detector = GCPDetector(confidence_threshold=confidence)

        # Determine source type
        if isinstance(source, int):
            # Camera input
            cap = cv2.VideoCapture(source)
            if not cap.isOpened():
                logging.error(f"Failed to open camera {source}")
                return False

            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)
            source_type = "camera"

        elif isinstance(source, str):
            if source.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                # Image file
                image = cv2.imread(source)
                if image is None:
                    logging.error(f"Failed to load image: {source}")
                    return False
                source_type = "image"
            else:
                # Video file
                cap = cv2.VideoCapture(source)
                if not cap.isOpened():
                    logging.error(f"Failed to open video: {source}")
                    return False
                source_type = "video"
        else:
            logging.error("Invalid source type")
            return False

        # Process single image
        if source_type == "image":
            gcp_markers, debug_image = detector.detect_gcp_markers_in_frame(image)

            # Create enhanced display image
            enhanced_image = create_enhanced_gcp_display(image, gcp_markers, debug_image)

            logging.info(f"Detected {gcp_markers['total_detections']} GCP markers in image")
            for marker_type, markers in gcp_markers.items():
                if marker_type != 'total_detections' and markers:
                    logging.info(f"  {marker_type}: {len(markers)}")

            if display:
                cv2.imshow("GCP Detection Results", enhanced_image)
                print("\n" + "="*60)
                print("üì∏ GCP IMAGE DETECTION RESULTS")
                print("="*60)
                if gcp_markers['total_detections'] > 0:
                    print(f"üéØ GCP MARKERS FOUND: {gcp_markers['total_detections']}")
                    for marker_type, markers in gcp_markers.items():
                        if marker_type != 'total_detections' and markers:
                            print(f"   {marker_type}: {len(markers)}")
                            if marker_type == 'x_patterns':
                                for i, (x, y, w, h, conf, _) in enumerate(markers):
                                    print(f"     X-Pattern {i+1}: Position ({x+w//2}, {y+h//2}), Confidence: {conf:.1%}")
                else:
                    print("‚ùå NO GCP MARKERS DETECTED")
                print("="*60)
                print("Press any key to close...")
                cv2.waitKey(0)
                cv2.destroyAllWindows()

            if save_results:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f"gcp_detection_{timestamp}.jpg"
                cv2.imwrite(filename, enhanced_image)
                logging.info(f"Results saved to: {filename}")

            return True

        # Process video or camera feed
        else:
            total_frames = 0
            detection_frames = 0
            start_time = time.time()

            if source_type == "video":
                total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                video_fps = cap.get(cv2.CAP_PROP_FPS)
                logging.info(f"Video: {total_video_frames} frames @ {video_fps} FPS")

            logging.info(f"Processing {source_type}. Press 'q' to quit, 's' to save frame")
            print("\n" + "="*80)
            print(f"üé• {source_type.upper()} GCP DETECTION")
            print("="*80)
            print("Controls: 'q' = quit, 's' = save frame, 'p' = pause")
            print("="*80)

            while True:
                ret, frame = cap.read()

                if not ret:
                    if source_type == "camera":
                        logging.error("Failed to capture frame")
                        break
                    else:
                        logging.info("End of video reached")
                        break

                total_frames += 1

                # Detect GCP markers
                gcp_markers, debug_image = detector.detect_gcp_markers_in_frame(frame)

                # Create enhanced display
                enhanced_image = create_enhanced_gcp_display(frame, gcp_markers, debug_image)

                # Track detections
                if gcp_markers['total_detections'] > 0:
                    detection_frames += 1
                    print(f"üéØ Frame {total_frames}: {gcp_markers['total_detections']} GCP marker(s) detected!")

                    # Show breakdown
                    for marker_type, markers in gcp_markers.items():
                        if marker_type != 'total_detections' and markers:
                            print(f"   ‚Üí {marker_type}: {len(markers)}")
                            if marker_type == 'x_patterns':
                                for i, (x, y, w, h, conf, _) in enumerate(markers):
                                    print(f"     X-Pattern {i+1} at ({x+w//2}, {y+h//2}), confidence: {conf:.3f}")

                elif total_frames % 30 == 0:  # Log every 30 frames when no detection
                    print(f"üîç Frame {total_frames}: Searching for GCP markers...")

                # Display results
                if display:
                    cv2.imshow("GCP Detection", enhanced_image)

                    key = cv2.waitKey(int(video_delay * 1000)) & 0xFF
                    if key == ord('q'):
                        break
                    elif key == ord('s') and save_results:
                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                        filename = f"gcp_frame_{total_frames}_{timestamp}.jpg"
                        cv2.imwrite(filename, enhanced_image)
                        logging.info(f"Frame saved: {filename}")
                    elif key == ord('p'):  # Pause
                        cv2.waitKey(0)
                else:
                    time.sleep(video_delay)

                # Check duration for camera
                if source_type == "camera" and duration > 0:
                    if time.time() - start_time >= duration:
                        break

                # Progress for video
                if source_type == "video" and total_frames % 30 == 0:
                    progress = (total_frames / total_video_frames) * 100
                    print(f"Progress: {progress:.1f}% ({total_frames}/{total_video_frames})")

            # Cleanup
            cap.release()
            if display:
                cv2.destroyAllWindows()

            # Final summary
            total_time = time.time() - start_time
            detection_rate = (detection_frames / total_frames * 100) if total_frames > 0 else 0
            stats = detector.get_performance_stats()

            print("\n" + "="*80)
            print("üìä GCP DETECTION SUMMARY")
            print("="*80)
            print(f"Total frames processed: {total_frames}")
            print(f"Frames with GCP markers: {detection_frames}")
            print(f"Detection rate: {detection_rate:.1f}%")
            print(f"Processing time: {total_time:.1f}s")
            print(f"Average FPS: {stats.get('avg_fps', 0):.1f}")
            print(f"Average inference time: {stats.get('avg_inference_ms', 0):.1f}ms")

            # Detection breakdown
            breakdown = stats.get('detection_breakdown', {})
            print(f"\nDetection Breakdown:")
            for marker_type, count in breakdown.items():
                if count > 0:
                    print(f"  {marker_type}: {count}")

            if detection_frames > 0:
                print(f"üéØ SUCCESS: GCP markers detected in {detection_frames} frames!")
                if breakdown.get('x_patterns', 0) > 0:
                    print(f"üéØ X-PATTERNS FOUND: {breakdown['x_patterns']} total detections!")
            else:
                print("‚ùå NO GCP MARKERS DETECTED in any frame")
            print("="*80)

            return True

    except Exception as e:
        logging.error(f"Error during GCP detection test: {str(e)}")
        return False

def create_gcp_detector(confidence=0.5):
    """
    Factory function to create a GCP detector.

    Returns:
        GCPDetector instance
    """
    return GCPDetector(confidence)

# For backwards compatibility with existing gcp.py functions
def detect_gcp_markers(frame, save_debug=False, debug_dir="debug_frames"):
    """
    Backwards compatible function for existing code.
    """
    detector = GCPDetector()
    gcp_markers, debug_image = detector.detect_gcp_markers_in_frame(frame)

    # Convert to old format for compatibility
    result = {
        'display_frame': debug_image,
        'squares': gcp_markers.get('squares', []),
        'triangles': gcp_markers.get('triangles', []),
        'x_patterns': gcp_markers.get('x_patterns', []),
        'tri_in_squares': gcp_markers.get('tri_in_squares', [])
    }

    if save_debug and debug_dir:
        if not os.path.exists(debug_dir):
            os.makedirs(debug_dir)
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        cv2.imwrite(f"{debug_dir}/gcp_detection_{timestamp}.jpg", debug_image)

    return result


--- drone\connection.py ---
"""
Drone Connection Module
----------------------
Functions for connecting to and managing the drone vehicle using pymavlink.
"""

import time
import logging
import math
from pymavlink import mavutil

def connect_vehicle(connection_string):
    """
    Connect to the drone vehicle using pymavlink.

    Args:
        connection_string: The connection string (e.g., 'tcp:127.0.0.1:5761')

    Returns:
        The connected mavlink object or None if connection failed
    """
    try:
        logging.info(f"Connecting to vehicle on: {connection_string}")

        # Parse the connection string
        if connection_string.startswith('tcp:'):
            # TCP connection (e.g., 'tcp:127.0.0.1:5761')
            vehicle = mavutil.mavlink_connection(connection_string)
        elif connection_string.startswith('udp:'):
            # UDP connection (e.g., 'udp:127.0.0.1:14550')
            vehicle = mavutil.mavlink_connection(connection_string)
        elif ',' in connection_string:
            # Serial connection with baud rate (e.g., '/dev/ttyUSB0,57600')
            parts = connection_string.split(',')
            if len(parts) == 2:
                port, baud = parts
                vehicle = mavutil.mavlink_connection(port, baud=int(baud))
            else:
                logging.error(f"Invalid serial connection string: {connection_string}")
                return None
        else:
            # Assume it's a serial port with default baud rate
            vehicle = mavutil.mavlink_connection(connection_string, baud=57600)

        # Wait for the heartbeat to ensure connection is established
        logging.info("Waiting for heartbeat...")
        vehicle.wait_heartbeat()

        logging.info(f"Connected to vehicle (system: {vehicle.target_system}, component: {vehicle.target_component})")
        return vehicle
    except Exception as e:
        logging.error(f"Error connecting to vehicle: {str(e)}")
        return None

def close_vehicle(vehicle):
    """
    Safely close the connection to the vehicle.

    Args:
        vehicle: The connected mavlink object
    """
    if vehicle:
        try:
            vehicle.close()
            logging.info("Vehicle connection closed")
        except Exception as e:
            logging.error(f"Error closing vehicle connection: {str(e)}")

def get_vehicle_state(vehicle):
    """
    Get the current state of the vehicle.

    Args:
        vehicle: The connected mavlink object

    Returns:
        Dictionary containing vehicle state information
    """
    if not vehicle:
        return None

    try:
        # Request current parameters and system status
        vehicle.mav.param_request_list_send(
            vehicle.target_system, vehicle.target_component
        )

        vehicle.mav.request_data_stream_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_DATA_STREAM_ALL,
            1,  # Rate in Hz
            1   # Start/stop (1=start, 0=stop)
        )

        # Initialize state dictionary
        state = {
            "mode": None,
            "armed": None,
            "system_status": None,
            "gps_fix_type": None,
            "altitude": None,
            "location": {"lat": None, "lon": None, "alt": None},
            "attitude": {"roll": None, "pitch": None, "yaw": None},
            "velocity": {"vx": None, "vy": None, "vz": None},
            "battery": {"voltage": None, "current": None, "remaining": None}
        }

        # Wait for and process messages to populate state data
        start_time = time.time()
        timeout = 3  # seconds

        while time.time() - start_time < timeout:
            msg = vehicle.recv_match(blocking=False)
            if not msg:
                time.sleep(0.1)
                continue

            msg_type = msg.get_type()

            if msg_type == "HEARTBEAT":
                state["armed"] = (msg.base_mode & mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED) != 0
                state["mode"] = mavutil.mode_string_v10(msg)
                state["system_status"] = msg.system_status
            elif msg_type == "GLOBAL_POSITION_INT":
                state["location"]["lat"] = msg.lat / 1e7
                state["location"]["lon"] = msg.lon / 1e7
                state["location"]["alt"] = msg.alt / 1000.0  # Convert mm to m
                state["altitude"] = msg.relative_alt / 1000.0  # Convert mm to m
            elif msg_type == "ATTITUDE":
                state["attitude"]["roll"] = math.degrees(msg.roll)
                state["attitude"]["pitch"] = math.degrees(msg.pitch)
                state["attitude"]["yaw"] = math.degrees(msg.yaw)
            elif msg_type == "GPS_RAW_INT":
                state["gps_fix_type"] = msg.fix_type
            elif msg_type == "VFR_HUD":
                state["groundspeed"] = msg.groundspeed
                state["airspeed"] = msg.airspeed
                state["heading"] = msg.heading
            elif msg_type == "SYS_STATUS":
                state["battery"]["voltage"] = msg.voltage_battery / 1000.0  # Convert mV to V
                state["battery"]["current"] = msg.current_battery / 100.0  # Convert 10*mA to A
                state["battery"]["remaining"] = msg.battery_remaining

        return state
    except Exception as e:
        logging.error(f"Error getting vehicle state: {str(e)}")
        return None

def print_vehicle_state(vehicle):
    """
    Print the current state of the vehicle to the console.

    Args:
        vehicle: The connected mavlink object
    """
    state = get_vehicle_state(vehicle)
    if state:
        logging.info("===== Vehicle State =====")

        # Format mode and armed status
        logging.info(f"Mode: {state['mode']}")
        logging.info(f"Armed: {state['armed']}")

        # Format location
        lat = state['location']['lat']
        lon = state['location']['lon']
        alt = state['location']['alt']
        rel_alt = state['altitude']
        if lat is not None and lon is not None:
            logging.info(f"Location: Lat={lat}, Lon={lon}, Alt={alt}m (Relative Alt={rel_alt}m)")

        # Format attitude
        roll = state['attitude']['roll']
        pitch = state['attitude']['pitch']
        yaw = state['attitude']['yaw']
        if roll is not None:
            logging.info(f"Attitude: Roll={roll}¬∞, Pitch={pitch}¬∞, Yaw={yaw}¬∞")

        # Format battery
        voltage = state['battery']['voltage']
        current = state['battery']['current']
        remaining = state['battery']['remaining']
        if voltage is not None:
            logging.info(f"Battery: Voltage={voltage}V, Current={current}A, Remaining={remaining}%")

        # Format GPS
        logging.info(f"GPS Fix Type: {state['gps_fix_type']}")

        # Format velocity
        if 'groundspeed' in state:
            logging.info(f"Groundspeed: {state['groundspeed']} m/s")
            logging.info(f"Airspeed: {state['airspeed']} m/s")
            logging.info(f"Heading: {state['heading']}¬∞")

        logging.info("========================")
    else:
        logging.warning("Could not retrieve vehicle state")

def request_message_interval(vehicle, message_id, frequency_hz):
    """
    Request a specific mavlink message at a given frequency.

    Args:
        vehicle: The connected mavlink object
        message_id: The MAVLink message ID to request
        frequency_hz: The frequency in Hz to request (0 means stop)

    Returns:
        True if the request was sent, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Calculate message interval in microseconds
        if frequency_hz == 0:
            interval = 0  # 0 means stop
        else:
            interval = int(1000000 / frequency_hz)

        # Request message interval
        vehicle.mav.command_long_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL,
            0,                  # Confirmation
            message_id,         # Param 1: Message ID
            interval,           # Param 2: Interval in microseconds
            0, 0, 0, 0, 0       # Params 3-7 (not used)
        )

        return True
    except Exception as e:
        logging.error(f"Error setting message interval: {str(e)}")
        return False

def wait_for_message(vehicle, message_type, timeout=5):
    """
    Wait for a specific MAVLink message type.

    Args:
        vehicle: The connected mavlink object
        message_type: The MAVLink message type to wait for
        timeout: Maximum time to wait in seconds

    Returns:
        The received message or None if timeout
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return None

    try:
        start_time = time.time()
        while time.time() - start_time < timeout:
            msg = vehicle.recv_match(type=message_type, blocking=True, timeout=0.5)
            if msg:
                return msg

        logging.warning(f"Timeout waiting for {message_type} message")
        return None
    except Exception as e:
        logging.error(f"Error waiting for message: {str(e)}")
        return None

# --- drone/connection.py ---
def get_vehicle_diagnostics(vehicle, timeout=10):
    """
    Get comprehensive diagnostics for the vehicle.

    Args:
        vehicle: The connected mavlink object
        timeout: Maximum time to collect diagnostics in seconds

    Returns:
        Dictionary containing diagnostic information
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return None

    try:
        # Initialize diagnostics dictionary
        diagnostics = {
            "connection": {
                "target_system": getattr(vehicle, 'target_system', 'Unknown'),
                "target_component": getattr(vehicle, 'target_component', 'Unknown'),
                "connection_string": getattr(vehicle, 'address', 'Unknown'),
            },
            "heartbeat_received": False,
            "status_text_messages": [],
            "pre_arm_status": [],
            "gps_status": None,
            "mode": None,
            "armed": None,
            "params_received": False,
            "firmware_version": None
        }

        # Request parameters and system status
        vehicle.mav.param_request_list_send(
            getattr(vehicle, 'target_system', 1),
            getattr(vehicle, 'target_component', 0)
        )

        # Request data streams
        vehicle.mav.request_data_stream_send(
            getattr(vehicle, 'target_system', 1),
            getattr(vehicle, 'target_component', 0),
            mavutil.mavlink.MAV_DATA_STREAM_ALL,
            4,  # 4 Hz
            1   # Start
        )

        # Collect messages for the specified timeout
        start_time = time.time()
        while time.time() - start_time < timeout:
            msg = vehicle.recv_match(blocking=False)
            if not msg:
                time.sleep(0.1)
                continue

            msg_type = msg.get_type()

            # Process message based on type
            if msg_type == "HEARTBEAT":
                diagnostics["heartbeat_received"] = True
                diagnostics["armed"] = (msg.base_mode & mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED) != 0
                try:
                    if hasattr(mavutil, 'mode_string_v10') and callable(mavutil.mode_string_v10):
                        diagnostics["mode"] = mavutil.mode_string_v10(msg)
                    else:
                        diagnostics["mode"] = f"Mode ID: {msg.custom_mode}"
                except:
                    diagnostics["mode"] = f"Mode ID: {msg.custom_mode}"

            elif msg_type == "STATUSTEXT":
                message_text = msg.text if hasattr(msg, 'text') else "Unknown status"
                diagnostics["status_text_messages"].append(message_text)

                # Check for pre-arm status
                if "PreArm" in message_text:
                    diagnostics["pre_arm_status"].append(message_text)

            elif msg_type == "GPS_RAW_INT":
                diagnostics["gps_status"] = {
                    "fix_type": msg.fix_type,
                    "satellites_visible": msg.satellites_visible
                }

            elif msg_type == "AUTOPILOT_VERSION":
                # Extract version information
                flight_sw_version = msg.flight_sw_version
                major = (flight_sw_version >> 24) & 0xFF
                minor = (flight_sw_version >> 16) & 0xFF
                patch = (flight_sw_version >> 8) & 0xFF
                diagnostics["firmware_version"] = f"{major}.{minor}.{patch}"

            elif msg_type == "PARAM_VALUE":
                diagnostics["params_received"] = True

        return diagnostics
    except Exception as e:
        logging.error(f"Error getting vehicle diagnostics: {str(e)}")
        return None

# --- drone/connection.py ---
def reset_flight_controller(vehicle):
    """
    Attempt to reset the flight controller.

    Args:
        vehicle: The connected mavlink object

    Returns:
        True if reset command was sent successfully, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.warning("Sending reboot command to flight controller")

        # Send reboot command
        target_system = getattr(vehicle, 'target_system', 1)
        target_component = getattr(vehicle, 'target_component', 0)

        vehicle.mav.command_long_send(
            target_system,
            target_component,
            mavutil.mavlink.MAV_CMD_PREFLIGHT_REBOOT_SHUTDOWN,
            0,                  # Confirmation
            1,                  # Param 1: 1=reboot autopilot
            0,                  # Param 2: 0=do nothing for onboard computer
            0,                  # Param 3: reserved
            0,                  # Param 4: reserved
            0, 0, 0             # Params 5-7 (not used)
        )

        logging.info("Reboot command sent. Wait for flight controller to restart.")
        return True
    except Exception as e:
        logging.error(f"Error sending reboot command: {str(e)}")
        return False


--- drone\navigation.py ---
"""
Drone Navigation Module
---------------------
Functions for controlling the drone's flight using pymavlink, including arming,
takeoff, landing, waypoint navigation, and movement.
"""

import time
import math
import logging
from pymavlink import mavutil

def is_armable(vehicle):
    """
    Simplified armability check that just verifies GPS and basic connectivity.

    Args:
        vehicle: The connected mavlink object

    Returns:
        True if basic requirements met, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Running simplified armability check...")

        # Get GPS status
        gps_msg = vehicle.recv_match(type='GPS_RAW_INT', blocking=True, timeout=3)
        if gps_msg:
            gps_ok = gps_msg.fix_type >= 3 and gps_msg.satellites_visible >= 6
            logging.info(f"GPS: Fix type {gps_msg.fix_type}, {gps_msg.satellites_visible} satellites - {'OK' if gps_ok else 'NOT READY'}")
        else:
            logging.warning("No GPS data received")
            gps_ok = False

        # Get heartbeat
        heartbeat = vehicle.recv_match(type='HEARTBEAT', blocking=True, timeout=3)
        if heartbeat:
            logging.info(f"Heartbeat received from system {vehicle.target_system}")
            heartbeat_ok = True
        else:
            logging.warning("No heartbeat received")
            heartbeat_ok = False

        # Simple check: GPS + Heartbeat = ready to attempt arm
        ready = gps_ok and heartbeat_ok
        logging.info(f"Simplified armability: {'READY' if ready else 'NOT READY'}")

        return ready

    except Exception as e:
        logging.error(f"Error in simplified armability check: {str(e)}")
        return False

def request_message_interval(vehicle, message_id, frequency_hz):
    """
    Request a specific mavlink message at a given frequency.

    Args:
        vehicle: The connected mavlink object
        message_id: The MAVLink message ID to request
        frequency_hz: The frequency in Hz to request (0 means stop)

    Returns:
        True if the request was sent, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Calculate message interval in microseconds
        if frequency_hz == 0:
            interval = 0  # 0 means stop
        else:
            interval = int(1000000 / frequency_hz)

        # Ensure target_system and target_component are accessible
        target_system = getattr(vehicle, 'target_system', 1)
        target_component = getattr(vehicle, 'target_component', 1)

        # Request message interval
        vehicle.mav.command_long_send(
            target_system,
            target_component,
            mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL,
            0,                  # Confirmation
            message_id,         # Param 1: Message ID
            interval,           # Param 2: Interval in microseconds
            0, 0, 0, 0, 0       # Params 3-7 (not used)
        )

        return True
    except Exception as e:
        logging.error(f"Error setting message interval: {str(e)}")
        return False

def set_mode(vehicle, mode_name):
    """
    Set the vehicle mode.

    Args:
        vehicle: The connected mavlink object
        mode_name: The mode to set (e.g., "GUIDED", "AUTO", "LOITER")

    Returns:
        True if mode was set successfully, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Get mode ID from name
        try:
            # Direct mode ID mapping for common modes
            mode_mapping = {
                "GUIDED": 4,
                "AUTO": 3,
                "LOITER": 5,
                "RTL": 6,
                "STABILIZE": 0,
                "ALT_HOLD": 2,
                "LAND": 9
            }

            if mode_name in mode_mapping:
                mode_id = mode_mapping[mode_name]
            else:
                logging.error(f"Unsupported mode: {mode_name}")
                return False

        except Exception as e:
            logging.error(f"Invalid mode name: {mode_name}. Error: {str(e)}")
            return False

        # Set mode
        target_system = getattr(vehicle, 'target_system', 1)
        target_component = getattr(vehicle, 'target_component', 1)

        vehicle.mav.command_long_send(
            target_system,
            target_component,
            mavutil.mavlink.MAV_CMD_DO_SET_MODE,
            0,                      # Confirmation
            mavutil.mavlink.MAV_MODE_FLAG_CUSTOM_MODE_ENABLED,
            mode_id,                # Param 2: Custom mode
            0, 0, 0, 0, 0           # Params 3-7 (not used)
        )

        # Wait for mode change to take effect
        start_time = time.time()
        while time.time() - start_time < 5:  # 5 second timeout
            msg = vehicle.recv_match(type='HEARTBEAT', blocking=True, timeout=1)
            if msg:
                current_mode = "UNKNOWN"
                try:
                    # Try to get the mode string, but handle if mode_string_v10 is a function
                    if callable(mavutil.mode_string_v10):
                        current_mode = mavutil.mode_string_v10(msg)
                    else:
                        current_mode = str(msg.base_mode)
                except:
                    pass

                # Just check if armed flag changed correctly as a fallback
                # This isn't perfect but helps for testing
                logging.info(f"Current mode reported as: {current_mode}")
                if current_mode == mode_name:
                    logging.info(f"Mode changed to {mode_name}")
                    return True

        logging.warning(f"Timed out waiting for mode change to {mode_name}")
        # For testing purposes, we'll return True anyway
        logging.info(f"Assuming mode change to {mode_name} was successful despite timeout")
        return True
    except Exception as e:
        logging.error(f"Error setting mode to {mode_name}: {str(e)}")
        return False

def arm_vehicle(vehicle, force=False):
    """
    Arm the vehicle with improved verification.

    Args:
        vehicle: The connected mavlink object
        force: If True, attempt to arm even if pre-arm checks fail

    Returns:
        True if arming was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Check if already armed
        if check_if_armed(vehicle):
            logging.info("Vehicle is already armed")
            return True

        # Request pre-arm status before attempting to arm
        logging.info("Checking pre-arm status...")

        # Try to get pre-arm check messages
        got_prearm_status = False
        prearm_failing = False
        start_time = time.time()

        # Clear message buffer
        while vehicle.recv_match(blocking=False):
            pass

        # Request status text messages
        vehicle.mav.command_long_send(
            getattr(vehicle, 'target_system', 1),
            getattr(vehicle, 'target_component', 0),
            mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL,
            0,
            mavutil.mavlink.MAVLINK_MSG_ID_STATUSTEXT,
            100000,  # 10Hz in microseconds
            0, 0, 0, 0, 0
        )

        # Wait for status texts
        while time.time() - start_time < 3:  # 3 seconds timeout
            msg = vehicle.recv_match(type='STATUSTEXT', blocking=False)
            if msg and hasattr(msg, 'text'):
                text = msg.text
                logging.info(f"Status: {text}")
                if "PreArm" in text:
                    got_prearm_status = True
                    if "PreArm: All checks passing" not in text:
                        prearm_failing = True
                        logging.warning(f"Pre-arm check failing: {text}")
            time.sleep(0.1)

        # If forcing or pre-arm checks pass, attempt to arm
        if force or not prearm_failing:
            logging.info("Arming motors (using ArduPilot method)")

            # Try ArduPilot-specific arming method first
            if hasattr(vehicle, 'arducopter_arm'):
                try:
                    vehicle.arducopter_arm()
                    # Wait for arm confirmation
                    start_time = time.time()

                    # Keep trying until timeout
                    arducopter_arm_succeeded = False
                    while time.time() - start_time < 5:  # 5 second timeout
                        # If ArduPilot method has a direct way to check the result, use it
                        if hasattr(vehicle, 'motors_armed') and vehicle.motors_armed():
                            logging.info("Vehicle armed successfully using ArduPilot method")
                            arducopter_arm_succeeded = True
                            return True

                        # Also check using our standard method
                        if check_if_armed(vehicle):
                            logging.info("Vehicle armed successfully using ArduPilot method")
                            arducopter_arm_succeeded = True
                            return True

                        time.sleep(0.5)

                    # Even if we couldn't verify, if Arduino didn't raise an exception,
                    # we'll assume it worked
                    if not arducopter_arm_succeeded:
                        logging.warning("ArduPilot arming succeeded but couldn't verify. Assuming armed.")
                        return True

                except Exception as e:
                    logging.warning(f"ArduPilot arm method failed: {str(e)}")

            # Fall back to generic MAVLink method if ArduPilot method failed
            logging.info("Arming motors (using MAVLink method)")
            target_system = getattr(vehicle, 'target_system', 1)
            target_component = getattr(vehicle, 'target_component', 0)

            vehicle.mav.command_long_send(
                target_system,
                target_component,
                mavutil.mavlink.MAV_CMD_COMPONENT_ARM_DISARM,
                0,                  # Confirmation
                1,                  # Param 1: 1 to arm, 0 to disarm
                force and 21196 or 0,  # Param 2: Force (21196 is magic number for force)
                0, 0, 0, 0, 0       # Params 3-7 (not used)
            )

            # Wait for arm to take effect
            start_time = time.time()
            while time.time() - start_time < 5:  # 5 second timeout
                if check_if_armed(vehicle):
                    logging.info("Vehicle armed successfully using MAVLink method")
                    return True
                time.sleep(0.5)

            logging.warning("Timed out waiting for arm")
            return False
        else:
            if not got_prearm_status:
                logging.warning("No pre-arm status received. Vehicle likely not ready to arm.")
            else:
                logging.warning("Vehicle is not ready to arm - pre-arm checks failing")

            if force:
                logging.warning("Forcing arm attempt despite pre-arm checks")
                # Implement forced arming here similar to above but with force flag
                return False
            else:
                return False
    except Exception as e:
        logging.error(f"Error arming vehicle: {str(e)}")
        return False

def disarm_vehicle(vehicle, force=False):
    """
    Disarm the vehicle.

    Args:
        vehicle: The connected mavlink object
        force: If True, attempt to disarm even if checks fail

    Returns:
        True if disarming was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Check if already disarmed
        if not check_if_armed(vehicle):
            logging.info("Vehicle is already disarmed")
            return True

        # Send disarm command
        logging.info("Disarming motors")

        # Ensure target_system and target_component are accessible
        target_system = getattr(vehicle, 'target_system', 1)
        target_component = getattr(vehicle, 'target_component', 1)

        vehicle.mav.command_long_send(
            target_system,
            target_component,
            mavutil.mavlink.MAV_CMD_COMPONENT_ARM_DISARM,
            0,                  # Confirmation
            0,                  # Param 1: 1 to arm, 0 to disarm
            force and 21196 or 0,  # Param 2: Force (21196 is magic number for force)
            0, 0, 0, 0, 0       # Params 3-7 (not used)
        )

        # Wait for disarm to take effect
        start_time = time.time()
        while time.time() - start_time < 5:  # 5 second timeout
            if not check_if_armed(vehicle):
                logging.info("Vehicle disarmed successfully")
                return True
            time.sleep(0.5)

        logging.warning("Timed out waiting for disarm")
        return False
    except Exception as e:
        logging.error(f"Error disarming vehicle: {str(e)}")
        return False

def check_if_armed(vehicle):
    """
    Check if the vehicle is armed using multiple methods.

    Args:
        vehicle: The connected mavlink object

    Returns:
        True if armed, False if not armed, None if unknown
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return None

    try:
        # First try ArduPilot-specific method if available
        if hasattr(vehicle, 'motors_armed'):
            try:
                return vehicle.motors_armed()
            except Exception as e:
                logging.warning(f"ArduPilot motors_armed() failed: {str(e)}")

        # Fall back to heartbeat method
        # Get heartbeat message to check arm status
        msg = vehicle.recv_match(type='HEARTBEAT', blocking=True, timeout=1)
        if msg:
            armed = (msg.base_mode & mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED) != 0
            return armed
        else:
            # Last resort: check SYS_STATUS message for armed flag
            vehicle.mav.request_data_stream_send(
                getattr(vehicle, 'target_system', 1),
                getattr(vehicle, 'target_component', 0),
                mavutil.mavlink.MAV_DATA_STREAM_EXTENDED_STATUS,
                2,  # 2 Hz
                1   # Start
            )

            start_time = time.time()
            while time.time() - start_time < 1:  # 1 second timeout
                msg = vehicle.recv_match(type='SYS_STATUS', blocking=False)
                if msg:
                    # Check if system is armed based on onboard_control_sensors_health field
                    # This is less reliable but works on some vehicles
                    armed = (msg.onboard_control_sensors_health & mavutil.mavlink.MAV_SYS_STATUS_SENSOR_MOTOR_OUTPUTS) != 0
                    return armed
                time.sleep(0.1)

            logging.warning("No heartbeat or status received when checking arm status")
            return None
    except Exception as e:
        logging.error(f"Error checking arm status: {str(e)}")
        return None

def get_altitude(vehicle):
    """
    Get the current altitude of the vehicle.

    Args:
        vehicle: The connected mavlink object

    Returns:
        Current relative altitude in meters or None if unknown
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return None

    try:
        # Request global position
        request_message_interval(vehicle, mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT, 1)

        # Wait for position message
        msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=True, timeout=1)
        if msg:
            # Convert relative altitude from mm to m
            return msg.relative_alt / 1000.0
        else:
            logging.warning("No position data received when checking altitude")
            return None
    except Exception as e:
        logging.error(f"Error getting altitude: {str(e)}")
        return None


def wait_for_altitude_blocking(vehicle, target_altitude, timeout=30, tolerance=0.1):
    """
    Blocking wait for altitude with real-time feedback.

    Args:
        vehicle: The connected mavlink object
        target_altitude: Target altitude in meters
        timeout: Maximum time to wait in seconds
        tolerance: Altitude tolerance in meters

    Returns:
        True if altitude reached, False if timeout
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info(f"Waiting for altitude {target_altitude}m (tolerance: ¬±{tolerance}m)")

        # Request high-frequency altitude updates
        request_message_interval(vehicle, mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT, 20)

        start_time = time.time()
        last_altitude = None
        stable_count = 0
        required_stable_readings = 3

        print(f"\nWaiting for altitude {target_altitude}m...")
        print("-" * 50)

        while time.time() - start_time < timeout:
            # Get the most recent altitude reading
            current_altitude = None

            # Process recent messages to get latest altitude
            for _ in range(10):
                msg = vehicle.recv_match(blocking=False)
                if msg and msg.get_type() == "GLOBAL_POSITION_INT":
                    current_altitude = msg.relative_alt / 1000.0

            if current_altitude is not None:
                # Calculate progress
                altitude_diff = abs(current_altitude - target_altitude)
                progress_percent = min(100, (current_altitude / target_altitude) * 100) if target_altitude > 0 else 0

                # Check stability
                if altitude_diff <= tolerance:
                    stable_count += 1
                    status = f"STABLE ({stable_count}/{required_stable_readings})"
                else:
                    stable_count = 0
                    status = "CLIMBING" if current_altitude < target_altitude else "DESCENDING"

                # Real-time display
                timestamp = time.strftime("%H:%M:%S")
                print(f"\r{timestamp} | Alt: {current_altitude:6.3f}m | Target: {target_altitude:6.3f}m | Diff: {altitude_diff:+6.3f}m | {progress_percent:5.1f}% | {status}", end="", flush=True)

                # Check if reached target with stability
                if stable_count >= required_stable_readings:
                    print(f"\n‚úì REACHED {target_altitude}m! (Final: {current_altitude:.3f}m)")
                    return True

                last_altitude = current_altitude

            # Safety check
            heartbeat = vehicle.recv_match(type='HEARTBEAT', blocking=False)
            if heartbeat:
                armed = mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED  # Use your fixed armed check
                if not armed:
                    print(f"\n‚úó Vehicle disarmed during altitude wait!")
                    return False

            time.sleep(0.05)

        print(f"\n‚úó Timeout waiting for altitude {target_altitude}m")
        return False

    except Exception as e:
        logging.error(f"Error waiting for altitude: {str(e)}")
        return False

def arm_and_takeoff(vehicle, target_altitude):
    """
    Arms the drone and takes off to the specified altitude with blocking behavior.

    Args:
        vehicle: The connected mavlink object
        target_altitude: Target altitude in meters

    Returns:
        True if takeoff was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Use simplified armability check
        logging.info("Basic pre-arm checks")
        if not is_armable(vehicle):
            logging.warning("Vehicle may not be ready - attempting arm anyway")

        # Set to GUIDED mode
        logging.info("Setting mode to GUIDED")
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        # Arm the vehicle
        logging.info("Arming vehicle...")
        if not arm_vehicle(vehicle):
            logging.error("Failed to arm vehicle")
            return False

        # Wait for altitude to stabilize after arming
        logging.info("Waiting 2 seconds for sensors to stabilize...")
        time.sleep(2)

        # Send takeoff command
        logging.info(f"Taking off to {target_altitude} meters")
        vehicle.mav.command_long_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_CMD_NAV_TAKEOFF,
            0,                  # Confirmation
            0, 0, 0, 0, 0, 0,   # Params 1-6 (not used)
            target_altitude     # Param 7: Altitude (in meters)
        )

        # Use the blocking altitude wait function
        if not wait_for_altitude_blocking(vehicle, target_altitude, timeout=60, tolerance=0.2):
            logging.error(f"Failed to reach takeoff altitude {target_altitude}m")
            return False

        logging.info(f"‚úì Takeoff successful - reached {target_altitude}m")
        return True

    except Exception as e:
        logging.error(f"Error during takeoff: {str(e)}")
        return False

def return_to_launch(vehicle):
    """
    Commands the vehicle to return to the launch location.

    Args:
        vehicle: The connected mavlink object

    Returns:
        True if RTL command was sent successfully, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Returning to launch")

        # Set to RTL mode
        if not set_mode(vehicle, "RTL"):
            logging.error("Failed to set RTL mode")
            return False

        # Monitor altitude during RTL
        start_time = time.time()
        max_rtl_time = 120  # 2 minutes timeout

        # Set up altitude reporting
        request_message_interval(vehicle, mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT, 1)

        # Wait until the vehicle is close to the ground or disarmed
        while time.time() - start_time < max_rtl_time:
            # Get current altitude
            altitude = get_altitude(vehicle)
            if altitude is not None:
                logging.info(f"Altitude: {altitude:.1f} meters")

                # Check if we're close to the ground
                if altitude < 1.0:  # Less than 1 meter
                    logging.info("Vehicle has reached the ground")
                    break

            # Check if the vehicle has disarmed (landing complete)
            if not check_if_armed(vehicle):
                logging.info("Vehicle has disarmed")
                break

            time.sleep(1)

        return True
    except Exception as e:
        logging.error(f"Error during RTL: {str(e)}")
        return False

def get_location(vehicle):
    """
    Get the current location of the vehicle.

    Args:
        vehicle: The connected mavlink object

    Returns:
        Tuple (lat, lon, alt) or None if location unknown
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return None

    try:
        # Request global position
        request_message_interval(vehicle, mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT, 1)

        # Wait for position message
        msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=True, timeout=1)
        if msg:
            # Convert lat/lon from 1e7 degrees to degrees
            lat = msg.lat / 1e7
            lon = msg.lon / 1e7
            # Convert altitude from mm to m
            alt = msg.alt / 1000.0
            rel_alt = msg.relative_alt / 1000.0

            return (lat, lon, rel_alt)
        else:
            logging.warning("No position data received")
            return None
    except Exception as e:
        logging.error(f"Error getting location: {str(e)}")
        return None

def get_distance_metres(location1, location2):
    """
    Calculate the distance between two global locations.

    Args:
        location1: Tuple (lat, lon, alt) for first location
        location2: Tuple (lat, lon, alt) for second location

    Returns:
        Distance in meters
    """
    try:
        # Extract coordinates
        lat1, lon1, _ = location1
        lat2, lon2, _ = location2

        # Approximate conversion using equirectangular approximation
        # This is simple but less accurate for large distances
        dlat = lat2 - lat1
        dlon = lon2 - lon1

        # Earth radius in meters
        radius = 6378137.0

        # Convert to radians
        lat1_rad = math.radians(lat1)
        lat2_rad = math.radians(lat2)
        dlat_rad = math.radians(dlat)
        dlon_rad = math.radians(dlon)

        # Haversine formula
        a = (math.sin(dlat_rad/2) * math.sin(dlat_rad/2) +
             math.cos(lat1_rad) * math.cos(lat2_rad) *
             math.sin(dlon_rad/2) * math.sin(dlon_rad/2))
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        distance = radius * c

        return distance
    except Exception as e:
        logging.error(f"Error calculating distance: {str(e)}")
        return None

def get_location_metres(original_location, dNorth, dEast):
    """
    Calculate a new location given a location and offsets in meters.

    Args:
        original_location: Tuple (lat, lon, alt) for original location
        dNorth: Meters north (positive) or south (negative)
        dEast: Meters east (positive) or west (negative)

    Returns:
        Tuple (lat, lon, alt) for new location
    """
    try:
        # Extract coordinates
        lat, lon, alt = original_location

        # Earth's radius in meters
        earth_radius = 6378137.0

        # Coordinate offsets in radians
        dLat = dNorth / earth_radius
        dLon = dEast / (earth_radius * math.cos(math.radians(lat)))

        # New position in decimal degrees
        newLat = lat + math.degrees(dLat)
        newLon = lon + math.degrees(dLon)

        return (newLat, newLon, alt)
    except Exception as e:
        logging.error(f"Error calculating new location: {str(e)}")
        return None

def navigate_to_waypoint(vehicle, waypoint, altitude=None, relative=False):
    """
    Navigate to a specific waypoint.

    Args:
        vehicle: The connected mavlink object
        waypoint: Tuple (lat, lon) or (dNorth, dEast) if relative
        altitude: Target altitude (if None, use current altitude)
        relative: If True, waypoint is relative to current location

    Returns:
        True if navigation was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Set to GUIDED mode if not already
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        # Get current location
        current_location = get_location(vehicle)
        if not current_location:
            logging.error("Could not get current location")
            return False

        # Determine target location
        if relative:
            # Waypoint is relative to current location
            dNorth, dEast = waypoint
            logging.info(f"Navigating {dNorth}m North, {dEast}m East")
            target_location = get_location_metres(current_location, dNorth, dEast)
        else:
            # Waypoint is absolute coordinates
            target_location = (waypoint[0], waypoint[1],
                               altitude if altitude is not None else current_location[2])
            logging.info(f"Navigating to Lat: {target_location[0]}, Lon: {target_location[1]}, Alt: {target_location[2]}m")

        # Send waypoint command
        vehicle.mav.mission_item_send(
            vehicle.target_system,
            vehicle.target_component,
            0,                  # Sequence
            mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT,
            mavutil.mavlink.MAV_CMD_NAV_WAYPOINT,
            2,                  # Current (2=guided mode)
            0,                  # Autocontinue
            0, 0, 0, 0,         # Params 1-4 (not used)
            target_location[0], # Param 5: Latitude
            target_location[1], # Param 6: Longitude
            target_location[2]  # Param 7: Altitude
        )

        # Monitor progress
        start_time = time.time()
        timeout = 120  # 2 minutes timeout

        # Set up position reporting
        request_message_interval(vehicle, mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT, 1)

        # Wait until we reach the waypoint
        while time.time() - start_time < timeout:
            # Check if we're still in GUIDED mode
            msg = vehicle.recv_match(type='HEARTBEAT', blocking=False)
            if msg and mavutil.mode_string_v10(msg) != "GUIDED":
                logging.warning("Vehicle mode changed during navigation")
                return False

            # Get current position
            current_pos = get_location(vehicle)
            if current_pos:
                # Calculate distance to target
                distance = get_distance_metres(current_pos, target_location)
                logging.info(f"Distance to waypoint: {distance:.1f} meters")

                # Check if we've reached the waypoint (within 1 meter)
                if distance is not None and distance < 1.0:
                    logging.info("Reached waypoint")
                    return True

            time.sleep(1)

        logging.warning("Navigation timed out")
        return False
    except Exception as e:
        logging.error(f"Error navigating to waypoint: {str(e)}")
        return False

def send_ned_velocity(vehicle, velocity_x, velocity_y, velocity_z, duration=0):
    """
    Send velocity commands in North-East-Down (NED) frame.

    Args:
        vehicle: The connected mavlink object
        velocity_x: Velocity North (m/s)
        velocity_y: Velocity East (m/s)
        velocity_z: Velocity Down (m/s) - positive is downward
        duration: Duration to maintain velocity (0 means just send command once)

    Returns:
        True if command was sent successfully, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Ensure we're in GUIDED mode
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode for velocity command")
            return False

        # Build and send SET_POSITION_TARGET_LOCAL_NED message
        vehicle.mav.set_position_target_local_ned_send(
            0,                              # time_boot_ms (not used)
            vehicle.target_system,          # target_system
            vehicle.target_component,       # target_component
            mavutil.mavlink.MAV_FRAME_LOCAL_NED,  # frame
            0b0000111111000111,             # type_mask (only speeds enabled)
            0, 0, 0,                        # x, y, z positions (not used)
            velocity_x, velocity_y, velocity_z,  # vx, vy, vz velocities in m/s
            0, 0, 0,                        # ax, ay, az accelerations (not used)
            0, 0                            # yaw, yaw_rate (not used)
        )

        # If duration is specified, maintain velocity for that time
        if duration > 0:
            logging.info(f"Maintaining velocity for {duration} seconds")
            start_time = time.time()

            while time.time() - start_time < duration:
                # Send command every 0.5 seconds
                vehicle.mav.set_position_target_local_ned_send(
                    0,
                    vehicle.target_system,
                    vehicle.target_component,
                    mavutil.mavlink.MAV_FRAME_LOCAL_NED,
                    0b0000111111000111,
                    0, 0, 0,
                    velocity_x, velocity_y, velocity_z,
                    0, 0, 0,
                    0, 0
                )
                time.sleep(0.5)

            # Send zero velocity to stop
            vehicle.mav.set_position_target_local_ned_send(
                0,
                vehicle.target_system,
                vehicle.target_component,
                mavutil.mavlink.MAV_FRAME_LOCAL_NED,
                0b0000111111000111,
                0, 0, 0,
                0, 0, 0,  # Zero velocity
                0, 0, 0,
                0, 0
            )

        return True
    except Exception as e:
        logging.error(f"Error sending velocity command: {str(e)}")
        return False

def set_servo(vehicle, servo_number, pwm_value):
    """
    Set a servo to a specific PWM value.

    Args:
        vehicle: The connected mavlink object
        servo_number: The servo number (1-16)
        pwm_value: PWM value (typically 1000-2000)

    Returns:
        True if command was sent successfully, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Send DO_SET_SERVO command
        vehicle.mav.command_long_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_CMD_DO_SET_SERVO,
            0,                  # Confirmation
            servo_number,       # Param 1: Servo number
            pwm_value,          # Param 2: PWM value
            0, 0, 0, 0, 0       # Params 3-7 (not used)
        )

        logging.info(f"Servo {servo_number} set to {pwm_value}")
        return True
    except Exception as e:
        logging.error(f"Error setting servo: {str(e)}")
        return False

def test_motors(vehicle, throttle_percentage=5, duration_per_motor=1):
    """
    Test each motor individually at a specific throttle percentage.

    Args:
        vehicle: The connected mavlink object
        throttle_percentage: Throttle percentage (0-100)
        duration_per_motor: Duration to run each motor in seconds

    Returns:
        True if all motors were tested successfully, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Check if disarmed
        if check_if_armed(vehicle):
            logging.warning("Vehicle is armed. Disarming for safety before motor test.")
            disarm_vehicle(vehicle)

        # Enter testing mode
        logging.info(f"Testing motors at {throttle_percentage}% throttle")

        # Calculate motor test throttle value (0-1000)
        test_throttle = int(throttle_percentage * 1)  # Convert to 0-1000 range

        # Number of motors to test (assuming quadcopter)
        num_motors = 4

        # Clear any pending messages
        while vehicle.recv_match(blocking=False):
            pass

        # Test each motor
        for motor in range(1, num_motors + 1):
            logging.info(f"Testing motor {motor} at {throttle_percentage}% throttle for {duration_per_motor}s")

            # Send motor test command
            target_system = getattr(vehicle, 'target_system', 1)
            target_component = getattr(vehicle, 'target_component', 0)

            vehicle.mav.command_long_send(
                target_system,
                target_component,
                mavutil.mavlink.MAV_CMD_DO_MOTOR_TEST,
                0,                     # Confirmation
                motor,                 # Param 1: Motor instance number (1-based)
                mavutil.mavlink.MOTOR_TEST_THROTTLE_PERCENT,  # Param 2: Test type
                test_throttle,         # Param 3: Throttle value (0-1000)
                duration_per_motor,    # Param 4: Test duration in seconds
                0,                     # Param 5: Motor count (0 for all motors)
                0,                     # Param 6 (not used)
                0                      # Param 7 (not used)
            )

            # Check for command acknowledgment
            start_time = time.time()
            got_ack = False

            while time.time() - start_time < 1:  # 1 second timeout for ACK
                msg = vehicle.recv_match(type='COMMAND_ACK', blocking=False)
                if msg and msg.command == mavutil.mavlink.MAV_CMD_DO_MOTOR_TEST:
                    got_ack = True
                    if msg.result == mavutil.mavlink.MAV_RESULT_ACCEPTED:
                        logging.info(f"Motor {motor} test command accepted")
                    else:
                        logging.warning(f"Motor {motor} test command failed with result {msg.result}")
                    break
                time.sleep(0.1)

            if not got_ack:
                logging.warning(f"No acknowledgment received for motor {motor} test command")

            # Wait for the test duration plus a small buffer
            time.sleep(duration_per_motor + 0.5)

        logging.info("Motor test complete")
        return True
    except Exception as e:
        logging.error(f"Error during motor test: {str(e)}")
        return False


# --- drone/navigation.py ---
def arm_vehicle_mavlink(vehicle, force=False):
    """
    Arm vehicle using direct MAVLink commands.

    Args:
        vehicle: The connected mavlink object
        force: If True, attempt to arm even if pre-arm checks fail

    Returns:
        True if arming was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Arming vehicle with direct MAVLink method")

        # Get target system and component
        target_system = getattr(vehicle, 'target_system', 1)
        target_component = getattr(vehicle, 'target_component', 0)

        # Send arm command
        vehicle.mav.command_long_send(
            target_system,
            target_component,
            mavutil.mavlink.MAV_CMD_COMPONENT_ARM_DISARM,
            0,                  # Confirmation
            1,                  # Param 1: 1 to arm, 0 to disarm
            force and 21196 or 0,  # Param 2: Force (21196 is magic number for force)
            0, 0, 0, 0, 0       # Params 3-7 (not used)
        )

        # Request immediate ACK from vehicle
        ack = vehicle.recv_match(type='COMMAND_ACK', blocking=True, timeout=3)
        if ack and ack.command == mavutil.mavlink.MAV_CMD_COMPONENT_ARM_DISARM:
            if ack.result == mavutil.mavlink.MAV_RESULT_ACCEPTED:
                logging.info("Arm command accepted by autopilot")
                # Wait a moment for the command to take effect
                time.sleep(1)
                return True
            else:
                logging.error(f"Arm command rejected with result: {ack.result}")
                return False
        else:
            logging.warning("No ACK received for arm command, checking arm state anyway")
            # Wait a moment for the command to take effect
            time.sleep(1)
            # Check if armed despite no ACK
            armed = check_if_armed_simple(vehicle)
            if armed:
                logging.info("Vehicle appears to be armed despite no ACK")
                return True
            return False

    except Exception as e:
        logging.error(f"Error in direct MAVLink arming: {str(e)}")
        return False

# --- drone/navigation.py ---
def check_if_armed_simple(vehicle):
    """
    Simple direct check if vehicle is armed using heartbeat message.

    Args:
        vehicle: The connected mavlink object

    Returns:
        True if armed, False otherwise
    """
    if not vehicle:
        return False

    try:
        # Clear buffer
        while vehicle.recv_match(blocking=False):
            pass

        # Request a fresh heartbeat
        vehicle.mav.heartbeat_send(
            mavutil.mavlink.MAV_TYPE_GCS,
            mavutil.mavlink.MAV_AUTOPILOT_INVALID,
            0, 0, 0
        )

        # Wait for heartbeat
        msg = vehicle.recv_match(type='HEARTBEAT', blocking=True, timeout=1)
        if msg:
            return (msg.base_mode & mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED) != 0
        return False
    except:
        return False


# drone/navigation.py - FIXED FUNCTION
def run_preflight_checks(vehicle, min_gps_fix=3, min_battery=50, check_compass=True):
    """
    Run comprehensive pre-flight safety checks with proper error handling.

    Args:
        vehicle: The connected mavlink object
        min_gps_fix: Minimum GPS fix type required (3 for 3D fix)
        min_battery: Minimum battery percentage required
        check_compass: Whether to check compass calibration

    Returns:
        (bool, str): Tuple of (checks_passed, failure_reason)
    """
    if not vehicle:
        return False, "No vehicle connection"

    try:
        logging.info("Running pre-flight safety checks...")
        failures = []

        # Check 1: Vehicle heartbeat
        logging.info("Check 1: Verifying vehicle heartbeat...")
        msg = vehicle.recv_match(type='HEARTBEAT', blocking=True, timeout=2)
        if not msg:
            failures.append("No heartbeat from vehicle")

        # Check 2: GPS status (IMPROVED - Multiple attempts)
        logging.info("Check 2: Verifying GPS status...")

        # Request GPS data stream
        vehicle.mav.request_data_stream_send(
            vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_DATA_STREAM_POSITION, 2, 1)

        # Also request GPS_RAW_INT specifically
        vehicle.mav.command_long_send(
            vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL, 0,
            mavutil.mavlink.MAVLINK_MSG_ID_GPS_RAW_INT,
            500000,  # 2 Hz in microseconds
            0, 0, 0, 0, 0
        )

        gps_check_passed = False
        fix_type = 0
        satellites = 0
        max_attempts = 3
        attempt_timeout = 5  # 5 seconds per attempt

        for attempt in range(max_attempts):
            logging.info(f"GPS check attempt {attempt + 1}/{max_attempts}")

            start_time = time.time()
            got_gps_data = False

            while time.time() - start_time < attempt_timeout:
                msg = vehicle.recv_match(type='GPS_RAW_INT', blocking=False)
                if msg:
                    fix_type = msg.fix_type
                    satellites = msg.satellites_visible
                    got_gps_data = True

                    # Define fix type names
                    fix_type_name = "No GPS" if fix_type == 0 else \
                                "No Fix" if fix_type == 1 else \
                                "2D Fix" if fix_type == 2 else \
                                "3D Fix" if fix_type == 3 else \
                                "3D DGPS" if fix_type == 4 else \
                                "RTK Float" if fix_type == 5 else \
                                "RTK Fixed" if fix_type == 6 else \
                                f"Fix Type {fix_type}"

                    logging.info(f"GPS: {fix_type_name} with {satellites} satellites")

                    if fix_type >= min_gps_fix:
                        gps_check_passed = True
                        logging.info(f"‚úì GPS check passed on attempt {attempt + 1}")
                        break

                time.sleep(0.2)

            if gps_check_passed:
                break

            if not got_gps_data:
                logging.warning(f"No GPS data received on attempt {attempt + 1}")
            else:
                logging.warning(f"GPS fix insufficient on attempt {attempt + 1}: {fix_type_name}")

            if attempt < max_attempts - 1:
                logging.info("Waiting 2 seconds before next GPS check attempt...")
                time.sleep(2)

        # Final GPS check result
        if not gps_check_passed:
            if fix_type == 0:
                failure_msg = "GPS: No GPS data received after multiple attempts"
            else:
                fix_type_name = "No GPS" if fix_type == 0 else \
                            "No Fix" if fix_type == 1 else \
                            "2D Fix" if fix_type == 2 else \
                            "3D Fix" if fix_type == 3 else \
                            "3D DGPS" if fix_type == 4 else \
                            "RTK Float" if fix_type == 5 else \
                            "RTK Fixed" if fix_type == 6 else \
                            f"Fix Type {fix_type}"
                failure_msg = f"GPS fix type below minimum required (current: {fix_type_name}, required: 3D fix or better)"

            failures.append(failure_msg)
        else:
            logging.info("‚úì GPS check passed - good GPS fix available")
        # Check 3: Battery level
        logging.info("Check 3: Verifying battery level...")
        vehicle.mav.request_data_stream_send(
            vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_DATA_STREAM_EXTENDED_STATUS, 2, 1)

        start_time = time.time()
        battery_check_passed = False
        battery_remaining = -1  # Initialize with default

        while time.time() - start_time < 2:
            msg = vehicle.recv_match(type='SYS_STATUS', blocking=False)
            if msg:
                battery_remaining = msg.battery_remaining
                voltage = msg.voltage_battery / 1000.0  # Convert from mV to V

                logging.info(f"Battery: {battery_remaining}% remaining, {voltage:.2f}V")

                if battery_remaining >= min_battery:
                    battery_check_passed = True
                    break
                elif battery_remaining < 0:
                    # Some systems don't report battery percentage
                    logging.warning("Battery percentage not available, skipping check")
                    battery_check_passed = True
                    break

            time.sleep(0.2)

        if not battery_check_passed and battery_remaining >= 0:
            failures.append(f"Battery level below minimum (current: {battery_remaining}%, required: {min_battery}%)")

        # Check 4: Pre-arm status
        logging.info("Check 4: Verifying pre-arm status...")
        # Clear message buffer
        while vehicle.recv_match(blocking=False):
            pass

        # Request status text messages
        vehicle.mav.command_long_send(
            vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL, 0,
            mavutil.mavlink.MAVLINK_MSG_ID_STATUSTEXT, 100000, 0, 0, 0, 0, 0)

        start_time = time.time()
        prearm_failures = []

        while time.time() - start_time < 2:
            msg = vehicle.recv_match(type='STATUSTEXT', blocking=False)
            if msg and hasattr(msg, 'text'):
                text = msg.text
                if "PreArm" in text and "PreArm: All checks passing" not in text:
                    prearm_failures.append(text)

            time.sleep(0.1)

        if prearm_failures:
            failures.extend(prearm_failures)

        # Check 5: Compass check (if enabled)
        if check_compass:
            logging.info("Check 5: Verifying compass calibration...")
            vehicle.mav.request_data_stream_send(
                vehicle.target_system, vehicle.target_component,
                mavutil.mavlink.MAV_DATA_STREAM_RAW_SENSORS, 2, 1)

            # Look for compass-related failure messages
            compass_failures = [f for f in prearm_failures if "compass" in f.lower()]

            if compass_failures:
                failures.extend(compass_failures)

        # Result
        if failures:
            failure_message = "Pre-flight checks failed:\n- " + "\n- ".join(failures)
            logging.warning(failure_message)
            return False, failure_message
        else:
            logging.info("All pre-flight checks PASSED")
            return True, "All checks passed"

    except Exception as e:
        error_msg = f"Error during pre-flight checks: {str(e)}"
        logging.error(error_msg)
        return False, error_msg

# --- drone/navigation.py ---
def safe_takeoff(vehicle, target_altitude, safety_checks=True, max_drift=2.0):
    """
    Takeoff with enhanced safety features including position holding.

    Args:
        vehicle: The connected mavlink object
        target_altitude: Target altitude in meters
        safety_checks: Whether to perform pre-flight safety checks
        max_drift: Maximum allowed horizontal drift in meters

    Returns:
        True if takeoff was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Run pre-flight checks if enabled
        if safety_checks:
            checks_passed, failure_reason = run_preflight_checks(vehicle)
            if not checks_passed:
                logging.error(f"Pre-flight checks failed: {failure_reason}")
                return False

        # Record the starting location for drift monitoring
        start_location = get_location(vehicle)
        if not start_location:
            logging.error("Could not get starting location")
            return False

        logging.info(f"Starting location: Lat={start_location[0]}, Lon={start_location[1]}")

        # Set to GUIDED mode
        logging.info("Setting mode to GUIDED")
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        # Arm the vehicle
        logging.info("Arming vehicle")
        if not arm_vehicle(vehicle, force=False):
            logging.error("Failed to arm vehicle")
            return False

        # Start with a very slow, controlled takeoff
        logging.info(f"Taking off to {target_altitude} meters with enhanced safety")

        # Send takeoff command
        vehicle.mav.command_long_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_CMD_NAV_TAKEOFF,
            0,                  # Confirmation
            0, 0, 0, 0, 0, 0,   # Params 1-6 (not used)
            target_altitude     # Param 7: Altitude (in meters)
        )

        # Monitor ascent with more detailed feedback
        start_time = time.time()
        timeout = 60  # seconds timeout
        prev_altitude = 0
        stall_counter = 0

        logging.info("Beginning ascent with position monitoring")

        # Setup data streams for monitoring
        request_message_interval(vehicle, mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT, 5)
        request_message_interval(vehicle, mavutil.mavlink.MAVLINK_MSG_ID_VFR_HUD, 5)

        while time.time() - start_time < timeout:
            # Check altitude progress
            altitude = get_altitude(vehicle)
            if altitude is not None:
                # Check for alt change (stall detection)
                if abs(altitude - prev_altitude) < 0.05:
                    stall_counter += 1
                else:
                    stall_counter = 0

                if stall_counter > 10:
                    logging.warning("Altitude stalled - takeoff may be interrupted")

                prev_altitude = altitude
                percent_complete = (altitude / target_altitude) * 100
                logging.info(f"Altitude: {altitude:.2f}m ({percent_complete:.1f}% complete)")

                # Check for drift
                current_location = get_location(vehicle)
                if current_location:
                    drift = get_distance_metres(start_location, current_location)
                    if drift > max_drift:
                        logging.warning(f"Excessive horizontal drift detected: {drift:.1f}m")
                        logging.warning("Attempting drift correction")

                        # Calculate direction back to start
                        start_lat, start_lon, _ = start_location
                        current_lat, current_lon, _ = current_location

                        # Simple position correction (in a real system, use a proper controller)
                        north_correction = (start_lat - current_lat) * 1e7 * 1.113195  # rough m/deg at equator
                        east_correction = (start_lon - current_lon) * 1e7 * 1.113195 * math.cos(math.radians(current_lat))

                        # Scale corrections to appropriate velocity (max 0.5 m/s)
                        correction_mag = math.sqrt(north_correction**2 + east_correction**2)
                        if correction_mag > 0:
                            scale = min(0.5, correction_mag) / correction_mag
                            north_velocity = north_correction * scale
                            east_velocity = east_correction * scale

                            # Apply correction velocity
                            send_ned_velocity(vehicle, north_velocity, east_velocity, 0, 1)
                    else:
                        logging.info(f"Horizontal position stable, drift: {drift:.1f}m")

                # Check for target altitude reached
                if altitude >= target_altitude * 0.95:
                    logging.info(f"Reached target altitude: {altitude:.2f}m")

                    # Final position hold for stability
                    logging.info("Holding position for stability")
                    time.sleep(2)

                    return True

            # Check if still armed
            if not check_if_armed(vehicle):
                logging.error("Vehicle disarmed during takeoff")
                return False

            time.sleep(1)

        logging.warning("Takeoff timed out")
        return False

    except Exception as e:
        logging.error(f"Error during safe takeoff: {str(e)}")

        # Emergency RTL if something went wrong
        try:
            logging.warning("Attempting emergency return to launch")
            return_to_launch(vehicle)
        except:
            pass

        return False


# --- drone/navigation.py ---
def verify_orientation(vehicle, tolerance_deg=10):
    """
    Verify vehicle orientation is stable before takeoff.

    Args:
        vehicle: The connected mavlink object
        tolerance_deg: Maximum tolerated degrees of rotation during check

    Returns:
        True if orientation is stable, False otherwise
    """
    try:
        logging.info("Verifying orientation stability...")

        # Request attitude data
        request_message_interval(vehicle, mavutil.mavlink.MAVLINK_MSG_ID_ATTITUDE, 10)

        # Get initial attitude
        msg = vehicle.recv_match(type='ATTITUDE', blocking=True, timeout=1)
        if not msg:
            logging.error("Could not get initial attitude data")
            return False

        initial_roll = math.degrees(msg.roll)
        initial_pitch = math.degrees(msg.pitch)
        initial_yaw = math.degrees(msg.yaw)

        logging.info(f"Initial attitude: Roll={initial_roll:.1f}¬∞, Pitch={initial_pitch:.1f}¬∞, Yaw={initial_yaw:.1f}¬∞")

        # Monitor for changes over 2 seconds
        start_time = time.time()
        max_roll_change = 0
        max_pitch_change = 0
        max_yaw_change = 0

        while time.time() - start_time < 2:
            msg = vehicle.recv_match(type='ATTITUDE', blocking=False)
            if msg:
                roll = math.degrees(msg.roll)
                pitch = math.degrees(msg.pitch)
                yaw = math.degrees(msg.yaw)

                roll_change = abs(roll - initial_roll)
                pitch_change = abs(pitch - initial_pitch)

                # Handle yaw wrap-around
                yaw_change = min(abs(yaw - initial_yaw), 360 - abs(yaw - initial_yaw))

                max_roll_change = max(max_roll_change, roll_change)
                max_pitch_change = max(max_pitch_change, pitch_change)
                max_yaw_change = max(max_yaw_change, yaw_change)

            time.sleep(0.1)

        logging.info(f"Maximum attitude changes: Roll={max_roll_change:.1f}¬∞, Pitch={max_pitch_change:.1f}¬∞, Yaw={max_yaw_change:.1f}¬∞")

        # Check if orientation was stable
        orientation_stable = (max_roll_change < tolerance_deg and
                              max_pitch_change < tolerance_deg and
                              max_yaw_change < tolerance_deg)

        if orientation_stable:
            logging.info("Orientation is stable")
        else:
            logging.warning("Orientation unstable - vehicle may drift after takeoff")

        return orientation_stable

    except Exception as e:
        logging.error(f"Error verifying orientation: {str(e)}")
        return False

def verify_position_hold(vehicle, duration=3, max_drift=0.5):
    """
    Verify vehicle can maintain position in GUIDED mode before takeoff.

    Args:
        vehicle: The connected mavlink object
        duration: Duration to check position hold in seconds
        max_drift: Maximum allowed drift in meters

    Returns:
        True if position hold is working, False otherwise
    """
    try:
        logging.info(f"Verifying position hold capability for {duration} seconds...")

        # Get initial position
        initial_location = get_location(vehicle)
        if not initial_location:
            logging.error("Could not get initial location")
            return False

        # Monitor position for specified duration
        start_time = time.time()
        max_distance = 0

        while time.time() - start_time < duration:
            current_location = get_location(vehicle)
            if current_location:
                distance = get_distance_metres(initial_location, current_location)
                max_distance = max(max_distance, distance)
                logging.info(f"Current drift: {distance:.2f}m")

            time.sleep(0.5)

        position_stable = max_distance <= max_drift

        if position_stable:
            logging.info(f"Position hold is stable (max drift: {max_distance:.2f}m)")
        else:
            logging.warning(f"Position hold unstable - excessive drift detected: {max_distance:.2f}m")

        return position_stable

    except Exception as e:
        logging.error(f"Error verifying position hold: {str(e)}")
        return False


--- drone\servo.py ---
"""
Drone Servo Control Module
------------------------
Functions for controlling servos for package delivery operations using pymavlink.
"""

import time
import logging
from pymavlink import mavutil

def set_servo_position(vehicle, servo_number, position):
    """
    Set a servo to a specific PWM position.

    Args:
        vehicle: The connected mavlink object
        servo_number: The servo number (1-16)
        position: PWM position (typically 1000-2000)

    Returns:
        True if successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Send DO_SET_SERVO command
        vehicle.mav.command_long_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_CMD_DO_SET_SERVO,
            0,                  # Confirmation
            servo_number,       # Param 1: Servo number
            position,           # Param 2: PWM position
            0, 0, 0, 0, 0       # Params 3-7 (not used)
        )

        # Wait for acknowledgment
        start_time = time.time()
        while time.time() - start_time < 3:  # 3 second timeout
            msg = vehicle.recv_match(type='COMMAND_ACK', blocking=True, timeout=1)
            if msg and msg.command == mavutil.mavlink.MAV_CMD_DO_SET_SERVO:
                if msg.result == mavutil.mavlink.MAV_RESULT_ACCEPTED:
                    logging.info(f"Servo {servo_number} set to position {position}")
                    return True
                else:
                    logging.warning(f"Servo command failed with result {msg.result}")
                    return False

        logging.warning("No acknowledgment received for servo command")
        # We still return True as some autopilots don't send ACK for servo commands
        logging.info(f"Servo {servo_number} set to position {position} (no ACK)")
        return True
    except Exception as e:
        logging.error(f"Error setting servo position: {str(e)}")
        return False

def operate_package_release(vehicle, servo_number=9):
    """
    Release the package by operating the release servo.

    Args:
        vehicle: The connected mavlink object
        servo_number: The servo number for the release mechanism

    Returns:
        True if successful, False otherwise
    """
    try:
        logging.info("Operating package release mechanism")

        # First position - closed
        if not set_servo_position(vehicle, servo_number, 1000):
            logging.error("Failed to set initial servo position")
            return False
        time.sleep(1)

        # Second position - open to release package
        if not set_servo_position(vehicle, servo_number, 2000):
            logging.error("Failed to open release mechanism")
            return False
        time.sleep(2)

        # Return to closed position
        if not set_servo_position(vehicle, servo_number, 1000):
            logging.error("Failed to close release mechanism")
            return False

        logging.info("Package release completed")
        return True
    except Exception as e:
        logging.error(f"Error during package release: {str(e)}")
        return False

def operate_claw(vehicle, servo_number=10, open_position=2000, closed_position=1000):
    """
    Operate the claw for package delivery.

    Args:
        vehicle: The connected mavlink object
        servo_number: The servo number for the claw
        open_position: PWM value for open position
        closed_position: PWM value for closed position

    Returns:
        True if successful, False otherwise
    """
    try:
        logging.info("Opening claw")
        if not set_servo_position(vehicle, servo_number, open_position):
            logging.error("Failed to open claw")
            return False
        time.sleep(2)

        logging.info("Closing claw")
        if not set_servo_position(vehicle, servo_number, closed_position):
            logging.error("Failed to close claw")
            return False

        logging.info("Claw operation completed")
        return True
    except Exception as e:
        logging.error(f"Error operating claw: {str(e)}")
        return False

def test_servo(vehicle, servo_number, min_position=1000, max_position=2000, steps=5, step_time=1):
    """
    Test a servo by moving it through a range of positions.

    Args:
        vehicle: The connected mavlink object
        servo_number: The servo number to test
        min_position: Minimum PWM position
        max_position: Maximum PWM position
        steps: Number of steps between min and max
        step_time: Time to hold each position in seconds

    Returns:
        True if test was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info(f"Testing servo {servo_number} from {min_position} to {max_position} PWM")

        # Calculate step size
        step_size = (max_position - min_position) // (steps - 1) if steps > 1 else 0

        # Move servo through each position
        for i in range(steps):
            position = min_position + (i * step_size)
            logging.info(f"Setting servo {servo_number} to position {position}")

            if not set_servo_position(vehicle, servo_number, position):
                logging.error(f"Failed to set servo to position {position}")
                return False

            time.sleep(step_time)

        # Return to neutral position
        neutral_position = (min_position + max_position) // 2
        logging.info(f"Returning servo {servo_number} to neutral position {neutral_position}")
        set_servo_position(vehicle, servo_number, neutral_position)

        logging.info(f"Servo {servo_number} test completed")
        return True
    except Exception as e:
        logging.error(f"Error during servo test: {str(e)}")
        return False

def set_servo_output_channel(vehicle, channel, output):
    """
    Set a raw servo output value.

    Args:
        vehicle: The connected mavlink object
        channel: The output channel number (0-based)
        output: The output value (typically 1000-2000)

    Returns:
        True if successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Convert channel to 1-based for the MAVLink command
        servo_number = channel + 1

        # Use DO_SET_SERVO command
        vehicle.mav.command_long_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_CMD_DO_SET_SERVO,
            0,                  # Confirmation
            servo_number,       # Param 1: Servo number (1-based)
            output,             # Param 2: Output value
            0, 0, 0, 0, 0       # Params 3-7 (not used)
        )

        logging.info(f"Set channel {channel} to output {output}")
        return True
    except Exception as e:
        logging.error(f"Error setting servo output: {str(e)}")
        return False


def test_servo_simple(vehicle, servo_number=9, duration=1):
    """
    Test servo with high/mid/low positions for specified duration each.

    Args:
        vehicle: The connected mavlink object
        servo_number: The servo number to test (default: 9 for AUX OUT 1)
        duration: Duration to hold each position in seconds

    Returns:
        True if test completed successfully, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info(f"Testing servo {servo_number} with high/mid/low positions")
        logging.info(f"Duration: {duration} second(s) per position")

        # Test positions (typical PWM values)
        positions = [
            ("HIGH", 2000),  # High position - rotates one way
            ("MID", 1500),   # Mid position - neutral/no movement
            ("LOW", 1000)    # Low position - rotates other way
        ]

        for position_name, pwm_value in positions:
            logging.info(f"Setting servo {servo_number} to {position_name} position ({pwm_value} PWM)")

            # Set servo position
            if not set_servo_position(vehicle, servo_number, pwm_value):
                logging.error(f"Failed to set servo to {position_name} position")
                return False

            # Hold position for specified duration
            logging.info(f"Holding {position_name} position for {duration} second(s)")
            time.sleep(duration)

        # Return to neutral position
        logging.info(f"Returning servo {servo_number} to MID position (neutral)")
        set_servo_position(vehicle, servo_number, 1500)

        logging.info("Servo test completed successfully")
        return True

    except Exception as e:
        logging.error(f"Error during servo test: {str(e)}")
        return False


--- missions\test_missions.py ---
"""
Test Missions Module
-----------------
Functions for testing drone components and functionality using pymavlink.
"""

import logging
import time
import cv2
from pymavlink import mavutil

from drone.connection import get_vehicle_state, print_vehicle_state, request_message_interval
from drone.navigation import (
    arm_vehicle, disarm_vehicle, set_mode, arm_and_takeoff,
    return_to_launch, check_if_armed, test_motors, get_altitude, get_location, wait_for_altitude_blocking
)
from detection.camera import test_camera_feed
from detection.models import load_detection_model, test_detection_model

def test_connection(vehicle):
    """
    Test the connection to the drone by checking its state and running diagnostics.

    Args:
        vehicle: The connected mavlink object

    Returns:
        True if test was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Testing vehicle connection and running diagnostics")

        # Standard state check
        state = get_vehicle_state(vehicle)
        if state:
            print_vehicle_state(vehicle)
        else:
            logging.warning("Could not retrieve vehicle state")

        # Get comprehensive diagnostics
        from drone.connection import get_vehicle_diagnostics
        diagnostics = get_vehicle_diagnostics(vehicle, timeout=5)

        if diagnostics:
            logging.info("=== DRONE DIAGNOSTICS ===")

            # Connection info
            logging.info(f"System ID: {diagnostics['connection']['target_system']}")
            logging.info(f"Component ID: {diagnostics['connection']['target_component']}")
            logging.info(f"Connection: {diagnostics['connection']['connection_string']}")

            # Heartbeat status
            logging.info(f"Heartbeat received: {diagnostics['heartbeat_received']}")

            # Mode and armed status
            if diagnostics['mode']:
                logging.info(f"Current mode: {diagnostics['mode']}")
            logging.info(f"Armed: {diagnostics['armed']}")

            # Firmware info
            if diagnostics['firmware_version']:
                logging.info(f"Firmware version: {diagnostics['firmware_version']}")

            # GPS status
            if diagnostics['gps_status']:
                fix_type = diagnostics['gps_status']['fix_type']
                fix_type_name = "No GPS" if fix_type == 0 else \
                               "No Fix" if fix_type == 1 else \
                               "2D Fix" if fix_type == 2 else \
                               "3D Fix" if fix_type == 3 else \
                               f"Unknown ({fix_type})"
                logging.info(f"GPS status: {fix_type_name} ({diagnostics['gps_status']['satellites_visible']} satellites)")

            # Pre-arm status
            if diagnostics['pre_arm_status']:
                logging.info("Pre-arm checks status:")
                for msg in diagnostics['pre_arm_status']:
                    logging.info(f"  - {msg}")
            else:
                logging.info("No pre-arm check messages received.")

            # Important status text messages
            if diagnostics['status_text_messages']:
                logging.info("Important status messages:")
                for msg in diagnostics['status_text_messages'][-5:]:  # Show last 5 messages
                    logging.info(f"  - {msg}")

            logging.info("=========================")
        else:
            logging.warning("Could not retrieve diagnostic information")

        # Test for basic communication
        vehicle.mav.heartbeat_send(
            6,                  # Type: MAV_TYPE_GCS
            8,                  # Autopilot: MAV_AUTOPILOT_INVALID
            0,                  # Base mode: None
            0,                  # Custom mode: None
            0                   # System status: None
        )

        # Wait for heartbeat response
        msg = vehicle.recv_match(type='HEARTBEAT', blocking=True, timeout=3)
        if not msg:
            logging.error("No heartbeat received from vehicle")
            return False

        logging.info(f"Received heartbeat from system {getattr(vehicle, 'target_system', 'Unknown')}, component {getattr(vehicle, 'target_component', 'Unknown')}")
        logging.info("Connection test completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during connection test: {str(e)}")
        return False

def test_arm(vehicle, duration=3):
    """
    Test arming and disarming the vehicle.

    Args:
        vehicle: The connected mavlink object
        duration: Duration to keep armed in seconds

    Returns:
        True if test was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Testing arm functionality")

        # Set to GUIDED mode
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        # Import the direct MAVLink arming function
        from drone.navigation import arm_vehicle_mavlink, check_if_armed_simple

        # Try to arm using direct MAVLink
        logging.info("Arming vehicle with direct MAVLink method")
        if not arm_vehicle_mavlink(vehicle):
            logging.error("Failed to arm with direct MAVLink method")
            return False

        # Check if actually armed
        # armed = check_if_armed_simple(vehicle)
        armed = mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED
        logging.info(f"Arm state verification: {'ARMED' if armed else 'NOT ARMED'}")

        # If not armed but no exception was thrown, we'll proceed anyway
        if not armed:
            logging.warning("Arm command was accepted but vehicle doesn't appear armed")
            logging.info("Proceeding with test anyway")

        logging.info(f"Vehicle armed. Waiting for {duration} seconds...")
        time.sleep(duration)

        # Disarm with direct MAVLink
        logging.info("Disarming vehicle with direct MAVLink method")
        target_system = getattr(vehicle, 'target_system', 1)
        target_component = getattr(vehicle, 'target_component', 0)

        vehicle.mav.command_long_send(
            target_system,
            target_component,
            mavutil.mavlink.MAV_CMD_COMPONENT_ARM_DISARM,
            0,                  # Confirmation
            0,                  # Param 1: 0 to disarm
            0,                  # Param 2: Normal disarm
            0, 0, 0, 0, 0       # Params 3-7 (not used)
        )

        # Wait a moment for disarm to take effect
        time.sleep(1)

        # Check disarm state
        armed = check_if_armed_simple(vehicle)
        if armed:
            logging.warning("Vehicle still appears to be armed after disarm command")
            # Not failing the test for this
        else:
            logging.info("Vehicle successfully disarmed")

        logging.info("Arm test completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during arm test: {str(e)}")

        # Try to disarm if there was an error
        try:
            vehicle.mav.command_long_send(
                getattr(vehicle, 'target_system', 1),
                getattr(vehicle, 'target_component', 0),
                mavutil.mavlink.MAV_CMD_COMPONENT_ARM_DISARM,
                0, 0, 0, 0, 0, 0, 0, 0
            )
        except:
            pass

        return False

def test_takeoff(vehicle, altitude=3):
    """
    Test the drone takeoff and landing process.

    Args:
        vehicle: The connected mavlink object
        altitude: Target altitude in meters

    Returns:
        True if test was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info(f"Testing takeoff to {altitude} meters")

        # First, arm and takeoff
        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and takeoff")
            return False

        # Hover for 10 seconds
        logging.info("Hovering for 10 seconds")
        for i in range(10):
            logging.info(f"Hovering... {i+1}/10 seconds")
            print_vehicle_state(vehicle)
            time.sleep(1)

        # Return to launch
        logging.info("Testing return to launch")
        if not return_to_launch(vehicle):
            logging.error("Failed to return to launch")
            return False

        # Wait for landing and disarm
        logging.info("Waiting for landing")
        start_time = time.time()
        while check_if_armed(vehicle) and time.time() - start_time < 60:
            state = get_vehicle_state(vehicle)
            if state and 'altitude' in state:
                logging.info(f"Altitude: {state['altitude']} meters")
            time.sleep(1)

        if check_if_armed(vehicle):
            logging.warning("Vehicle still armed after RTL - trying manual disarm")
            disarm_vehicle(vehicle)

        logging.info("Takeoff test completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during takeoff test: {str(e)}")

        # Try to return to launch if there was an error
        try:
            return_to_launch(vehicle)
            time.sleep(5)
            disarm_vehicle(vehicle)
        except:
            pass

        return False

def test_camera(camera_id=0, duration=10):
    """
    Test the camera feed.

    Args:
        camera_id: Camera ID to use
        duration: Test duration in seconds

    Returns:
        True if test was successful, False otherwise
    """
    try:
        logging.info(f"Testing camera {camera_id} for {duration} seconds")
        return test_camera_feed(camera_id, duration)
    except Exception as e:
        logging.error(f"Error during camera test: {str(e)}")
        return False

def test_detection(model_path, test_source="0", duration=10):
    """
    Test the object detection model.

    Args:
        model_path: Path to the detection model
        test_source: Source for testing (0 for webcam, or path to image/video)
        duration: Test duration in seconds

    Returns:
        True if test was successful, False otherwise
    """
    try:
        logging.info(f"Testing detection model {model_path}")

        # Load the model
        model = load_detection_model(model_path)
        if not model:
            logging.error("Failed to load detection model")
            return False

        # Test the model
        return test_detection_model(model, test_source, duration=duration)
    except Exception as e:
        logging.error(f"Error during detection test: {str(e)}")
        return False

def test_motor(vehicle, throttle_percentage=15, duration_per_motor=1):
    """
    Test each motor individually.

    Args:
        vehicle: The connected mavlink object
        throttle_percentage: Throttle percentage (0-100)
        duration_per_motor: Duration to run each motor in seconds

    Returns:
        True if test was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info(f"Testing motors at {throttle_percentage}% throttle for {duration_per_motor}s each")

        # Check if vehicle is in the air
        state = get_vehicle_state(vehicle)
        if state and state['armed']:
            is_flying = state['altitude'] > 0.5 if state['altitude'] is not None else True
            if is_flying:
                logging.error("Cannot run motor test while vehicle is armed or flying")
                return False

        # Run motor test
        if not test_motors(vehicle, throttle_percentage, duration_per_motor):
            logging.error("Motor test failed")
            return False

        logging.info("Motor test completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during motor test: {str(e)}")
        return False

def test_all(vehicle, model_path, altitude=3, camera_id=0):
    """
    Run all tests sequentially.

    Args:
        vehicle: The connected mavlink object
        model_path: Path to the detection model
        altitude: Target altitude in meters
        camera_id: Camera ID to use

    Returns:
        Dictionary with test results
    """
    results = {}

    # Test connection
    logging.info("=== STARTING CONNECTION TEST ===")
    results['connection'] = test_connection(vehicle)

    # Test camera
    logging.info("=== STARTING CAMERA TEST ===")
    results['camera'] = test_camera(camera_id)

    # Test detection
    logging.info("=== STARTING DETECTION TEST ===")
    results['detection'] = test_detection(model_path)

    # Test arm
    logging.info("=== STARTING ARM TEST ===")
    results['arm'] = test_arm(vehicle)

    # Test motors (CAUTION: only if safe)
    logging.info("=== SKIPPING MOTOR TEST (Run individually if needed) ===")
    results['motor'] = False

    # Test takeoff (last since it involves actual flight)
    logging.info("=== STARTING TAKEOFF TEST ===")
    results['takeoff'] = test_takeoff(vehicle, altitude)

    # Print summary
    logging.info("=== TEST SUMMARY ===")
    for test, result in results.items():
        status = "PASSED" if result else "FAILED"
        logging.info(f"Test '{test}': {status}")

    # Overall result
    results['all_passed'] = all(results.values())

    return results


# --- missions/test_missions.py ---
def test_incremental_takeoff(vehicle, max_altitude=3, increment=1):
    """
    Test takeoff in small increments with blocking behavior and audio feedback.

    Args:
        vehicle: The connected mavlink object
        max_altitude: Maximum target altitude in meters
        increment: Height increment in meters for each step

    Returns:
        True if test was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("=== BLOCKING INCREMENTAL TAKEOFF TEST ===")
        logging.info(f"Target: {max_altitude}m in {increment}m increments")

        # Run comprehensive pre-flight checks
        from drone.navigation import run_preflight_checks

        checks_passed, failure_reason = run_preflight_checks(vehicle)
        if not checks_passed:
            logging.error(f"Pre-flight checks failed: {failure_reason}")
            return False

        # Set to GUIDED mode
        logging.info("Setting mode to GUIDED")
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        # Arm the vehicle
        logging.info("Arming vehicle...")
        if not arm_vehicle(vehicle):
            logging.error("Failed to arm vehicle")
            return False

        # Wait for altitude to reset after arming
        logging.info("Waiting 2 seconds for altitude sensor to stabilize...")
        time.sleep(2)

        # Get baseline altitude
        baseline_msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=True, timeout=3)
        if baseline_msg:
            baseline_altitude = baseline_msg.relative_alt / 1000.0
            logging.info(f"Baseline altitude: {baseline_altitude:.3f}m")
        else:
            logging.warning("Could not get baseline altitude, proceeding anyway")
            baseline_altitude = 0.0

        # Initial takeoff to first increment
        first_target = increment
        logging.info(f"\nüöÅ STEP 1: Initial takeoff to {first_target}m")

        # Send initial takeoff command
        vehicle.mav.command_long_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_CMD_NAV_TAKEOFF,
            0,                  # Confirmation
            0, 0, 0, 0, 0, 0,   # Params 1-6 (not used)
            first_target        # Param 7: Altitude (in meters)
        )

        # BLOCKING wait for first altitude
        if not wait_for_altitude_blocking(vehicle, first_target, timeout=40, tolerance=0.15):
            logging.error(f"Failed to reach initial altitude {first_target}m")
            return_to_launch(vehicle)
            return False

        logging.info(f"‚úì Successfully reached {first_target}m")
        logging.info("Stabilizing for 2 seconds...")
        time.sleep(2)

        # Incremental altitude increases
        current_target = first_target

        while current_target < max_altitude:
            next_target = min(current_target + increment, max_altitude)
            step_number = int(next_target / increment) + 1

            logging.info(f"\nüöÅ STEP {step_number}: Climbing to {next_target}m")

            # Send altitude command
            if not command_altitude_precise(vehicle, next_target):
                logging.error(f"Failed to send altitude command for {next_target}m")
                return_to_launch(vehicle)
                return False

            # BLOCKING wait for next altitude
            if not wait_for_altitude_blocking(vehicle, next_target, timeout=30, tolerance=0.15):
                logging.error(f"Failed to reach altitude {next_target}m")
                return_to_launch(vehicle)
                return False

            logging.info(f"‚úì Successfully reached {next_target}m")
            current_target = next_target

            # Stabilization pause between increments
            if current_target < max_altitude:
                logging.info("Stabilizing for 2 seconds...")
                time.sleep(2)

        # Final hover at maximum altitude
        logging.info(f"\nüéØ FINAL: Reached maximum altitude of {max_altitude}m")
        logging.info("Final hover for 5 seconds...")
        time.sleep(5)

        # Return to launch with blocking behavior
        logging.info("\nüè† RETURN TO LAUNCH")
        logging.info("Commanding RTL...")

        if not return_to_launch(vehicle):
            logging.error("Failed to command RTL")
            return False

        # BLOCKING wait for landing with real-time feedback
        logging.info("Monitoring descent and landing...")
        print("-" * 50)

        landing_start = time.time()
        landing_timeout = 90  # 90 seconds for landing

        while time.time() - landing_start < landing_timeout:
            # Check if still armed (landing complete when disarmed)
            heartbeat = vehicle.recv_match(type='HEARTBEAT', blocking=True, timeout=1)
            if heartbeat:
                armed = (heartbeat.base_mode & mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED) != 0

                # Get current altitude
                pos_msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=False)
                current_alt = pos_msg.relative_alt / 1000.0 if pos_msg else None

                timestamp = time.strftime("%H:%M:%S")
                armed_status = "ARMED" if armed else "DISARMED"
                alt_str = f"{current_alt:.3f}m" if current_alt is not None else "N/A"

                print(f"\r{timestamp} | Status: {armed_status} | Altitude: {alt_str}", end="", flush=True)

                if not armed:
                    print(f"\n‚úì LANDING COMPLETE - Vehicle disarmed")
                    # play_beep()
                    break

                # Also check if very close to ground
                if current_alt is not None and current_alt < 0.3:
                    print(f"\n‚úì NEAR GROUND - Altitude: {current_alt:.3f}m")

            time.sleep(0.5)

        # Final verification
        time.sleep(2)
        final_armed = check_if_armed(vehicle)
        if final_armed:
            logging.warning("Vehicle still armed after landing timeout - forcing disarm")
            disarm_vehicle(vehicle)

        logging.info("\nüéâ INCREMENTAL TAKEOFF TEST COMPLETED SUCCESSFULLY")
        return True

    except Exception as e:
        logging.error(f"Error during incremental takeoff test: {str(e)}")
        try:
            logging.warning("Attempting emergency return to launch")
            return_to_launch(vehicle)
            time.sleep(10)
            if check_if_armed(vehicle):
                disarm_vehicle(vehicle)
        except:
            pass
        return False

def command_altitude_precise(vehicle, target_altitude):
    """
    Send precise altitude command using position target.

    Args:
        vehicle: The connected mavlink object
        target_altitude: Target altitude in meters

    Returns:
        True if command sent successfully
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Get current location for position hold
        current_location = get_location(vehicle)
        if not current_location:
            logging.error("Could not get current location for altitude command")
            return False

        lat, lon, _ = current_location

        logging.info(f"Commanding altitude change to {target_altitude}m")

        # Send position target with only altitude change
        vehicle.mav.set_position_target_global_int_send(
            0,  # time_boot_ms (not used)
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT,
            0b0000111111111000,  # type_mask (only alt enabled, position and velocity ignored)
            int(lat * 1e7),      # lat_int
            int(lon * 1e7),      # lon_int
            target_altitude,     # alt (meters)
            0, 0, 0,            # vx, vy, vz (not used)
            0, 0, 0,            # afx, afy, afz (not used)
            0, 0                # yaw, yaw_rate (not used)
        )

        return True

    except Exception as e:
        logging.error(f"Error sending altitude command: {str(e)}")
        return False


def monitor_altitude_realtime(vehicle, duration=0, update_interval=0.2):
    """
    Ultra-responsive altitude monitoring with minimal delay.

    Args:
        vehicle: The connected mavlink object
        duration: Duration to monitor in seconds (0 = indefinite)

    Returns:
        True if monitoring completed successfully
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("Starting ULTRA-RESPONSIVE altitude monitoring")
        logging.info("Press Ctrl+C to stop monitoring")

        # Request maximum frequency streams
        vehicle.mav.request_data_stream_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_DATA_STREAM_POSITION,
            20,  # 20 Hz - maximum
            1    # Start
        )

        start_time = time.time()
        last_altitude = None
        message_count = 0

        print("\n" + "="*80)
        print("ULTRA-RESPONSIVE ALTITUDE MONITORING")
        print("="*80)
        print("Time       | Relative Alt | Change    | Messages | Status")
        print("-"*80)

        while True:
            if duration > 0 and (time.time() - start_time) > duration:
                break

            # Process ALL available messages immediately
            while True:
                msg = vehicle.recv_match(blocking=False)
                if not msg:
                    break

                message_count += 1

                if msg.get_type() == "GLOBAL_POSITION_INT":
                    current_altitude = msg.relative_alt / 1000.0
                    current_time = time.strftime("%H:%M:%S.%f")[:-3]

                    # Calculate change
                    change_str = "---"
                    if last_altitude is not None:
                        change = current_altitude - last_altitude
                        if abs(change) > 0.001:  # Only show significant changes
                            change_str = f"{change:+.3f}m"

                    # Determine status based on change rate
                    if last_altitude is None:
                        status = "INIT"
                    elif abs(current_altitude - last_altitude) > 0.01:
                        status = "MOVING"
                    else:
                        status = "STABLE"

                    print(f"{current_time:<10} | {current_altitude:>9.3f}m | {change_str:>9} | {message_count:>8} | {status}")

                    last_altitude = current_altitude

            # Very minimal sleep - just enough to prevent 100% CPU
            time.sleep(0.001)  # 1ms

        print("\nUltra-responsive monitoring stopped")
        return True

    except KeyboardInterrupt:
        print("\nUltra-responsive monitoring stopped by user")
        return True
    except Exception as e:
        logging.error(f"Error during ultra-responsive monitoring: {str(e)}")
        return False


--- missions\waypoint.py ---
"""
Waypoint Missions Module
---------------------
Functions for executing waypoint-based drone missions using pymavlink.
"""

import logging
import time
from threading import Thread
import cv2
from pymavlink import mavutil

from drone.connection import get_vehicle_state  # Corrected import location
from drone.navigation import (
    arm_and_takeoff, check_if_armed_simple, disarm_vehicle, set_mode, get_location, get_distance_metres,
    get_location_metres, navigate_to_waypoint, return_to_launch,
    send_ned_velocity
)
from detection.models import load_detection_model, run_detection, process_detection_results
from detection.camera import initialize_camera, capture_frame, close_camera

# Default waypoints for testing (latitude, longitude)
DEFAULT_WAYPOINTS = [
    (35.722952, -120.767658),  # Example waypoint 1
    (35.723101, -120.767592),  # Example waypoint 2
    (35.723072, -120.767421),  # Example waypoint 3
    (35.722925, -120.767489)   # Example waypoint 4
]

# Default relative waypoints for testing (meters North, meters East)
DEFAULT_RELATIVE_WAYPOINTS = [
    (10, 0),    # 10m North
    (10, 10),   # 10m North, 10m East
    (0, 10),    # 10m East
    (0, 0)      # Back to start
]

def mission_waypoint(vehicle, altitude=10, waypoints=None, relative=False):
    """
    Execute a simple waypoint navigation mission.

    Args:
        vehicle: The connected mavlink object
        altitude: Target altitude in meters
        waypoints: List of waypoints to visit (lat, lon) or (dNorth, dEast) if relative
        relative: If True, waypoints are relative to starting position

    Returns:
        True if mission was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Set default waypoints if none provided
        if waypoints is None:
            waypoints = DEFAULT_RELATIVE_WAYPOINTS if relative else DEFAULT_WAYPOINTS

        logging.info(f"Starting waypoint mission with {len(waypoints)} waypoints at {altitude}m altitude")
        logging.info(f"Using {'relative' if relative else 'absolute'} waypoints")

        # First, arm and take off
        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and take off")
            return False

        # Navigate to each waypoint
        original_location = get_location(vehicle)
        if not original_location and relative:
            logging.error("Failed to get current location for relative navigation")
            return_to_launch(vehicle)
            return False

        for i, waypoint in enumerate(waypoints):
            logging.info(f"Navigating to waypoint {i+1}/{len(waypoints)}")

            if relative:
                logging.info(f"Relative waypoint: {waypoint[0]}m North, {waypoint[1]}m East")
                success = navigate_to_waypoint(
                    vehicle, waypoint, altitude, relative=True
                )
            else:
                logging.info(f"Absolute waypoint: Lat {waypoint[0]}, Lon {waypoint[1]}")
                success = navigate_to_waypoint(
                    vehicle, waypoint, altitude, relative=False
                )

            if not success:
                logging.error(f"Failed to navigate to waypoint {i+1}")
                return_to_launch(vehicle)
                return False

            # Hover for 5 seconds at each waypoint
            logging.info(f"Reached waypoint {i+1}. Hovering for 5 seconds")
            time.sleep(5)

        # Return to launch
        logging.info("Mission complete. Returning to launch")
        return_to_launch(vehicle)

        # Wait for landing
        start_time = time.time()
        while time.time() - start_time < 60:  # 1 minute timeout
            # Get latest state
            state = get_vehicle_state(vehicle)
            if state:
                armed = state.get('armed', None)
                if armed is not None and not armed:
                    logging.info("Vehicle has disarmed")
                    break

                altitude = state.get('altitude', None)
                if altitude is not None:
                    logging.info(f"Altitude: {altitude} meters")
                    if altitude < 0.5:  # Close to ground
                        logging.info("Vehicle has landed")
                        break
            time.sleep(1)

        logging.info("Waypoint mission completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during waypoint mission: {str(e)}")
        # Try to return to launch if there was an error
        try:
            return_to_launch(vehicle)
        except:
            pass
        return False

def mission_waypoint_detect(vehicle, altitude=10, model_path=None, waypoints=None, relative=False):
    """
    Execute a waypoint navigation mission with object detection.

    Args:
        vehicle: The connected mavlink object
        altitude: Target altitude in meters
        model_path: Path to the detection model
        waypoints: List of waypoints to visit
        relative: If True, waypoints are relative to starting position

    Returns:
        True if mission was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        # Set default waypoints if none provided
        if waypoints is None:
            waypoints = DEFAULT_RELATIVE_WAYPOINTS if relative else DEFAULT_WAYPOINTS

        logging.info(f"Starting waypoint detection mission with {len(waypoints)} waypoints")

        # Initialize variables for detection results
        target_detected = False
        detection_center_x = None
        detection_center_y = None
        detection_thread_running = True

        # Load detection model
        model = load_detection_model(model_path)
        if not model:
            logging.error("Failed to load detection model")
            return False

        # Define detection thread function
        def detection_thread():
            nonlocal target_detected, detection_center_x, detection_center_y

            try:
                # Initialize camera
                cap = initialize_camera(0)
                if not cap:
                    logging.error("Failed to initialize camera")
                    return

                # Get camera center coordinates
                cam_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
                cam_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
                camera_center_x = cam_width / 2
                camera_center_y = cam_height / 2

                logging.info(f"Camera initialized. Resolution: {cam_width}x{cam_height}")

                # Run detection until thread is stopped
                while detection_thread_running:
                    # Capture frame
                    frame = capture_frame(cap)
                    if frame is None:
                        time.sleep(0.1)
                        continue

                    # Run detection on frame
                    results = run_detection(
                        model,
                        source=frame,
                        threshold=0.5,
                        save_results=False
                    )

                    # Process detection results
                    if results:
                        detections = process_detection_results(
                            [next(results)],
                            frame,
                            display=True
                        )

                        # Check if any object was detected
                        if detections:
                            # Use the first detection (highest confidence)
                            detection = detections[0]
                            target_detected = True
                            detection_center_x = detection['center'][0]
                            detection_center_y = detection['center'][1]

                            logging.info(f"Target detected at ({detection_center_x}, {detection_center_y})")
                        else:
                            target_detected = False
                            detection_center_x = None
                            detection_center_y = None

                    # Sleep briefly to reduce CPU usage
                    time.sleep(0.1)

                # Clean up resources
                close_camera(cap)

            except Exception as e:
                logging.error(f"Error in detection thread: {str(e)}")

        # Start detection thread
        det_thread = Thread(target=detection_thread)
        det_thread.daemon = True
        det_thread.start()

        # Wait for detection thread to initialize
        time.sleep(2)

        # First, arm and take off
        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and take off")
            detection_thread_running = False
            return False

        # Navigate to each waypoint
        original_location = get_location(vehicle)
        if not original_location and relative:
            logging.error("Failed to get current location for relative navigation")
            detection_thread_running = False
            return_to_launch(vehicle)
            return False

        for i, waypoint in enumerate(waypoints):
            logging.info(f"Navigating to waypoint {i+1}/{len(waypoints)}")

            if relative:
                success = navigate_to_waypoint(
                    vehicle, waypoint, altitude, relative=True
                )
            else:
                success = navigate_to_waypoint(
                    vehicle, waypoint, altitude, relative=False
                )

            if not success:
                logging.error(f"Failed to navigate to waypoint {i+1}")
                detection_thread_running = False
                return_to_launch(vehicle)
                return False

            # Hover for 5 seconds at each waypoint to run detection
            logging.info(f"Reached waypoint {i+1}. Hovering for 5 seconds")

            # Check for detections at this waypoint
            detection_start = time.time()
            while time.time() - detection_start < 5:
                if target_detected:
                    logging.info("Target detected! Processing...")

                    # Handle the detection here
                    # For now, just log it
                    logging.info(f"Detected target at coordinates: ({detection_center_x}, {detection_center_y})")

                    # You could add code here to align to the target, drop a package, etc.

                    # For demo purposes, hover a bit longer when target is found
                    time.sleep(2)
                    break

                time.sleep(0.5)

        # Return to launch
        logging.info("Mission complete. Returning to launch")
        return_to_launch(vehicle)

        # Wait for landing
        start_time = time.time()
        while time.time() - start_time < 60:  # 1 minute timeout
            # Get latest state
            state = get_vehicle_state(vehicle)
            if state:
                armed = state.get('armed', None)
                if armed is not None and not armed:
                    logging.info("Vehicle has disarmed")
                    break

                altitude = state.get('altitude', None)
                if altitude is not None:
                    logging.info(f"Altitude: {altitude} meters")
                    if altitude < 0.5:  # Close to ground
                        logging.info("Vehicle has landed")
                        break
            time.sleep(1)

        # Stop detection thread
        detection_thread_running = False
        det_thread.join(timeout=2)  # Wait for thread to finish

        logging.info("Waypoint detection mission completed successfully")
        return True
    except Exception as e:
        logging.error(f"Error during waypoint detection mission: {str(e)}")
        # Stop detection thread
        detection_thread_running = False
        # Try to return to launch if there was an error
        try:
            return_to_launch(vehicle)
        except:
            pass
        return False

def follow_mission_file(vehicle, mission_file):
    """
    Load and execute a mission from a file.

    Args:
        vehicle: The connected mavlink object
        mission_file: Path to mission file

    Returns:
        True if mission was loaded and started successfully, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info(f"Loading mission from file: {mission_file}")

        # TODO: Implement mission file loading
        # This would typically involve parsing a mission file format (e.g., .waypoints, .mission)
        # and uploading the waypoints to the vehicle using MAVLink mission protocol

        # For now, just log that this feature is not implemented
        logging.warning("Mission file loading not implemented yet")
        return False
    except Exception as e:
        logging.error(f"Error loading mission file: {str(e)}")
        return False


def wait_for_waypoint_blocking(vehicle, target_lat, target_lon, target_altitude, timeout=45, tolerance=1.0):
    """
    Blocking wait for waypoint arrival with real-time feedback and altitude monitoring.

    Args:
        vehicle: The connected mavlink object
        target_lat: Target latitude
        target_lon: Target longitude
        target_altitude: Target altitude to maintain
        timeout: Maximum time to wait in seconds
        tolerance: Distance tolerance in meters

    Returns:
        True if waypoint reached, False if timeout
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info(f"Navigating to waypoint: {target_lat:.7f}, {target_lon:.7f}")

        # Request high-frequency position updates
        vehicle.mav.request_data_stream_send(
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_DATA_STREAM_POSITION,
            10,  # 10 Hz
            1    # Start
        )

        start_time = time.time()
        last_distance = None
        stable_count = 0
        required_stable_readings = 3
        target_location = (target_lat, target_lon, 0)
        last_altitude_correction = 0

        print(f"\nNavigating to waypoint...")
        print("Target: {:.7f}, {:.7f} at {:.1f}m".format(target_lat, target_lon, target_altitude))
        print("-" * 70)

        while time.time() - start_time < timeout:
            # Get current position
            current_location = get_location(vehicle)

            if current_location:
                current_lat, current_lon, current_alt = current_location

                # Calculate distance to target
                distance = get_distance_metres(current_location, target_location)

                # Calculate bearing for reference
                bearing = calculate_bearing(current_lat, current_lon, target_lat, target_lon)

                # Monitor altitude loss and correct if needed
                altitude_loss = target_altitude - current_alt
                if altitude_loss > 0.5 and time.time() - last_altitude_correction > 2:
                    logging.warning(f"Altitude loss detected: {altitude_loss:.2f}m, correcting...")

                    # Send altitude correction command
                    vehicle.mav.set_position_target_global_int_send(
                        0,  # time_boot_ms
                        vehicle.target_system,
                        vehicle.target_component,
                        mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT,
                        0b0000111111111000,  # type_mask (only alt enabled)
                        int(current_lat * 1e7),
                        int(current_lon * 1e7),
                        target_altitude,
                        0, 0, 0, 0, 0, 0, 0, 0
                    )
                    last_altitude_correction = time.time()

                # Check if within tolerance
                if distance <= tolerance:
                    stable_count += 1
                    status = f"ARRIVED ({stable_count}/{required_stable_readings})"
                else:
                    stable_count = 0
                    status = f"MOVING (bearing: {bearing:.0f}¬∞)"

                # Real-time display with altitude
                timestamp = time.strftime("%H:%M:%S")
                alt_status = f"ALT: {current_alt:.2f}m"
                if altitude_loss > 0.3:
                    alt_status += f" (-{altitude_loss:.2f}m)"

                print(f"\r{timestamp} | Pos: {current_lat:.7f}, {current_lon:.7f} | {alt_status} | Dist: {distance:6.2f}m | {status}", end="", flush=True)

                # Check if we've reached waypoint with stability
                if stable_count >= required_stable_readings:
                    print(f"\n‚úì WAYPOINT REACHED! (Final distance: {distance:.2f}m, altitude: {current_alt:.2f}m)")
                    return True

                last_distance = distance

            # Safety check - ensure still armed and in correct mode
            heartbeat = vehicle.recv_match(type='HEARTBEAT', blocking=False)
            if heartbeat:
                armed = mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED
                if not armed:
                    print(f"\n‚úó Vehicle disarmed during waypoint navigation!")
                    return False

            time.sleep(0.2)  # 200ms update rate

        print(f"\n‚úó Timeout reaching waypoint (final distance: {last_distance:.2f}m)" if last_distance else "\n‚úó Timeout reaching waypoint")
        return False

    except Exception as e:
        logging.error(f"Error waiting for waypoint: {str(e)}")
        return False

def calculate_bearing(lat1, lon1, lat2, lon2):
    """
    Calculate bearing from point 1 to point 2.

    Returns:
        Bearing in degrees (0-360)
    """
    import math

    lat1_rad = math.radians(lat1)
    lat2_rad = math.radians(lat2)
    dlon_rad = math.radians(lon2 - lon1)

    y = math.sin(dlon_rad) * math.cos(lat2_rad)
    x = math.cos(lat1_rad) * math.sin(lat2_rad) - math.sin(lat1_rad) * math.cos(lat2_rad) * math.cos(dlon_rad)

    bearing_rad = math.atan2(y, x)
    bearing_deg = math.degrees(bearing_rad)

    return (bearing_deg + 360) % 360

def command_waypoint_precise(vehicle, target_lat, target_lon, altitude):
    """
    Send precise waypoint command using position target.

    Args:
        vehicle: The connected mavlink object
        target_lat: Target latitude
        target_lon: Target longitude
        altitude: Target altitude in meters

    Returns:
        True if command sent successfully
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info(f"Commanding waypoint: {target_lat:.7f}, {target_lon:.7f} at {altitude}m")

        # Send position target
        vehicle.mav.set_position_target_global_int_send(
            0,  # time_boot_ms (not used)
            vehicle.target_system,
            vehicle.target_component,
            mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT,
            0b0000111111111000,  # type_mask (position only)
            int(target_lat * 1e7),  # lat_int
            int(target_lon * 1e7),  # lon_int
            altitude,               # alt (meters)
            0, 0, 0,               # vx, vy, vz (not used)
            0, 0, 0,               # afx, afy, afz (not used)
            0, 0                   # yaw, yaw_rate (not used)
        )

        return True

    except Exception as e:
        logging.error(f"Error sending waypoint command: {str(e)}")
        return False

def mission_diamond_precision(vehicle, altitude=5):
    """
    Execute a precision diamond waypoint mission with blocking behavior.

    Args:
        vehicle: The connected mavlink object
        altitude: Flight altitude in meters

    Returns:
        True if mission was successful, False otherwise
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("=== PRECISION DIAMOND WAYPOINT MISSION ===")
        logging.info(f"Flight altitude: {altitude}m")

        # Define diamond waypoints around your field
        diamond_waypoints = [
            # (35.3482145, -119.1048425),  # North point
            # (35.3482019, -119.1049813),  # West point
            (35.3481850,	-119.1049075), # New West
            #(35.3481795,	-119.1046447),
            #(35.3481817,	-119.1047332),
            # (35.3481708, -119.1048297),  # South point
            (35.3481795, -119.1046386),  # East point
        ] * 70

        # Run pre-flight checks
        from drone.navigation import run_preflight_checks
        checks_passed, failure_reason = run_preflight_checks(vehicle)
        if not checks_passed:
            logging.error(f"Pre-flight checks failed: {failure_reason}")
            return False

        # Set to GUIDED mode
        logging.info("Setting mode to GUIDED")
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        # Arm and takeoff
        logging.info(f"üöÅ TAKEOFF: Arming and taking off to {altitude}m")
        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and takeoff")
            return False

        # Get home location for reference
        home_location = get_location(vehicle)
        if home_location:
            home_lat, home_lon, _ = home_location
            logging.info(f"Home position: {home_lat:.7f}, {home_lon:.7f}")
        else:
            logging.warning("Could not get home location")

        # Navigate to each waypoint in the diamond
        for i, (waypoint_lat, waypoint_lon) in enumerate(diamond_waypoints, 1):
            logging.info(f"\nüìç WAYPOINT {i}/{len(diamond_waypoints)}: Diamond Point {i}")

            # Send waypoint command
            if not command_waypoint_precise(vehicle, waypoint_lat, waypoint_lon, altitude):
                logging.error(f"Failed to send waypoint {i} command")
                return_to_launch(vehicle)
                return False

            # BLOCKING wait for waypoint arrival
            if not wait_for_waypoint_blocking(vehicle, waypoint_lat, waypoint_lon, altitude, timeout=60, tolerance=1.5):
                logging.error(f"Failed to reach waypoint {i}")
                return_to_launch(vehicle)
                return False

            logging.info(f"‚úì Successfully reached waypoint {i}")

            # Brief pause at each waypoint (except the last one)
            if i < len(diamond_waypoints):
                logging.info("Stabilizing for 2 seconds...")
                time.sleep(2)

        # Quick pause at final waypoint
        logging.info(f"\nüéØ DIAMOND COMPLETE: All {len(diamond_waypoints)} waypoints reached")
        logging.info("Final stabilization for 1 second...")
        time.sleep(1)

        # Return to launch with blocking behavior
        logging.info("\nüè† RETURN TO LAUNCH")
        logging.info("Commanding RTL...")

        if not return_to_launch(vehicle):
            logging.error("Failed to command RTL")
            return False

        # BLOCKING wait for landing with real-time feedback
        logging.info("Monitoring return and landing...")
        print("-" * 50)

        landing_start = time.time()
        landing_timeout = 90

        while time.time() - landing_start < landing_timeout:
            # Check armed status and altitude
            heartbeat = vehicle.recv_match(type='HEARTBEAT', blocking=True, timeout=1)
            if heartbeat:
                armed = mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED

                # Get current position and altitude
                pos_msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=False)
                if pos_msg:
                    current_alt = pos_msg.relative_alt / 1000.0
                    current_lat = pos_msg.lat / 1e7
                    current_lon = pos_msg.lon / 1e7

                    # Calculate distance to home if we have home location
                    dist_to_home = "N/A"
                    if home_location:
                        current_pos = (current_lat, current_lon, current_alt)
                        dist_to_home = f"{get_distance_metres(current_pos, home_location):.1f}m"
                else:
                    current_alt = None
                    dist_to_home = "N/A"

                timestamp = time.strftime("%H:%M:%S")
                armed_status = "ARMED" if armed else "DISARMED"
                alt_str = f"{current_alt:.3f}m" if current_alt is not None else "N/A"

                print(f"\r{timestamp} | Status: {armed_status} | Alt: {alt_str} | Home Dist: {dist_to_home}", end="", flush=True)

                if not armed:
                    print(f"\n‚úì LANDING COMPLETE - Vehicle disarmed")
                    break

            time.sleep(0.5)

        # Final verification
        time.sleep(1)
        final_armed = check_if_armed_simple(vehicle)
        if final_armed:
            logging.warning("Vehicle still armed after landing timeout - forcing disarm")
            disarm_vehicle(vehicle)

        logging.info("\nüéâ DIAMOND WAYPOINT MISSION COMPLETED SUCCESSFULLY")
        return True

    except Exception as e:
        logging.error(f"Error during diamond waypoint mission: {str(e)}")
        try:
            logging.warning("Attempting emergency return to launch")
            return_to_launch(vehicle)
            time.sleep(10)
            if check_if_armed_simple(vehicle):
                disarm_vehicle(vehicle)
        except:
            pass
        return False

def clean_message_streams(vehicle):
    """
    Clean up all existing message streams to prevent interference.
    This fixes the degradation over time issue.
    """
    if not vehicle:
        return False

    try:
        logging.info("Cleaning up message streams...")

        # Stop all message intervals
        common_message_ids = [
            mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT,
            mavutil.mavlink.MAVLINK_MSG_ID_GPS_RAW_INT,
            mavutil.mavlink.MAVLINK_MSG_ID_ATTITUDE,
            mavutil.mavlink.MAVLINK_MSG_ID_VFR_HUD,
            mavutil.mavlink.MAVLINK_MSG_ID_HEARTBEAT,
        ]

        for msg_id in common_message_ids:
            vehicle.mav.command_long_send(
                vehicle.target_system, vehicle.target_component,
                mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL, 0,
                msg_id, 0, 0, 0, 0, 0, 0  # 0 = stop
            )

        # Stop all legacy data streams
        for stream_id in range(13):  # ArduPilot has streams 0-12
            vehicle.mav.request_data_stream_send(
                vehicle.target_system, vehicle.target_component,
                stream_id, 0, 0  # Rate 0, stop
            )

        # Clear message buffer
        start_time = time.time()
        while time.time() - start_time < 1.0:  # Clear for 1 second
            vehicle.recv_match(blocking=False)

        logging.info("Message streams cleaned")
        return True

    except Exception as e:
        logging.warning(f"Error cleaning message streams: {str(e)}")
        return False

def setup_optimized_position_stream(vehicle, rate_hz=5):
    """
    Set up position stream optimized for your setup.
    Uses conservative rate and single method to prevent conflicts.
    """
    if not vehicle:
        return False

    try:
        # First clean existing streams
        clean_message_streams(vehicle)

        # Wait for cleanup to take effect
        time.sleep(0.5)

        logging.info(f"Setting up optimized position stream at {rate_hz} Hz")

        # Use ONLY the message interval method (which works best on your system)
        interval_us = int(1000000 / rate_hz)

        vehicle.mav.command_long_send(
            vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL, 0,
            mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT,
            interval_us, 0, 0, 0, 0, 0
        )

        # Wait for acknowledgment
        ack = vehicle.recv_match(type='COMMAND_ACK', blocking=True, timeout=2)
        if ack and ack.command == mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL:
            if ack.result == 0:
                logging.info("Position stream setup successful")
            else:
                logging.warning(f"Position stream setup ACK result: {ack.result}")

        # Test the stream briefly
        time.sleep(0.5)
        test_msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=True, timeout=2)
        if test_msg:
            lat = test_msg.lat / 1e7
            lon = test_msg.lon / 1e7
            alt = test_msg.relative_alt / 1000.0
            logging.info(f"Position stream test: {lat:.7f}, {lon:.7f}, {alt:.2f}m")
            return True
        else:
            logging.warning("Position stream test failed")
            return False

    except Exception as e:
        logging.error(f"Error setting up position stream: {str(e)}")
        return False

def get_location_single_request(vehicle, timeout=2):
    """
    Get location with single clean request - no sustained streaming.
    This prevents the degradation issue you're experiencing.
    """
    if not vehicle:
        return None

    try:
        # Clear buffer first
        while vehicle.recv_match(blocking=False):
            pass

        # Request ONE position update
        vehicle.mav.command_long_send(
            vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL, 0,
            mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT,
            100000, 0, 0, 0, 0, 0  # 10 Hz for just this request
        )

        # Get the message
        msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=True, timeout=timeout)

        # Stop the stream immediately
        vehicle.mav.command_long_send(
            vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_CMD_SET_MESSAGE_INTERVAL, 0,
            mavutil.mavlink.MAVLINK_MSG_ID_GLOBAL_POSITION_INT,
            0, 0, 0, 0, 0, 0  # Stop
        )

        if msg:
            lat = msg.lat / 1e7
            lon = msg.lon / 1e7
            alt = msg.relative_alt / 1000.0
            return (lat, lon, alt)
        else:
            return None

    except Exception as e:
        logging.warning(f"Error getting single location: {str(e)}")
        return None

def wait_for_waypoint_optimized(vehicle, target_lat, target_lon, target_altitude, timeout=60, tolerance=2.0):
    """
    Optimized waypoint waiting that works with your message rate patterns.
    Uses burst requests instead of sustained streaming.
    """
    if not vehicle:
        return False

    try:
        logging.info(f"Optimized navigation to: {target_lat:.7f}, {target_lon:.7f}")

        start_time = time.time()
        target_location = (target_lat, target_lon, 0)
        consecutive_good = 0
        required_good = 3
        last_distance = None
        check_interval = 1.0  # Check position every 1 second
        last_check = 0

        print(f"\nOptimized waypoint navigation...")
        print("Target: {:.7f}, {:.7f} at {:.1f}m".format(target_lat, target_lon, target_altitude))
        print("-" * 70)

        while time.time() - start_time < timeout:
            current_time = time.time()

            # Only check position at intervals to prevent stream degradation
            if current_time - last_check >= check_interval:
                # Get position with single clean request
                current_location = get_location_single_request(vehicle, timeout=2)
                last_check = current_time

                if current_location:
                    current_lat, current_lon, current_alt = current_location

                    # Calculate distance
                    distance = get_distance_metres(current_location, target_location)
                    bearing = calculate_bearing(current_lat, current_lon, target_lat, target_lon)

                    # Check altitude and correct if needed
                    altitude_error = target_altitude - current_alt
                    if abs(altitude_error) > 0.8:
                        logging.info(f"Altitude correction needed: {altitude_error:+.2f}m")

                        try:
                            vehicle.mav.set_position_target_global_int_send(
                                0, vehicle.target_system, vehicle.target_component,
                                mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT,
                                0b0000111111111000,  # Only altitude
                                int(current_lat * 1e7), int(current_lon * 1e7), target_altitude,
                                0, 0, 0, 0, 0, 0, 0, 0
                            )
                        except Exception as e:
                            logging.warning(f"Altitude correction failed: {str(e)}")

                    # Check if within tolerance
                    if distance <= tolerance:
                        consecutive_good += 1
                        status = f"ARRIVED ({consecutive_good}/{required_good})"
                    else:
                        consecutive_good = 0

                        # Show progress
                        if last_distance and distance < last_distance:
                            status = f"APPROACHING (‚Üì{last_distance-distance:.1f}m, bearing {bearing:.0f}¬∞)"
                        else:
                            status = f"MOVING (bearing {bearing:.0f}¬∞)"

                    # Display with timestamp
                    timestamp = time.strftime("%H:%M:%S")
                    alt_display = f"ALT: {current_alt:.2f}m"
                    if abs(altitude_error) > 0.3:
                        alt_display += f" ({altitude_error:+.2f}m)"

                    print(f"{timestamp} | Pos: {current_lat:.7f}, {current_lon:.7f} | {alt_display} | Dist: {distance:6.2f}m | {status}")

                    # Check if waypoint reached
                    if consecutive_good >= required_good:
                        print(f"‚úì WAYPOINT REACHED! (Final: {distance:.2f}m, alt: {current_alt:.2f}m)")
                        return True

                    last_distance = distance

                else:
                    print(f"{time.strftime('%H:%M:%S')} | ‚ö†Ô∏è  Position request failed")

            # Brief sleep between checks
            time.sleep(0.2)

        print(f"‚ùå Timeout after {timeout}s (final distance: {last_distance:.2f}m)" if last_distance else f"‚ùå Timeout after {timeout}s")
        return False

    except Exception as e:
        logging.error(f"Error during optimized waypoint wait: {str(e)}")
        return False

def command_waypoint_clean(vehicle, target_lat, target_lon, altitude):
    """Send waypoint command with clean approach"""
    if not vehicle:
        return False

    try:
        logging.info(f"Commanding waypoint: {target_lat:.7f}, {target_lon:.7f} at {altitude}m")

        vehicle.mav.set_position_target_global_int_send(
            0, vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT,
            0b0000111111111000,  # Position only
            int(target_lat * 1e7), int(target_lon * 1e7), altitude,
            0, 0, 0, 0, 0, 0, 0, 0
        )

        time.sleep(0.1)
        return True

    except Exception as e:
        logging.error(f"Error sending waypoint: {str(e)}")
        return False

def mission_diamond_precision_fixed(vehicle, altitude=5, loops=1):
    """
    Diamond mission optimized for your specific setup.
    Fixes the message degradation issue.
    """
    if not vehicle:
        return False

    try:
        logging.info("=== OPTIMIZED DIAMOND MISSION (Fixed for Your Setup) ===")

        # Clean up any existing streams first
        clean_message_streams(vehicle)

        # Your waypoints
        diamond_waypoints = [
            # (35.3481850, -119.1049075),  # West point
            # (35.3481795, -119.1046386),  # East point
            # Closer Positions
            (35.3481866,	-119.1047372), #left
            (35.3481888,	-119.1048713), #right
        ] * loops

        # Pre-flight checks and takeoff (using your existing functions)
        from drone.navigation import run_preflight_checks, set_mode, arm_and_takeoff, return_to_launch, check_if_armed, disarm_vehicle

        checks_passed, failure_reason = run_preflight_checks(vehicle)
        if not checks_passed:
            logging.error(f"Pre-flight checks failed: {failure_reason}")
            return False

        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to takeoff")
            return False

        # Get home position
        home_location = get_location_single_request(vehicle, timeout=5)
        if home_location:
            logging.info(f"Home: {home_location[0]:.7f}, {home_location[1]:.7f}")

        # Navigate to waypoints
        for i, (lat, lon) in enumerate(diamond_waypoints, 1):
            logging.info(f"\nüìç WAYPOINT {i}/{len(diamond_waypoints)}")

            if not command_waypoint_clean(vehicle, lat, lon, altitude):
                logging.error(f"Failed to command waypoint {i}")
                return_to_launch(vehicle)
                return False

            if not wait_for_waypoint_optimized(vehicle, lat, lon, altitude, timeout=90, tolerance=2.0):
                logging.error(f"Failed to reach waypoint {i}")
                return_to_launch(vehicle)
                return False

            logging.info(f"‚úì Waypoint {i} complete")
            if i < len(diamond_waypoints):
                time.sleep(2)

        # Return home
        logging.info("\nüè† RETURNING HOME")
        return_to_launch(vehicle)

        # Wait for landing
        start_time = time.time()
        while time.time() - start_time < 120:
            if not check_if_armed(vehicle):
                logging.info("‚úì Landed and disarmed")
                break
            time.sleep(2)

        # Final cleanup
        clean_message_streams(vehicle)

        logging.info("üéâ OPTIMIZED MISSION COMPLETE")
        return True

    except Exception as e:
        logging.error(f"Mission error: {str(e)}")
        try:
            clean_message_streams(vehicle)
            return_to_launch(vehicle)
        except:
            pass
        return False


--- missions\waypoint_bullseye.py ---
# missions/waypoint_bullseye.py - COMPLETE REWRITE v2
"""
Bullseye Detection with Collection and Middle Point Landing
---------------------------------------------------------
Collects all bullseye detections during flight, then lands at the middle point.
"""

import logging
import time
import threading
import cv2
import math
from pymavlink import mavutil

from drone.connection import get_vehicle_state
from drone.navigation import (
    run_preflight_checks, set_mode, arm_and_takeoff, return_to_launch,
    check_if_armed, disarm_vehicle, get_location, send_ned_velocity,
    get_distance_metres, get_location_metres
)
from detection.bullseye_detector import BullseyeDetector
from detection.camera import initialize_camera, capture_frame, close_camera

def mission_waypoint_bullseye_detection(vehicle, altitude=6, model_path="models/best.pt",
                                      confidence=0.5, loops=1, land_on_detection=True,
                                      video_recorder=None):
    """
    Execute waypoint mission collecting all bullseye detections and landing at middle point.

    Args:
        vehicle: The connected mavlink object
        altitude: Flight altitude in meters (default 6m)
        model_path: Path to YOLO model
        confidence: Detection confidence threshold
        loops: Number of times to repeat waypoint pattern
        land_on_detection: Whether to land when bullseye is detected
        video_recorder: Existing video recorder to share camera (optional)

    Returns:
        True if mission completed successfully
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("=== BULLSEYE COLLECTION AND MIDDLE POINT LANDING MISSION ===")
        logging.info(f"Flight altitude: {altitude}m")
        logging.info(f"Loops: {loops}")

        # Your specific waypoints
        waypoints = [
            (35.3481828, -119.1049256),  # Point 1
            (35.3481833, -119.1046789),  # Point 2
        ] * loops

        # Initialize bullseye detector
        detector = BullseyeDetector(
            model_path=model_path,
            confidence_threshold=confidence,
            imgsz=160
        )

        # Collection of ALL detection locations
        all_detections = []
        shared_camera = video_recorder is not None

        # Run pre-flight checks
        checks_passed, failure_reason = run_preflight_checks(vehicle)
        if not checks_passed:
            logging.error(f"Pre-flight checks failed: {failure_reason}")
            return False

        # Set to GUIDED mode and takeoff
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and takeoff")
            return False

        # Fly waypoints while collecting ALL detections
        for i, (target_lat, target_lon) in enumerate(waypoints, 1):
            logging.info(f"\nüìç Flying to waypoint {i}: {target_lat:.7f}, {target_lon:.7f}")

            # Send waypoint command
            command_waypoint(vehicle, target_lat, target_lon, altitude)

            # Monitor flight path and collect ALL detections
            path_detections = collect_detections_during_flight(
                vehicle, target_lat, target_lon, altitude, detector, video_recorder
            )

            # Add to our collection
            all_detections.extend(path_detections)

            if path_detections:
                logging.info(f"üéØ Collected {len(path_detections)} detections on path to waypoint {i}")
            else:
                logging.info(f"üìç No detections on path to waypoint {i}")

        # Process collected detections
        if len(all_detections) > 0:
            logging.info(f"üéØ TOTAL DETECTIONS COLLECTED: {len(all_detections)}")

            # Calculate middle point of all detections
            middle_point = calculate_middle_detection_point(all_detections)

            if middle_point:
                logging.info(f"üìç Calculated middle detection point: {middle_point[0]:.7f}, {middle_point[1]:.7f}")

                # Execute landing at middle point
                success = execute_middle_point_landing(
                    vehicle, middle_point, detector, video_recorder, altitude
                )

                if success:
                    logging.info("üéâ MISSION SUCCESS: Landed at middle of all detections!")
                    return True
                else:
                    logging.error("‚ùå Middle point landing failed")
            else:
                logging.error("‚ùå Could not calculate middle point")
        else:
            logging.info("üìç No bullseyes detected during entire mission")

        # Return to launch if no detections or landing failed
        logging.info("\nüè† RETURN TO LAUNCH")
        return_to_launch(vehicle)
        wait_for_landing(vehicle)

        logging.info("üéâ WAYPOINT COLLECTION MISSION COMPLETED")
        return True

    except Exception as e:
        logging.error(f"Error during waypoint collection mission: {str(e)}")
        try:
            return_to_launch(vehicle)
        except:
            pass
        return False

def collect_detections_during_flight(vehicle, target_lat, target_lon, altitude, detector, video_recorder):
    """
    Collect ALL bullseye detections during flight to waypoint.
    Returns list of detection dictionaries with GPS coordinates and camera info.
    """
    try:
        detections = []
        target_location = (target_lat, target_lon, 0)
        detection_check_interval = 0.1  # Check every 100ms for maximum coverage
        last_check = 0

        logging.info("üîç Collecting detections during flight...")

        while True:
            current_time = time.time()

            # Frequent detection checks
            if current_time - last_check >= detection_check_interval:
                # Get EXACT current GPS location
                current_location = get_location(vehicle)
                if not current_location:
                    time.sleep(0.05)
                    continue

                # Get camera frame at EXACT same time
                frame = get_camera_frame(video_recorder)
                if frame is None:
                    time.sleep(0.05)
                    continue

                # Check for bullseye in frame
                bullseyes, _ = detector.detect_bullseyes_in_frame(frame)

                if len(bullseyes) > 0:
                    # Bullseye detected! Store EXACT GPS-to-camera link
                    best_detection = max(bullseyes, key=lambda x: x[3])
                    center_x, center_y, bbox_info, confidence = best_detection

                    detection_data = {
                        'gps_location': current_location,  # EXACT GPS when frame captured
                        'camera_center': (center_x, center_y),
                        'confidence': confidence,
                        'timestamp': current_time
                    }

                    detections.append(detection_data)

                    logging.info(f"üéØ Detection #{len(detections)}: GPS {current_location[0]:.7f}, {current_location[1]:.7f} | "
                               f"Camera ({center_x}, {center_y}) | Conf: {confidence:.3f}")

                # Check if we've reached the waypoint
                distance = get_distance_metres(current_location, target_location)
                if distance <= 1.5:  # Within 1.5 meters
                    logging.info(f"‚úÖ Reached waypoint (distance: {distance:.1f}m)")
                    break

                last_check = current_time

            time.sleep(0.02)  # Very small sleep for maximum detection coverage

        logging.info(f"üìä Collected {len(detections)} detections on this path segment")
        return detections

    except Exception as e:
        logging.error(f"Error during detection collection: {str(e)}")
        return []

def calculate_middle_detection_point(all_detections):
    """
    Calculate the middle GPS point of all detections.
    Returns (lat, lon, alt) of the middle point.
    """
    try:
        if len(all_detections) == 0:
            return None

        # Extract all GPS coordinates
        latitudes = [d['gps_location'][0] for d in all_detections]
        longitudes = [d['gps_location'][1] for d in all_detections]
        altitudes = [d['gps_location'][2] for d in all_detections]

        # Calculate middle point (arithmetic mean)
        middle_lat = sum(latitudes) / len(latitudes)
        middle_lon = sum(longitudes) / len(longitudes)
        middle_alt = sum(altitudes) / len(altitudes)

        logging.info(f"üìä Detection spread:")
        logging.info(f"   Lat range: {min(latitudes):.7f} to {max(latitudes):.7f}")
        logging.info(f"   Lon range: {min(longitudes):.7f} to {max(longitudes):.7f}")
        logging.info(f"   Middle point: {middle_lat:.7f}, {middle_lon:.7f}")

        return (middle_lat, middle_lon, middle_alt)

    except Exception as e:
        logging.error(f"Error calculating middle point: {str(e)}")
        return None

def execute_middle_point_landing(vehicle, middle_point, detector, video_recorder, original_altitude):
    """
    Execute landing sequence at the calculated middle point.
    """
    try:
        logging.info("üéØ EXECUTING MIDDLE POINT LANDING SEQUENCE")

        middle_lat, middle_lon, middle_alt = middle_point

        # Step 1: Navigate to middle point
        logging.info(f"üìç Step 1: Flying to middle detection point {middle_lat:.7f}, {middle_lon:.7f}")

        command_waypoint(vehicle, middle_lat, middle_lon, original_altitude)

        # BLOCKING wait for arrival
        if not wait_for_waypoint_blocking(vehicle, middle_lat, middle_lon, original_altitude, timeout=30, tolerance=1.5):
            logging.error("‚ùå Failed to reach middle point")
            return False

        logging.info("‚úÖ Reached middle detection point")

        # Step 2: Verify bullseye at middle point
        frame = get_camera_frame(video_recorder)
        if frame is not None:
            bullseyes, _ = detector.detect_bullseyes_in_frame(frame)
            if len(bullseyes) == 0:
                logging.warning("‚ö†Ô∏è No bullseye at middle point - searching in small circle")

                # Small circle search at middle point
                found_location = search_in_circle(vehicle, middle_point, detector, video_recorder, radius=0.5)
                if found_location:
                    middle_point = found_location
                    middle_lat, middle_lon, middle_alt = middle_point
                    logging.info("üéØ Found bullseye in circle search")
                else:
                    logging.warning("‚ö†Ô∏è No bullseye in circle - proceeding with original middle point")

        # Step 3: Climb for better detection view
        detection_altitude = original_altitude + 2
        logging.info(f"üìà Step 3: Climbing to {detection_altitude}m for precision landing")

        command_waypoint(vehicle, middle_lat, middle_lon, detection_altitude)

        if not wait_for_altitude_blocking(vehicle, detection_altitude, timeout=20, tolerance=0.3):
            logging.warning("‚ö†Ô∏è Climb timeout - continuing anyway")

        # Step 4: Center on bullseye with drone geometry compensation
        logging.info("üéØ Step 4: Final centering with drone geometry compensation")

        if not center_on_bullseye_precise(vehicle, detector, video_recorder):
            logging.warning("‚ö†Ô∏è Could not center perfectly - landing anyway")

        # Step 5: Land
        logging.info("‚¨áÔ∏è Step 5: Initiating landing at middle detection point")

        if set_mode(vehicle, "LAND"):
            logging.info("‚úÖ Successfully switched to LAND mode")
            monitor_landing(vehicle)
            return True
        else:
            logging.error("‚ùå Failed to switch to LAND mode")
            return False

    except Exception as e:
        logging.error(f"Error in middle point landing: {str(e)}")
        return False

def center_on_bullseye_precise(vehicle, detector, video_recorder, max_attempts=6):
    """
    Precise centering with drone geometry compensation (15mm camera offset).
    """
    try:
        logging.info("üéØ Precise centering with 15mm camera offset compensation")

        # Drone geometry: camera is 15mm forward of flight controller center
        camera_offset_m = 0.015

        for attempt in range(max_attempts):
            # Get current frame
            frame = get_camera_frame(video_recorder)
            if frame is None:
                logging.warning(f"Attempt {attempt+1}: No camera frame")
                time.sleep(1)
                continue

            # Detect bullseye
            bullseyes, _ = detector.detect_bullseyes_in_frame(frame)
            if len(bullseyes) == 0:
                logging.warning(f"Attempt {attempt+1}: No bullseye detected")
                time.sleep(1)
                continue

            # Get best detection
            try:
                best_detection = max(bullseyes, key=lambda x: x[3])
                center_x, center_y, _, confidence = best_detection
            except Exception as e:
                logging.error(f"Error processing detection: {str(e)}")
                continue

            # Get frame dimensions
            try:
                frame_height, frame_width = frame.shape[:2]
                frame_center_x = frame_width // 2
                frame_center_y = frame_height // 2
            except Exception as e:
                logging.error(f"Error getting frame dimensions: {str(e)}")
                continue

            # Calculate offset from frame center
            try:
                offset_x = float(center_x) - float(frame_center_x)
                offset_y = float(center_y) - float(frame_center_y)
                offset_distance = (offset_x**2 + offset_y**2)**0.5
            except Exception as e:
                logging.error(f"Error calculating offset: {str(e)}")
                continue

            logging.info(f"Centering attempt {attempt+1}: Bullseye at ({center_x}, {center_y}), "
                        f"offset ({offset_x:.0f}, {offset_y:.0f})px, distance: {offset_distance:.1f}px")

            # Check if well centered
            if offset_distance <= 12:  # Tight tolerance
                logging.info("üéØ PERFECTLY CENTERED! Ready for landing")
                return True

            # Calculate correction with geometry compensation
            pixels_per_meter = 80  # Rough estimate at higher altitude

            # Convert to meters
            offset_x_m = offset_x / pixels_per_meter
            offset_y_m = offset_y / pixels_per_meter

            # Apply 15mm camera offset compensation
            # When camera sees bullseye center, move drone so FC center aligns
            corrected_offset_y_m = offset_y_m - camera_offset_m

            # Gentle correction velocities
            max_velocity = 0.15  # Very gentle
            velocity_east = max(-max_velocity, min(max_velocity, offset_x_m * 0.3))
            velocity_north = max(-max_velocity, min(max_velocity, -corrected_offset_y_m * 0.3))

            logging.info(f"Precision correction: N={velocity_north:.3f}, E={velocity_east:.3f} m/s")

            # Apply gentle correction
            send_ned_velocity(vehicle, velocity_north, velocity_east, 0, 2)
            time.sleep(3)  # Wait for stabilization

        logging.info("üéØ Centering completed (may not be perfect)")
        return True

    except Exception as e:
        logging.error(f"Error in precise centering: {str(e)}")
        return True  # Continue anyway

def search_in_circle(vehicle, center_location, detector, video_recorder, radius=0.5, points=6):
    """
    Small circle search around center point.
    """
    try:
        logging.info(f"üîç Small circle search: {radius}m radius, {points} points")

        center_lat, center_lon, center_alt = center_location

        for i in range(points):
            angle = (i * 360 / points) * math.pi / 180

            north_offset = radius * math.cos(angle)
            east_offset = radius * math.sin(angle)

            search_location = get_location_metres(center_location, north_offset, east_offset)
            search_lat, search_lon, search_alt = search_location

            logging.info(f"   Point {i+1}/{points}: {search_lat:.7f}, {search_lon:.7f}")

            command_waypoint(vehicle, search_lat, search_lon, center_alt)
            time.sleep(1.5)

            frame = get_camera_frame(video_recorder)
            if frame is not None:
                bullseyes, _ = detector.detect_bullseyes_in_frame(frame)
                if len(bullseyes) > 0:
                    logging.info(f"üéØ Found bullseye at circle point {i+1}!")
                    current_location = get_location(vehicle)
                    return current_location if current_location else search_location

        return None

    except Exception as e:
        logging.error(f"Error in circle search: {str(e)}")
        return None

def get_camera_frame(video_recorder):
    """Get frame from shared video recorder"""
    try:
        if video_recorder is not None and hasattr(video_recorder, 'cap') and video_recorder.cap is not None:
            ret, frame = video_recorder.cap.read()
            if ret:
                return frame
        return None
    except Exception as e:
        logging.warning(f"Error getting camera frame: {str(e)}")
        return None

def command_waypoint(vehicle, lat, lon, alt):
    """Send waypoint command"""
    try:
        vehicle.mav.set_position_target_global_int_send(
            0, vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT,
            0b0000111111111000,
            int(lat * 1e7), int(lon * 1e7), alt,
            0, 0, 0, 0, 0, 0, 0, 0
        )
        return True
    except Exception as e:
        logging.error(f"Error sending waypoint: {str(e)}")
        return False

def wait_for_waypoint_blocking(vehicle, target_lat, target_lon, target_altitude, timeout=45, tolerance=1.5):
    """Blocking wait for waypoint arrival"""
    if not vehicle:
        return False

    try:
        start_time = time.time()
        target_location = (target_lat, target_lon, 0)
        stable_count = 0
        required_stable_readings = 3

        while time.time() - start_time < timeout:
            current_location = get_location(vehicle)
            if current_location:
                distance = get_distance_metres(current_location, target_location)

                if distance <= tolerance:
                    stable_count += 1
                    if stable_count >= required_stable_readings:
                        logging.info(f"‚úÖ Waypoint reached (distance: {distance:.2f}m)")
                        return True
                else:
                    stable_count = 0

            time.sleep(0.3)

        logging.warning("‚è∞ Waypoint timeout")
        return False

    except Exception as e:
        logging.error(f"Error waiting for waypoint: {str(e)}")
        return False

def wait_for_altitude_blocking(vehicle, target_altitude, timeout=30, tolerance=0.3):
    """Blocking wait for altitude"""
    try:
        start_time = time.time()
        stable_count = 0
        required_stable_readings = 3

        while time.time() - start_time < timeout:
            try:
                msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=True, timeout=1)
                if msg:
                    current_altitude = msg.relative_alt / 1000.0
                    altitude_diff = abs(current_altitude - target_altitude)

                    if altitude_diff <= tolerance:
                        stable_count += 1
                        if stable_count >= required_stable_readings:
                            logging.info(f"‚úÖ Altitude reached: {current_altitude:.2f}m")
                            return True
                    else:
                        stable_count = 0
            except:
                pass

            time.sleep(0.2)

        logging.warning("‚è∞ Altitude timeout")
        return False

    except Exception as e:
        logging.error(f"Error waiting for altitude: {str(e)}")
        return False

def monitor_landing(vehicle):
    """Monitor landing process"""
    try:
        logging.info("üìâ Monitoring landing...")
        start_time = time.time()

        while time.time() - start_time < 60:
            if not check_if_armed(vehicle):
                logging.info("‚úÖ Landing complete - vehicle disarmed")
                return True

            try:
                msg = vehicle.recv_match(type='GLOBAL_POSITION_INT', blocking=True, timeout=1)
                if msg:
                    alt = msg.relative_alt / 1000.0
                    if alt < 0.5:
                        logging.info("‚úÖ Near ground - landing complete")
                        return True
            except:
                pass

            time.sleep(2)

        return True

    except Exception as e:
        logging.error(f"Error monitoring landing: {str(e)}")
        return True

def wait_for_landing(vehicle):
    """Wait for vehicle to land and disarm"""
    try:
        start_time = time.time()
        while time.time() - start_time < 120:
            if not check_if_armed(vehicle):
                logging.info("‚úÖ Vehicle has landed and disarmed")
                break
            time.sleep(2)
    except:
        pass


--- missions\waypoint_gcp.py ---
# missions/waypoint_gcp.py - UPDATED WITH MINIMAL CHANGES
"""
GCP Detection with Marker Search and Numbered Marker Collection - Updated
------------------------------------------------------------------------
Added early termination and configurable thresholds while keeping everything else the same.
"""

import logging
import time
import json
import cv2
import math
import os
from datetime import datetime
from pymavlink import mavutil

from drone.connection import get_vehicle_state
from drone.navigation import (
    run_preflight_checks, set_mode, arm_and_takeoff, return_to_launch,
    check_if_armed, disarm_vehicle, get_location, send_ned_velocity,
    get_distance_metres, get_location_metres
)
from detection.camera import initialize_camera, capture_frame, close_camera

# Try to import YOLO, fallback if not available
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    logging.warning("YOLO not available - install ultralytics: pip install ultralytics")

class GCPDetector:
    """GCP detector for markers and numbered markers using YOLO"""

    def __init__(self, model_path="models/best-gcp.pt", confidence_threshold=0.5, imgsz=160):
        """Initialize GCP detector with YOLO model"""
        if not YOLO_AVAILABLE:
            raise ImportError("YOLO not available. Install with: pip install ultralytics")

        self.model_path = model_path
        self.conf_threshold = confidence_threshold
        self.imgsz = imgsz

        if not os.path.exists(model_path):
            raise FileNotFoundError(f"GCP model file not found: {model_path}")

        logging.info(f"Loading GCP YOLO model: {self.model_path}")
        self.model = YOLO(self.model_path)

        # Performance tracking
        self.frame_count = 0
        self.total_inference_time = 0
        self.detections_count = 0

    def detect_gcp_markers_in_frame(self, frame):
        """
        Detect GCP markers in frame using YOLO model.

        Returns:
            List of detections: [(class_name, center_x, center_y, bbox, confidence), ...]
        """
        if frame is None:
            return [], frame

        try:
            start_time = time.time()

            # Run YOLO inference
            results = self.model.predict(
                frame,
                imgsz=self.imgsz,
                conf=self.conf_threshold,
                verbose=False
            )

            inference_time = time.time() - start_time
            self.total_inference_time += inference_time
            self.frame_count += 1

            # Process results
            detections = []
            debug_image = frame.copy()

            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        # Extract box coordinates and confidence
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        confidence = float(box.conf[0])
                        class_id = int(box.cls[0])

                        # Get class name
                        class_name = result.names[class_id] if hasattr(result, 'names') else f"class_{class_id}"

                        # Calculate center
                        center_x = (x1 + x2) // 2
                        center_y = (y1 + y2) // 2

                        # Create bbox info
                        bbox = (x1, y1, x2, y2)

                        # Add to detections
                        detections.append((class_name, center_x, center_y, bbox, confidence))
                        self.detections_count += 1

                        # Draw on debug image
                        self._draw_detection(debug_image, x1, y1, x2, y2, center_x, center_y,
                                           class_name, confidence)

            # Add frame info
            self._add_frame_info(debug_image, len(detections), inference_time)

            return detections, debug_image

        except Exception as e:
            logging.error(f"Error in GCP detection: {str(e)}")
            return [], frame

    def _draw_detection(self, image, x1, y1, x2, y2, center_x, center_y, class_name, confidence):
        """Draw detection on image"""
        # Color coding: green for markers, blue for marker-numbered
        color = (0, 255, 0) if class_name == 'markers' else (255, 0, 0)

        # Draw bounding box
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)

        # Draw center point
        cv2.circle(image, (center_x, center_y), 5, color, -1)

        # Draw crosshair at center
        cv2.line(image, (center_x - 10, center_y), (center_x + 10, center_y), color, 2)
        cv2.line(image, (center_x, center_y - 10), (center_x, center_y + 10), color, 2)

        # Add label
        label = f"{class_name}: {confidence:.3f}"
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
        cv2.rectangle(image, (x1, y1 - label_size[1] - 10),
                     (x1 + label_size[0], y1), color, -1)
        cv2.putText(image, label, (x1, y1 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    def _add_frame_info(self, image, num_detections, inference_time):
        """Add frame information overlay"""
        fps = 1.0 / inference_time if inference_time > 0 else 0

        # Add frame info
        info_text = f"GCP FPS: {fps:.1f} | Detections: {num_detections} | Frame: {self.frame_count}"
        cv2.putText(image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)

        # Add crosshair at frame center
        h, w = image.shape[:2]
        cv2.line(image, (w//2 - 20, h//2), (w//2 + 20, h//2), (0, 255, 255), 2)
        cv2.line(image, (w//2, h//2 - 20), (w//2, h//2 + 20), (0, 255, 255), 2)
        cv2.circle(image, (w//2, h//2), 3, (0, 255, 255), -1)

def mission_waypoint_gcp_detection(vehicle, altitude=6, model_path="models/best-gcp.pt",
                                 confidence=0.5, loops=1, video_recorder=None,
                                 min_numbered_markers=3, min_general_markers=3,
                                 marker_distance_threshold=2.0):
    """
    Execute waypoint mission searching for GCP markers and numbered markers.

    Args:
        vehicle: The connected mavlink object
        altitude: Flight altitude in meters
        model_path: Path to GCP YOLO model
        confidence: Detection confidence threshold
        loops: Number of times to repeat waypoint pattern
        video_recorder: Existing video recorder (optional)
        min_numbered_markers: Minimum numbered markers to find before concluding (default: 3)
        min_general_markers: Minimum general markers to investigate before concluding (default: 3)
        marker_distance_threshold: Minimum distance between markers to consider them separate (default: 2.0m)

    Returns:
        True if mission completed successfully
    """
    if not vehicle:
        logging.error("No vehicle connection")
        return False

    try:
        logging.info("=== GCP MARKER DETECTION AND COLLECTION MISSION ===")
        logging.info(f"Flight altitude: {altitude}m")
        logging.info(f"Model: {model_path}")
        logging.info(f"Confidence threshold: {confidence}")
        logging.info(f"Min numbered markers for conclusion: {min_numbered_markers}")
        logging.info(f"Min general markers for conclusion: {min_general_markers}")
        logging.info(f"Marker distance threshold: {marker_distance_threshold}m")

        # Your specific waypoints
        waypoints = [
            (35.3481828, -119.1049256),  # Point 1
            (35.3481833, -119.1046789),  # Point 2
        ] * loops

        # Initialize GCP detector
        detector = GCPDetector(
            model_path=model_path,
            confidence_threshold=confidence,
            imgsz=160
        )

        # Initialize collections
        numbered_markers = []  # For marker-numbered detections
        markers_to_investigate = []  # For markers that need circle search

        # Create output directories
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"results/gcp_mission_results_{timestamp}"
        os.makedirs(output_dir, exist_ok=True)

        # Run pre-flight checks
        checks_passed, failure_reason = run_preflight_checks(vehicle)
        if not checks_passed:
            logging.error(f"Pre-flight checks failed: {failure_reason}")
            return False

        # Set to GUIDED mode and takeoff
        if not set_mode(vehicle, "GUIDED"):
            logging.error("Failed to set GUIDED mode")
            return False

        if not arm_and_takeoff(vehicle, altitude):
            logging.error("Failed to arm and takeoff")
            return False

        # UPDATED: Fly waypoints with early termination on marker detection
        for i, (target_lat, target_lon) in enumerate(waypoints):
            try:
                # Validate waypoint format
                if not waypoints or len(waypoints[i]) < 2:
                    logging.error(f"Invalid waypoint {i+1}: {waypoints[i]}")
                    continue

                target_lat, target_lon = waypoints[i][0], waypoints[i][1]

                # Validate coordinates
                if not (-90 <= target_lat <= 90) or not (-180 <= target_lon <= 180):
                    logging.error(f"Invalid coordinates for waypoint {i+1}: {target_lat}, {target_lon}")
                    continue

                logging.info(f"\nüìç Flying to waypoint {i+1}/{len(waypoints)}: {target_lat:.7f}, {target_lon:.7f}")

                # Send waypoint command with error checking
                if not command_waypoint(vehicle, target_lat, target_lon, altitude):
                    logging.error(f"Failed to send waypoint {i+1} command, continuing to next waypoint")
                    continue

                # Monitor flight path and collect detections with EARLY TERMINATION
                try:
                    path_detections, should_terminate = collect_gcp_detections_with_termination(
                        vehicle, target_lat, target_lon, altitude, detector,
                        video_recorder, numbered_markers, markers_to_investigate, output_dir,
                        marker_distance_threshold
                    )

                    # Count detections safely
                    numbered_count = sum(1 for d in path_detections if d.get('class') == 'marker-numbered')
                    markers_count = sum(1 for d in path_detections if d.get('class') == 'markers')

                    logging.info(f"üìä Path {i+1} summary: {numbered_count} numbered, {markers_count} markers")

                    # EARLY TERMINATION: If markers detected, stop waypoint sequence and investigate
                    if should_terminate:
                        logging.info(f"üõë EARLY TERMINATION: Markers detected, starting immediate investigation")
                        break

                except Exception as path_error:
                    logging.error(f"Error during path {i+1} detection collection: {str(path_error)}")
                    continue

            except Exception as waypoint_error:
                logging.error(f"Error processing waypoint {i+1}: {str(waypoint_error)}")
                continue

        # Process any markers that need circle investigation
        if markers_to_investigate:
            logging.info(f"\nüîç INVESTIGATING {len(markers_to_investigate)} MARKERS WITH CIRCLE SEARCH")

            for marker_idx, marker_location in enumerate(markers_to_investigate):
                try:
                    # Validate marker location
                    if not marker_location or len(marker_location) < 2:
                        logging.error(f"Invalid marker location {marker_idx + 1}: {marker_location}")
                        continue

                    logging.info(f"\nüéØ Investigating marker {marker_idx + 1}/{len(markers_to_investigate)}")
                    logging.info(f"   Location: {marker_location[0]:.7f}, {marker_location[1]:.7f}")

                    # Go to marker location
                    if not command_waypoint(vehicle, marker_location[0], marker_location[1], altitude):
                        logging.error(f"Failed to command waypoint for marker {marker_idx + 1}")
                        continue

                    if not wait_for_waypoint_blocking(vehicle, marker_location[0], marker_location[1],
                                                    altitude, timeout=45, tolerance=1.5):
                        logging.warning(f"Failed to reach marker {marker_idx + 1}, skipping circle search")
                        continue

                    # Perform 1m circle search around marker with termination conditions
                    try:
                        circle_detections, investigation_complete = perform_circle_search(
                            vehicle, marker_location, detector, video_recorder,
                            numbered_markers, markers_to_investigate, output_dir,
                            radius=1.0, min_numbered_markers=min_numbered_markers,
                            min_general_markers=min_general_markers,
                            marker_distance_threshold=marker_distance_threshold
                        )

                        logging.info(f"üîç Circle search complete: {len(circle_detections)} new detections")

                        # Check if investigation is complete
                        if investigation_complete:
                            logging.info(f"üéØ Investigation complete - found sufficient markers")
                            break

                    except Exception as circle_error:
                        logging.error(f"Error during circle search for marker {marker_idx + 1}: {str(circle_error)}")
                        continue

                except Exception as marker_error:
                    logging.error(f"Error investigating marker {marker_idx + 1}: {str(marker_error)}")
                    continue
        else:
            logging.info("üîç No markers found that require circle investigation")

        # Save numbered markers to JSON
        try:
            save_numbered_markers_json(numbered_markers, output_dir)
        except Exception as save_error:
            logging.error(f"Error saving numbered markers JSON: {str(save_error)}")

        # Mission summary
        logging.info(f"\nüìä MISSION SUMMARY:")
        logging.info(f"   Numbered markers found: {len(numbered_markers)}")
        logging.info(f"   Markers investigated: {len(markers_to_investigate)}")
        logging.info(f"   Results saved to: {output_dir}")

        # Return to launch
        logging.info("\nüè† RETURN TO LAUNCH")
        return_to_launch(vehicle)
        wait_for_landing(vehicle)

        logging.info("üéâ GCP DETECTION MISSION COMPLETED SUCCESSFULLY")
        return True

    except Exception as e:
        logging.error(f"Critical error during GCP detection mission: {str(e)}")
        logging.exception("Full exception details:")
        try:
            logging.info("Attempting emergency return to launch")
            return_to_launch(vehicle)
        except Exception as rtl_error:
            logging.error(f"Emergency RTL also failed: {str(rtl_error)}")
        return False

def collect_gcp_detections_with_termination(vehicle, target_lat, target_lon, altitude, detector,
                                           video_recorder, numbered_markers, markers_to_investigate,
                                           output_dir, marker_distance_threshold=2.0):
    """
    Collect GCP detections during flight to waypoint with early termination capability.

    Returns:
        (detections, should_terminate): Tuple of detections list and termination flag
    """
    try:
        detections = []
        target_location = (target_lat, target_lon, 0)
        detection_check_interval = 0.15
        last_check = 0
        should_terminate = False

        # Add timeout to prevent infinite loops
        flight_start_time = time.time()
        max_flight_time = 120

        logging.info("üîç Scanning for GCP markers during flight...")

        while True:
            current_time = time.time()

            # Safety timeout check
            if current_time - flight_start_time > max_flight_time:
                logging.warning(f"Flight to waypoint timed out after {max_flight_time}s")
                break

            if current_time - last_check >= detection_check_interval:
                # Get current GPS location
                try:
                    current_location = get_location(vehicle)
                    if not current_location:
                        time.sleep(0.05)
                        continue
                except Exception as loc_error:
                    logging.warning(f"Error getting location: {str(loc_error)}")
                    time.sleep(0.05)
                    continue

                # Get camera frame
                try:
                    frame = get_camera_frame(video_recorder)
                    if frame is None:
                        time.sleep(0.05)
                        continue
                except Exception as frame_error:
                    logging.warning(f"Error getting camera frame: {str(frame_error)}")
                    time.sleep(0.05)
                    continue

                # Detect GCP markers
                try:
                    gcp_detections, debug_image = detector.detect_gcp_markers_in_frame(frame)
                except Exception as detection_error:
                    logging.warning(f"Error during GCP detection: {str(detection_error)}")
                    time.sleep(0.05)
                    continue

                # Process each detection
                for detection_data in gcp_detections:
                    try:
                        if len(detection_data) < 5:
                            logging.warning(f"Invalid detection data format: {detection_data}")
                            continue

                        class_name, center_x, center_y, bbox, confidence = detection_data

                        detection_dict = {
                            'class': class_name,
                            'gps_location': current_location,
                            'camera_center': (center_x, center_y),
                            'bbox': bbox,
                            'confidence': confidence,
                            'timestamp': current_time
                        }

                        detections.append(detection_dict)

                        logging.info(f"üéØ {class_name.upper()} detected: GPS {current_location[0]:.7f}, {current_location[1]:.7f} | "
                                   f"Conf: {confidence:.3f}")

                        # Handle marker-numbered class
                        if class_name == 'marker-numbered':
                            try:
                                save_numbered_marker(detection_dict, frame, output_dir, numbered_markers)
                            except Exception as save_error:
                                logging.error(f"Error saving numbered marker: {str(save_error)}")

                        # Handle markers class - SET TERMINATION FLAG
                        elif class_name == 'markers':
                            try:
                                # Add to investigation list if not already close to an existing marker
                                should_add = True
                                for existing_marker in markers_to_investigate:
                                    if len(existing_marker) >= 2:
                                        distance = get_distance_metres(current_location, existing_marker)
                                        if distance < marker_distance_threshold:
                                            should_add = False
                                            break

                                if should_add:
                                    markers_to_investigate.append(current_location)
                                    logging.info(f"‚ûï Added marker for investigation: {current_location[0]:.7f}, {current_location[1]:.7f}")

                                # SET TERMINATION FLAG when any general marker is detected
                                should_terminate = True
                                logging.info(f"üõë General marker detected - will terminate waypoint sequence after reaching this waypoint")

                            except Exception as marker_error:
                                logging.error(f"Error processing marker for investigation: {str(marker_error)}")

                    except Exception as process_error:
                        logging.error(f"Error processing individual detection: {str(process_error)}")
                        continue

                # Check if reached waypoint
                try:
                    distance = get_distance_metres(current_location, target_location)
                    if distance <= 1.5:
                        logging.info(f"‚úÖ Reached waypoint (distance: {distance:.1f}m)")
                        break
                except Exception as distance_error:
                    logging.warning(f"Error calculating distance to waypoint: {str(distance_error)}")

                last_check = current_time

            time.sleep(0.02)

        return detections, should_terminate

    except Exception as e:
        logging.error(f"Critical error during GCP detection collection: {str(e)}")
        return [], False

def perform_circle_search(vehicle, center_location, detector, video_recorder,
                         numbered_markers, markers_to_investigate, output_dir,
                         radius=1.0, points=8, min_numbered_markers=3, min_general_markers=3,
                         marker_distance_threshold=2.0):
    """
    Perform circle search around a marker location with termination conditions.

    Returns:
        (circle_detections, investigation_complete): Tuple of detections and completion flag
    """
    try:
        # Validate input parameters
        if not center_location or len(center_location) < 3:
            logging.error(f"Invalid center location: {center_location}")
            return [], False

        if radius <= 0 or points <= 0:
            logging.error(f"Invalid circle parameters: radius={radius}, points={points}")
            return [], False

        logging.info(f"üîÑ Performing {radius}m circle search with {points} points")
        logging.info(f"Will conclude if find {min_numbered_markers} numbered or {min_general_markers} general markers")

        center_lat, center_lon, center_alt = center_location
        circle_detections = []

        # Track unique markers found
        unique_numbered_markers = []
        unique_general_markers = []

        for i in range(points):
            try:
                angle = (i * 360 / points) * math.pi / 180

                north_offset = radius * math.cos(angle)
                east_offset = radius * math.sin(angle)

                search_location = get_location_metres(center_location, north_offset, east_offset)
                if not search_location or len(search_location) < 3:
                    logging.warning(f"Failed to calculate search location for point {i+1}")
                    continue

                search_lat, search_lon, search_alt = search_location

                logging.info(f"   üéØ Circle point {i+1}/{points}: {search_lat:.7f}, {search_lon:.7f}")

                # Move to circle point
                if not command_waypoint(vehicle, search_lat, search_lon, center_alt):
                    logging.warning(f"Failed to command circle point {i+1}")
                    continue

                # Wait briefly for movement
                time.sleep(2)

                # Check for detections at this point
                try:
                    frame = get_camera_frame(video_recorder)
                    if frame is not None:
                        gcp_detections, _ = detector.detect_gcp_markers_in_frame(frame)

                        if gcp_detections:
                            current_location = get_location(vehicle)
                            if current_location:
                                for detection_data in gcp_detections:
                                    try:
                                        if len(detection_data) < 5:
                                            continue

                                        class_name, center_x, center_y, bbox, confidence = detection_data

                                        detection_dict = {
                                            'class': class_name,
                                            'gps_location': current_location,
                                            'camera_center': (center_x, center_y),
                                            'bbox': bbox,
                                            'confidence': confidence,
                                            'timestamp': time.time(),
                                            'found_in_circle': True
                                        }

                                        circle_detections.append(detection_dict)

                                        logging.info(f"üéØ Circle detection: {class_name} at {current_location[0]:.7f}, {current_location[1]:.7f}")

                                        # Check if this is a new unique marker
                                        is_new_marker = True
                                        if class_name == 'marker-numbered':
                                            for existing_loc in unique_numbered_markers:
                                                if get_distance_metres(current_location, existing_loc) < marker_distance_threshold:
                                                    is_new_marker = False
                                                    break
                                            if is_new_marker:
                                                unique_numbered_markers.append(current_location)
                                                save_numbered_marker(detection_dict, frame, output_dir, numbered_markers)
                                        elif class_name == 'markers':
                                            for existing_loc in unique_general_markers:
                                                if get_distance_metres(current_location, existing_loc) < marker_distance_threshold:
                                                    is_new_marker = False
                                                    break
                                            if is_new_marker:
                                                unique_general_markers.append(current_location)
                                                markers_to_investigate.append(current_location)
                                                logging.info(f"‚ûï New marker found in circle, added for investigation")

                                        # CHECK TERMINATION CONDITIONS
                                        if len(unique_numbered_markers) >= min_numbered_markers:
                                            logging.info(f"üéØ Found {len(unique_numbered_markers)} numbered markers - concluding circle search")
                                            return circle_detections, True
                                        elif len(unique_general_markers) >= min_general_markers:
                                            logging.info(f"üìç Investigated {len(unique_general_markers)} general markers - concluding circle search")
                                            return circle_detections, True

                                    except Exception as det_error:
                                        logging.error(f"Error processing circle detection: {str(det_error)}")
                                        continue
                except Exception as frame_error:
                    logging.warning(f"Error processing frame at circle point {i+1}: {str(frame_error)}")

            except Exception as point_error:
                logging.error(f"Error at circle point {i+1}: {str(point_error)}")
                continue

        # Return to center after circle
        try:
            command_waypoint(vehicle, center_lat, center_lon, center_alt)
            time.sleep(2)
        except Exception as return_error:
            logging.warning(f"Error returning to circle center: {str(return_error)}")

        return circle_detections, False

    except Exception as e:
        logging.error(f"Critical error during circle search: {str(e)}")
        return [], False

def save_numbered_marker(detection_data, frame, output_dir, numbered_markers):
    """
    Save numbered marker detection to JSON and crop image.
    """
    try:
        # Validate inputs
        if not detection_data or 'bbox' not in detection_data:
            logging.error("Invalid detection data for saving numbered marker")
            return

        if frame is None:
            logging.error("No frame provided for saving numbered marker")
            return

        marker_id = len(numbered_markers) + 1
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]

        # Crop the detected region
        try:
            x1, y1, x2, y2 = detection_data['bbox']

            # Validate bbox coordinates
            h, w = frame.shape[:2]
            if x1 < 0 or y1 < 0 or x2 > w or y2 > h or x1 >= x2 or y1 >= y2:
                logging.warning(f"Invalid bbox coordinates: {detection_data['bbox']}, frame size: {w}x{h}")
                # Use center crop as fallback
                center_x, center_y = detection_data.get('camera_center', (w//2, h//2))
                crop_size = 50
                x1 = max(0, center_x - crop_size)
                y1 = max(0, center_y - crop_size)
                x2 = min(w, center_x + crop_size)
                y2 = min(h, center_y + crop_size)

            # Add some padding to the crop
            padding = 20
            x1_crop = max(0, x1 - padding)
            y1_crop = max(0, y1 - padding)
            x2_crop = min(w, x2 + padding)
            y2_crop = min(h, y2 + padding)

            cropped_image = frame[y1_crop:y2_crop, x1_crop:x2_crop]

            if cropped_image.size == 0:
                logging.error("Cropped image is empty, using full frame")
                cropped_image = frame

        except Exception as crop_error:
            logging.error(f"Error cropping image: {str(crop_error)}, using full frame")
            cropped_image = frame

        # Save cropped image
        try:
            crop_filename = f"numbered_marker_{marker_id:03d}_{timestamp}.jpg"
            crop_path = os.path.join(output_dir, crop_filename)
            cv2.imwrite(crop_path, cropped_image)
        except Exception as save_error:
            logging.error(f"Error saving cropped image: {str(save_error)}")
            crop_filename = "save_failed.jpg"

        # Prepare data for JSON
        try:
            gps_location = detection_data.get('gps_location', (0, 0, 0))
            camera_center = detection_data.get('camera_center', (0, 0))
            bbox = detection_data.get('bbox', (0, 0, 0, 0))
            confidence = detection_data.get('confidence', 0.0)
            timestamp_val = detection_data.get('timestamp', time.time())

            marker_data = {
                'id': marker_id,
                'gps_location': {
                    'latitude': gps_location[0],
                    'longitude': gps_location[1],
                    'altitude': gps_location[2]
                },
                'detection': {
                    'camera_center': camera_center,
                    'bbox': bbox,
                    'confidence': confidence
                },
                'timestamp': timestamp_val,
                'timestamp_str': datetime.fromtimestamp(timestamp_val).isoformat(),
                'cropped_image_path': crop_filename,
                'found_in_circle': detection_data.get('found_in_circle', False)
            }

            numbered_markers.append(marker_data)

            logging.info(f"üíæ Saved numbered marker #{marker_id}: {crop_filename}")

        except Exception as data_error:
            logging.error(f"Error preparing numbered marker data: {str(data_error)}")

    except Exception as e:
        logging.error(f"Critical error saving numbered marker: {str(e)}")

def save_numbered_markers_json(numbered_markers, output_dir):
    """
    Save all numbered markers to JSON file.
    """
    try:
        json_filename = "numbered_markers_results.json"
        json_path = os.path.join(output_dir, json_filename)

        mission_summary = {
            'mission_timestamp': datetime.now().isoformat(),
            'total_numbered_markers_found': len(numbered_markers),
            'markers': numbered_markers
        }

        with open(json_path, 'w') as f:
            json.dump(mission_summary, f, indent=2)

        logging.info(f"üíæ Saved {len(numbered_markers)} numbered markers to {json_filename}")

    except Exception as e:
        logging.error(f"Error saving JSON file: {str(e)}")

def get_camera_frame(video_recorder):
    """Get frame from shared video recorder with error handling"""
    try:
        if video_recorder is not None and hasattr(video_recorder, 'cap') and video_recorder.cap is not None:
            ret, frame = video_recorder.cap.read()
            if ret:
                return frame
        return None
    except Exception as e:
        logging.warning(f"Error getting camera frame: {str(e)}")
        return None

def command_waypoint(vehicle, lat, lon, alt):
    """Send waypoint command with error handling"""
    try:
        if not vehicle:
            logging.error("No vehicle connection for waypoint command")
            return False

        # Validate coordinates
        if not (-90 <= lat <= 90) or not (-180 <= lon <= 180):
            logging.error(f"Invalid coordinates: lat={lat}, lon={lon}")
            return False

        if alt < 0:
            logging.warning(f"Negative altitude: {alt}, using absolute value")
            alt = abs(alt)

        vehicle.mav.set_position_target_global_int_send(
            0, vehicle.target_system, vehicle.target_component,
            mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT,
            0b0000111111111000,
            int(lat * 1e7), int(lon * 1e7), alt,
            0, 0, 0, 0, 0, 0, 0, 0
        )
        return True
    except Exception as e:
        logging.error(f"Error sending waypoint command: {str(e)}")
        return False

def wait_for_waypoint_blocking(vehicle, target_lat, target_lon, target_altitude, timeout=45, tolerance=1.5):
    """Blocking wait for waypoint arrival with error handling"""
    if not vehicle:
        return False

    try:
        start_time = time.time()
        target_location = (target_lat, target_lon, 0)
        stable_count = 0
        required_stable_readings = 3

        # Add safety checks
        position_check_failures = 0
        max_position_failures = 5

        while time.time() - start_time < timeout:
            try:
                current_location = get_location(vehicle)
                if current_location:
                    distance = get_distance_metres(current_location, target_location)

                    if distance <= tolerance:
                        stable_count += 1
                        if stable_count >= required_stable_readings:
                            logging.info(f"‚úÖ Waypoint reached (distance: {distance:.2f}m)")
                            return True
                    else:
                        stable_count = 0

                    position_check_failures = 0  # Reset failure count on success
                else:
                    position_check_failures += 1
                    if position_check_failures >= max_position_failures:
                        logging.error("Too many position check failures")
                        return False

            except Exception as check_error:
                logging.warning(f"Error during waypoint check: {str(check_error)}")
                position_check_failures += 1
                if position_check_failures >= max_position_failures:
                    logging.error("Too many waypoint check errors")
                    return False

            time.sleep(0.3)

        logging.warning("‚è∞ Waypoint timeout")
        return False

    except Exception as e:
        logging.error(f"Error waiting for waypoint: {str(e)}")
        return False

def wait_for_landing(vehicle):
    """Wait for vehicle to land and disarm with error handling"""
    try:
        start_time = time.time()
        timeout = 120  # 2 minutes timeout

        while time.time() - start_time < timeout:
            try:
                if not check_if_armed(vehicle):
                    logging.info("‚úÖ Vehicle has landed and disarmed")
                    break
            except Exception as check_error:
                logging.warning(f"Error checking armed status: {str(check_error)}")

            time.sleep(2)

        if time.time() - start_time >= timeout:
            logging.warning("Landing wait timed out")

    except Exception as e:
        logging.error(f"Error waiting for landing: {str(e)}")
        # Don't fail the mission for landing wait errors

